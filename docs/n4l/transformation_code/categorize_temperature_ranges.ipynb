{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c20b0bbddb1e204",
   "metadata": {},
   "source": "assign temperature range assertions, like would be found in local/flattened_n4l_temperature_components.tsv, agaisnt the minimum and maximum boundaries in metpo.owl"
  },
  {
   "cell_type": "markdown",
   "id": "c1417875270c75e7",
   "metadata": {},
   "source": "why are there N4L and NCBI taxa in there now?"
  },
  {
   "cell_type": "markdown",
   "id": "c71cccde79486788",
   "metadata": {},
   "source": "need better review of  conflicts, which should lead to modified parsing"
  },
  {
   "cell_type": "markdown",
   "id": "2d48b83b0cfe55af",
   "metadata": {},
   "source": "check which taxa didn't get any assignments"
  },
  {
   "cell_type": "markdown",
   "id": "70cba90a3284c76a",
   "metadata": {},
   "source": [
    "N4L temperature predicates, after normalization\n",
    "\n",
    "* <http://example.com/n4l/temperature>\n",
    "    * at least partially handled by metpo/classify_temperature_values.ipynb, sparql/report_parsed_temperature_categories.rq\n",
    "* <http://example.com/n4l/temperature_(grows)>\n",
    "* <http://example.com/n4l/temperature_optimum>\n",
    "* <http://example.com/n4l/temperature_range>\n",
    "* <http://example.com/n4l/temperature_(does_not_grow)>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9ccf6dbaef1576",
   "metadata": {},
   "source": [
    "What can be inferred from another temperature assertion?\n",
    "\n",
    "Optimum is generally measured, not inferred.\n",
    "\n",
    "* Delta can always be calculated from the range.\n",
    "* Categorical labels are assigned based on optimum (and sometimes range).\n",
    "* Psychrotolerant/thermotolerant specifically require both optimum and range (and duration of tolerance?) for accurate assignment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a40f42d6522c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f2a2ee50f7533",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_dir = Path().resolve()\n",
    "project_root = notebook_dir if (notebook_dir / \"Makefile\").exists() else notebook_dir.parent\n",
    "# assets_dir = project_root / \"assets\"\n",
    "# local_dir = project_root / \"local\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55812a05ae386d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROTOLOG_DIR = project_root / \"assets\" / \"N4L_phenotypic_ontology_2016\" / \"extracted_protologs_2013\" / \"protologs\"\n",
    "\n",
    "protologs_set = set(os.listdir(PROTOLOG_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e451cef25d7cf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_csv = project_root / \"local\" / \"metpo_classes_temperature_limits.csv\"\n",
    "observations_tsv = project_root / \"local\" / \"flattened_n4l_temperature_components.tsv\"\n",
    "output_tsv = project_root / \"local\" / \"categorized_temperature_range_assignments.tsv\"\n",
    "summary_tsv = project_root / \"local\" / \"categorized_temperature_range_summary.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994416f4b4a07617",
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_conflict_threshold = 8\n",
    "inter_conflict_threshold = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa2bc9a59138080",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_threshold = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476e14c03474eb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations_df = pd.read_csv(observations_tsv, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1977ef7c2762fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inputs\n",
    "classes_df = pd.read_csv(classes_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11966c13fd81c873",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations_df = observations_df[[\"?subject\", \"?predicate\",\n",
    "                                   \"?minimum_value\", \"?maximum_value\", \"?spot_value\",\n",
    "                                   \"?unit\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135acf62beab18ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations_df = observations_df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c9ad534e476bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations_df = observations_df[\n",
    "    observations_df[[\"?minimum_value\", \"?maximum_value\", \"?spot_value\"]]\n",
    "    .notna().any(axis=1)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f857ed98e5d2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean class definitions\n",
    "classes_df = classes_df.rename(columns={\n",
    "    \"s\": \"class_iri\",\n",
    "    \"l\": \"class_label\",\n",
    "    \"min\": \"class_min\",\n",
    "    \"max\": \"class_max\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57716ea3fc8fbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations_df = observations_df.rename(columns=lambda c: c.lstrip(\"?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e4668f7d7525b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"minimum_value\", \"maximum_value\", \"spot_value\"]:\n",
    "    observations_df[col] = pd.to_numeric(observations_df[col], errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfc4c9feee5aeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove angle brackets for subject matching\n",
    "observations_df[\"subject\"] = observations_df[\"subject\"].str.strip(\"<>\")\n",
    "observations_df[\"predicate\"] = observations_df[\"predicate\"].str.strip(\"<>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d82d1cc5a18e10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numeric values if not done already\n",
    "for col in [\"minimum_value\", \"maximum_value\", \"spot_value\"]:\n",
    "    observations_df[col] = pd.to_numeric(observations_df[col], errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9907f70cda7236bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4680aa6a54bc28c0",
   "metadata": {},
   "source": "may want to add facultative psychrophile to match KG-Microbe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f00763a586ba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------\n",
    "# Define class groupings\n",
    "# -----------------------------------------------\n",
    "\n",
    "# Group 1: growth category classes (e.g., thermophile)\n",
    "growth_classes = classes_df[classes_df[\"class_label\"].isin([\n",
    "    \"psychrophile\", \"psychrotolerant\", \"mesophile\",\n",
    "    \"thermotolerant\", \"thermophile\", \"hyperthermophile\",\n",
    "    \"extreme thermophile\", \"extreme hyperthermophile\"\n",
    "])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c85cbd144f7388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group 2: temperature optimum and range subclasses\n",
    "subrange_classes = classes_df[classes_df[\"class_label\"].str.startswith(\"temperature optimum\") |\n",
    "                              classes_df[\"class_label\"].str.startswith(\"temperature range\")].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e432d08c2ad9984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group 3: delta range classes\n",
    "delta_classes = classes_df[classes_df[\"class_label\"].str.startswith(\"temperature delta\")].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af6290394801fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count non-null values across minimum, maximum, spot (melted)\n",
    "observation_counts = (\n",
    "    observations_df[[\"subject\", \"minimum_value\", \"maximum_value\", \"spot_value\"]]\n",
    "    .melt(id_vars=\"subject\", value_name=\"value\")\n",
    "    .dropna(subset=[\"value\"])\n",
    "    .groupby(\"subject\")\n",
    "    .size()\n",
    "    .reset_index(name=\"observation_count\")\n",
    ")\n",
    "\n",
    "# Count unique predicates per subject\n",
    "predicate_counts = (\n",
    "    observations_df[[\"subject\", \"predicate\"]]\n",
    "    .drop_duplicates()\n",
    "    .groupby(\"subject\")\n",
    "    .size()\n",
    "    .reset_index(name=\"predicate_count\")\n",
    ")\n",
    "\n",
    "# âœ… Merge them into one DataFrame\n",
    "summary = pd.merge(observation_counts, predicate_counts, on=\"subject\", how=\"outer\").fillna(0)\n",
    "summary[\"observation_count\"] = summary[\"observation_count\"].astype(int)\n",
    "summary[\"predicate_count\"] = summary[\"predicate_count\"].astype(int)\n",
    "\n",
    "summary[\"magnitude\"] = np.sqrt(summary[\"observation_count\"] ** 2 + summary[\"predicate_count\"] ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8c1034c6bf2484",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICATE_COLORS = {\n",
    "    \"temperature_optimum\": \"green\",\n",
    "    \"temperature_range\": \"yellow\",\n",
    "    \"temperature_(grows)\": \"orange\",\n",
    "    \"temperature_(does_not_grow)\": \"red\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772078235e7d7f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicate_color(predicate_iri):\n",
    "    short = predicate_iri.split(\"/\")[-1]\n",
    "    return PREDICATE_COLORS.get(short, \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d93f0fe71bb80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_temperature_profile(subject_id=None, observations_df=None, classes_df=None):\n",
    "    has_obs = observations_df is not None and subject_id is not None\n",
    "    has_classes = classes_df is not None\n",
    "\n",
    "    if not has_obs and not has_classes:\n",
    "        raise ValueError(\"Must provide at least a subject + observations_df or a classes_df.\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    y_labels = []\n",
    "    y_positions = []\n",
    "    y_pos = 0\n",
    "\n",
    "    # === Plot subject observations ===\n",
    "    if has_obs:\n",
    "        sub = observations_df[observations_df[\"subject\"] == subject_id].copy()\n",
    "        if sub.empty:\n",
    "            print(f\"No observations found for subject: {subject_id}\")\n",
    "        else:\n",
    "            spot_agg = (\n",
    "                sub[pd.notnull(sub[\"spot_value\"])]\n",
    "                .groupby([\"predicate\", \"spot_value\"])\n",
    "                .size()\n",
    "                .reset_index(name=\"count\")\n",
    "            )\n",
    "\n",
    "            for pred_short in reversed(PREDICATE_COLORS):\n",
    "                full_preds = [p for p in sub[\"predicate\"].unique() if p.endswith(pred_short)]\n",
    "                for pred in full_preds:\n",
    "                    color = get_predicate_color(pred)\n",
    "\n",
    "                    # Spot values\n",
    "                    spots = spot_agg[spot_agg[\"predicate\"] == pred]\n",
    "                    if not spots.empty:\n",
    "                        for _, row in spots.iterrows():\n",
    "                            ax.scatter(row[\"spot_value\"], y_pos, color=color,\n",
    "                                       s=30 + 20 * row[\"count\"], zorder=5)\n",
    "                        y_labels.append(f\"{pred_short} (spot)\")\n",
    "                        y_positions.append(y_pos)\n",
    "                        y_pos += 1\n",
    "\n",
    "                    # Range values\n",
    "                    ranges = sub[\n",
    "                        (sub[\"predicate\"] == pred) &\n",
    "                        pd.notnull(sub[\"minimum_value\"]) &\n",
    "                        pd.notnull(sub[\"maximum_value\"])\n",
    "                        ]\n",
    "                    if not ranges.empty:\n",
    "                        range_group = (\n",
    "                            ranges.groupby([\"minimum_value\", \"maximum_value\"])\n",
    "                            .size()\n",
    "                            .reset_index(name=\"count\")\n",
    "                        )\n",
    "                        for _, row in range_group.iterrows():\n",
    "                            ax.plot([row[\"minimum_value\"], row[\"maximum_value\"]], [y_pos, y_pos],\n",
    "                                    color=color, lw=1 + row[\"count\"], alpha=0.6)\n",
    "                            ax.scatter([row[\"minimum_value\"], row[\"maximum_value\"]], [y_pos, y_pos],\n",
    "                                       color=color, s=20 + 10 * row[\"count\"])\n",
    "                        y_labels.append(f\"{pred_short} (range)\")\n",
    "                        y_positions.append(y_pos)\n",
    "                        y_pos += 1\n",
    "\n",
    "    # === Plot target classes ===\n",
    "    if has_classes:\n",
    "        class_df = classes_df[\n",
    "            ~classes_df[\"class_label\"].str.startswith(\"temperature delta\")\n",
    "        ].copy()\n",
    "\n",
    "        # Sorting keys\n",
    "        class_df[\"sort_min\"] = class_df[\"class_min\"].fillna(-np.inf)\n",
    "        class_df[\"sort_max\"] = class_df[\"class_max\"].fillna(np.inf)\n",
    "\n",
    "        # Grouping logic\n",
    "        is_range = class_df[\"class_label\"].str.contains(\"temperature range\", case=False)\n",
    "        is_optimum = class_df[\"class_label\"].str.contains(\"temperature optimum\", case=False)\n",
    "\n",
    "        df_range = class_df[is_range].sort_values(by=[\"sort_min\", \"sort_max\"])\n",
    "        df_optimum = class_df[is_optimum & ~is_range].sort_values(by=[\"sort_min\", \"sort_max\"])\n",
    "        df_other = class_df[~is_range & ~is_optimum].sort_values(by=[\"sort_min\", \"sort_max\"])\n",
    "\n",
    "        sorted_class_df = pd.concat([df_range, df_optimum, df_other], ignore_index=True)\n",
    "\n",
    "        for _, row in sorted_class_df.iterrows():\n",
    "            label = row[\"class_label\"]\n",
    "            min_val = row[\"class_min\"]\n",
    "            max_val = row[\"class_max\"]\n",
    "            cy = y_pos\n",
    "\n",
    "            if pd.notnull(min_val) and pd.notnull(max_val):\n",
    "                ax.plot([min_val, max_val], [cy, cy], color=\"black\", lw=2)\n",
    "                ax.scatter([min_val, max_val], [cy, cy], color=\"black\", zorder=5)\n",
    "            elif pd.notnull(min_val) and pd.isnull(max_val):\n",
    "                ax.text(min_val, cy, \"â–¶\", fontsize=12, ha=\"left\", va=\"center\", color=\"black\")\n",
    "            elif pd.notnull(max_val) and pd.isnull(min_val):\n",
    "                ax.text(max_val, cy, \"â—€\", fontsize=12, ha=\"right\", va=\"center\", color=\"black\")\n",
    "\n",
    "            y_labels.append(label)\n",
    "            y_positions.append(cy)\n",
    "            y_pos += 1\n",
    "\n",
    "    # === Final layout ===\n",
    "    if y_labels:\n",
    "        ax.set_yticks(y_positions)\n",
    "        ax.set_yticklabels(y_labels)\n",
    "\n",
    "    ax.set_xlabel(\"Temperature (Â°C)\")\n",
    "    title = \"Temperature Profile\"\n",
    "    if subject_id:\n",
    "        title += f\" for {subject_id}\"\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bfb375fd9ff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def assign_temperature_classes_advanced(\n",
    "        subject_id,\n",
    "        observations_df,\n",
    "        classes_df,\n",
    "        overlap_threshold=0.5,\n",
    "        return_all_matches=True\n",
    "):\n",
    "    def get_range(row):\n",
    "        if pd.notnull(row.get(\"minimum_value\")) and pd.notnull(row.get(\"maximum_value\")):\n",
    "            return row[\"minimum_value\"], row[\"maximum_value\"]\n",
    "        elif pd.notnull(row.get(\"spot_value\")):\n",
    "            return row[\"spot_value\"], row[\"spot_value\"]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    obs = observations_df[observations_df[\"subject\"] == subject_id]\n",
    "    if obs.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    predicate_intervals = {\n",
    "        \"temperature_optimum\": [],\n",
    "        \"temperature_range\": [],\n",
    "        \"temperature_(grows)\": [],\n",
    "        \"temperature_(does_not_grow)\": []\n",
    "    }\n",
    "\n",
    "    for _, row in obs.iterrows():\n",
    "        predicate = row[\"predicate\"].split(\"/\")[-1]\n",
    "        if predicate in predicate_intervals:\n",
    "            r = get_range(row)\n",
    "            if r:\n",
    "                predicate_intervals[predicate].append(r)\n",
    "\n",
    "    all_positive_ranges = predicate_intervals[\"temperature_range\"] + predicate_intervals[\"temperature_(grows)\"] + \\\n",
    "                          predicate_intervals[\"temperature_optimum\"]\n",
    "    if all_positive_ranges:\n",
    "        min_temp = min(r[0] for r in all_positive_ranges)\n",
    "        max_temp = max(r[1] for r in all_positive_ranges)\n",
    "        delta = max_temp - min_temp\n",
    "    else:\n",
    "        delta = None\n",
    "\n",
    "    def tag_class_group(label):\n",
    "        if \"delta\" in label.lower():\n",
    "            return \"delta\"\n",
    "        elif \"range\" in label.lower():\n",
    "            return \"range\"\n",
    "        elif \"optimum\" in label.lower():\n",
    "            return \"optimum\"\n",
    "        else:\n",
    "            return \"categorical\"\n",
    "\n",
    "    results = []\n",
    "    class_df = classes_df.copy()\n",
    "    class_df[\"group\"] = class_df[\"class_label\"].apply(tag_class_group)\n",
    "    class_df[\"span\"] = class_df[\"class_max\"].fillna(np.inf) - class_df[\"class_min\"].fillna(-np.inf)\n",
    "\n",
    "    for _, cls in class_df.iterrows():\n",
    "        label = cls[\"class_label\"]\n",
    "        iri = cls.get(\"class_iri\")\n",
    "        group = cls[\"group\"]\n",
    "        cmin = cls[\"class_min\"] if pd.notnull(cls[\"class_min\"]) else -np.inf\n",
    "        cmax = cls[\"class_max\"] if pd.notnull(cls[\"class_max\"]) else np.inf\n",
    "        span = cls[\"span\"]\n",
    "\n",
    "        matched = False\n",
    "        excluded = False\n",
    "        matched_range = None\n",
    "        overlap_fraction = 0\n",
    "\n",
    "        if group == \"optimum\":\n",
    "            candidates = predicate_intervals[\"temperature_optimum\"]\n",
    "        elif group in [\"range\", \"categorical\"]:\n",
    "            candidates = predicate_intervals[\"temperature_range\"] + predicate_intervals[\"temperature_(grows)\"]\n",
    "        elif group == \"delta\" and delta is not None:\n",
    "            if cmin <= delta <= cmax:\n",
    "                matched = True\n",
    "                matched_range = (delta, delta)\n",
    "                overlap_fraction = 1.0\n",
    "        else:\n",
    "            candidates = []\n",
    "\n",
    "        for rmin, rmax in candidates:\n",
    "            overlap_min = max(cmin, rmin)\n",
    "            overlap_max = min(cmax, rmax)\n",
    "            overlap_len = max(0, overlap_max - overlap_min)\n",
    "            rlen = max(1e-6, rmax - rmin)\n",
    "            frac = overlap_len / rlen\n",
    "            if frac >= overlap_threshold:\n",
    "                matched = True\n",
    "                matched_range = (rmin, rmax)\n",
    "                overlap_fraction = frac\n",
    "                break\n",
    "\n",
    "        if matched and group != \"delta\":\n",
    "            for rmin, rmax in predicate_intervals[\"temperature_(does_not_grow)\"]:\n",
    "                if max(cmin, rmin) < min(cmax, rmax):\n",
    "                    excluded = True\n",
    "                    break\n",
    "\n",
    "        if matched:\n",
    "            results.append({\n",
    "                \"subject\": subject_id,\n",
    "                \"class_label\": label,\n",
    "                \"class_iri\": iri,\n",
    "                \"class_group\": group,\n",
    "                \"assignment\": \"match\" if not excluded else \"excluded\",\n",
    "                \"source_range\": matched_range,\n",
    "                \"class_range\": (cmin, cmax),\n",
    "                \"overlap_fraction\": overlap_fraction,\n",
    "                \"class_span\": span\n",
    "            })\n",
    "\n",
    "    result_df = pd.DataFrame(results)\n",
    "    if not return_all_matches:\n",
    "        final = []\n",
    "        for group in result_df[\"class_group\"].unique():\n",
    "            subset = result_df[(result_df[\"class_group\"] == group) & (result_df[\"assignment\"] == \"match\")]\n",
    "            if not subset.empty:\n",
    "                final.append(subset.loc[subset[\"class_span\"].idxmin()])\n",
    "        return pd.DataFrame(final)\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22953e273f7993ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments = assign_temperature_classes_advanced(\n",
    "    \"http://example.com/n4l/rid.2547_nm.11491\",\n",
    "    observations_df,\n",
    "    classes_df,\n",
    "    overlap_threshold=overlap_threshold,\n",
    "    return_all_matches=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d2b355c2a36607",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_subjects = observations_df[\"subject\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55ab84dbe24351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments = pd.concat([\n",
    "    assign_temperature_classes_advanced(\n",
    "        subject_id=subj,\n",
    "        observations_df=observations_df,\n",
    "        classes_df=classes_df,\n",
    "        overlap_threshold=overlap_threshold,\n",
    "        return_all_matches=True\n",
    "    )\n",
    "    for subj in unique_subjects\n",
    "], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a20af7c7f33dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc64e331def724c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_temperature_conflicts(observations_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    def extract_intervals(df: pd.DataFrame) -> List[Tuple[float, float]]:\n",
    "        ranges = []\n",
    "        for _, row in df.iterrows():\n",
    "            if pd.notnull(row.get(\"minimum_value\")) and pd.notnull(row.get(\"maximum_value\")):\n",
    "                ranges.append((row[\"minimum_value\"], row[\"maximum_value\"]))\n",
    "            elif pd.notnull(row.get(\"spot_value\")):\n",
    "                v = row[\"spot_value\"]\n",
    "                ranges.append((v, v))\n",
    "        return ranges\n",
    "\n",
    "    def compute_spread(intervals: List[Tuple[float, float]]) -> float:\n",
    "        if not intervals:\n",
    "            return 0.0\n",
    "        mins, maxs = zip(*intervals)\n",
    "        return max(maxs) - min(mins)\n",
    "\n",
    "    def count_disjoint_clusters(intervals: List[Tuple[float, float]], proximity=2.0) -> int:\n",
    "        if not intervals:\n",
    "            return 0\n",
    "        sorted_intervals = sorted(intervals, key=lambda x: x[0])\n",
    "        clusters = 1\n",
    "        _, current_end = sorted_intervals[0]\n",
    "        for start, end in sorted_intervals[1:]:\n",
    "            if start > current_end + proximity:\n",
    "                clusters += 1\n",
    "                current_end = end\n",
    "            else:\n",
    "                current_end = max(current_end, end)\n",
    "        return clusters\n",
    "\n",
    "    def has_overlap(a: Tuple[float, float], b: Tuple[float, float], buffer=1.0) -> bool:\n",
    "        return max(a[0], b[0]) - min(a[1], b[1]) <= buffer\n",
    "\n",
    "    summaries = []\n",
    "    for subject, group in observations_df.groupby(\"subject\"):\n",
    "        summary = {\"subject\": subject}\n",
    "        notes = []\n",
    "\n",
    "        # Per-predicate intra-conflict analysis (excluding does_not_grow)\n",
    "        intra_scores = []\n",
    "        for predicate in [\"temperature_optimum\", \"temperature_range\", \"temperature_(grows)\"]:\n",
    "            pred_group = group[group[\"predicate\"].str.endswith(predicate)]\n",
    "            intervals = extract_intervals(pred_group)\n",
    "            spread = compute_spread(intervals)\n",
    "            clusters = count_disjoint_clusters(intervals)\n",
    "\n",
    "            summary[f\"{predicate}_spread\"] = spread\n",
    "            summary[f\"{predicate}_clusters\"] = clusters\n",
    "            intra_scores.append(clusters + spread / 10)\n",
    "\n",
    "            if clusters > 1:\n",
    "                notes.append(f\"{predicate} has {clusters} disjoint clusters\")\n",
    "            if spread > 30:\n",
    "                notes.append(f\"{predicate} spread is wide ({spread:.1f}Â°C)\")\n",
    "\n",
    "        summary[\"intra_conflict_score\"] = sum(intra_scores)\n",
    "\n",
    "        # Inter-predicate conflict: grows vs does_not_grow\n",
    "        grows = extract_intervals(group[group[\"predicate\"].str.endswith(\"temperature_(grows)\")])\n",
    "        not_grows = extract_intervals(group[group[\"predicate\"].str.endswith(\"temperature_(does_not_grow)\")])\n",
    "        inter_score = 0\n",
    "        for g in grows:\n",
    "            for ng in not_grows:\n",
    "                if has_overlap(g, ng, buffer=2.0):\n",
    "                    inter_score += 1\n",
    "                    notes.append(f\"Grow {g} conflicts with NoGrow {ng}\")\n",
    "\n",
    "        summary[\"inter_conflict_score\"] = inter_score\n",
    "        summary[\"conflict_notes\"] = \"; \".join(notes) if notes else \"None\"\n",
    "        summaries.append(summary)\n",
    "\n",
    "    return pd.DataFrame(summaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e484ebbdb9b679d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_conflicts = detect_temperature_conflicts(observations_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0b8e1d725ebba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the counts and conflicts\n",
    "full_summary = pd.merge(\n",
    "    summary,\n",
    "    temperature_conflicts,\n",
    "    on=\"subject\",\n",
    "    how=\"left\"  # so no subject gets dropped\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462b8aafc6045e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is called df\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(full_summary[\"intra_conflict_score\"], full_summary[\"inter_conflict_score\"], alpha=0.7)\n",
    "plt.xlabel(\"Intra Conflict Score\")\n",
    "plt.ylabel(\"Inter Conflict Score\")\n",
    "plt.title(\"Scatter Plot of Conflict Scores\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9609d8928f5f7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(full_summary[\"intra_conflict_score\"], bins=30, color=\"steelblue\", edgecolor=\"black\", alpha=0.8)\n",
    "plt.xlabel(\"Intra Conflict Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of Intra Conflict Scores\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f257f25ebcd1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_conflict_df = full_summary.query(\n",
    "    f\"intra_conflict_score >= {intra_conflict_threshold} or inter_conflict_score >= {inter_conflict_threshold}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f8c0ac5966e22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ids(subject_iri: str) -> Tuple[str, str]:\n",
    "    rid_match = re.search(r\"(rid\\.\\d+)\", subject_iri)\n",
    "    nm_match = re.search(r\"(nm\\.\\d+)\", subject_iri)\n",
    "    rid = rid_match.group(1) if rid_match else \"?\"\n",
    "    nm = nm_match.group(1) if nm_match else \"?\"\n",
    "    return rid, nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520437fb4f31436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_protolog_files(rid: str, nm: str, filenames: set) -> Dict[str, Optional[str] or List[str]]:\n",
    "    exact = f\"{rid}_{nm}.xml\" if rid != \"?\" and nm != \"?\" else None\n",
    "    exact_match = exact if exact in filenames else None\n",
    "\n",
    "    partial_matches = []\n",
    "\n",
    "    # Compile strict regex: match only if ID is surrounded by (_) or (.) or start/end of string\n",
    "    rid_pattern = re.compile(rf\"(^|[_\\.]){re.escape(rid)}([_\\.]|$)\") if rid != \"?\" else None\n",
    "    nm_pattern = re.compile(rf\"(^|[_\\.]){re.escape(nm)}([_\\.]|$)\") if nm != \"?\" else None\n",
    "\n",
    "    for f in filenames:\n",
    "        if exact_match and f == exact_match:\n",
    "            continue\n",
    "        if ((rid_pattern and rid_pattern.search(f)) or\n",
    "                (nm_pattern and nm_pattern.search(f))):\n",
    "            partial_matches.append(f)\n",
    "\n",
    "    return {\n",
    "        \"exact\": exact_match,\n",
    "        \"partial\": sorted(partial_matches)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a6a4dc9e26a759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_protolog_content_pretty(filepath: str) -> Optional[str]:\n",
    "    try:\n",
    "\n",
    "        ns = {\"n4l\": \"http://namesforlife.com/ns/protolog\"}\n",
    "        ET.register_namespace(\"\", ns[\"n4l\"])\n",
    "\n",
    "        tree = ET.parse(filepath)\n",
    "        root = tree.getroot()\n",
    "        content = root.find(\".//{http://namesforlife.com/ns/protolog}content\")\n",
    "\n",
    "        if content is not None:\n",
    "            # Convert ElementTree element to string\n",
    "            rough_string = ET.tostring(content, encoding=\"utf-8\")\n",
    "            # Parse with minidom for pretty print\n",
    "            reparsed = minidom.parseString(rough_string)\n",
    "            return reparsed.toprettyxml(indent=\"  \")\n",
    "        else:\n",
    "            return \"(no <content> node found)\"\n",
    "    except Exception as e:\n",
    "        print(f\"(Failed to load {filepath}: {e})\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c67abe084c93618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_subject_protolog(\n",
    "        subject_iri: str,\n",
    "        intra_score: float,\n",
    "        inter_score: float,\n",
    "        observations_df: pd.DataFrame,\n",
    "        classes_df: pd.DataFrame\n",
    "):\n",
    "    rid, nm = extract_ids(subject_iri)\n",
    "    print(f\"## {subject_iri}\")\n",
    "    print(f\"  - Reference ID: {rid}\")\n",
    "    print(f\"  - Taxon Name ID: {nm}\")\n",
    "    print(f\"  - Intra Conflict Score: {intra_score}\")\n",
    "    print(f\"  - Inter Conflict Score: {inter_score}\")\n",
    "\n",
    "    plot_temperature_profile(subject_id=subject_iri, observations_df=observations_df, classes_df=classes_df)\n",
    "\n",
    "    match_info = find_protolog_files(rid, nm, protologs_set)\n",
    "    if match_info[\"exact\"]:\n",
    "        print(f\"\\nâœ… Exact match: {match_info['exact']}\")\n",
    "        path = os.path.join(PROTOLOG_DIR, match_info[\"exact\"])\n",
    "        xml_text = load_protolog_content_pretty(path)\n",
    "        if xml_text:\n",
    "            print(\"\\n--- Protolog XML ---\")\n",
    "            print(xml_text)\n",
    "    elif match_info[\"partial\"]:\n",
    "        print(f\"\\nðŸŸ¡ Partial matches for {rid or '[none]'}, {nm or '[none]'}:\")\n",
    "        for fname in match_info[\"partial\"]:\n",
    "            print(f\"   - {fname}\")\n",
    "        for fname in match_info[\"partial\"]:\n",
    "            path = os.path.join(PROTOLOG_DIR, fname)\n",
    "            xml_text = load_protolog_content_pretty(path)\n",
    "            if xml_text:\n",
    "                print(\"\\n--- Protolog XML ---\")\n",
    "                print(xml_text)\n",
    "                break\n",
    "    else:\n",
    "        print(\"\\n(no protolog XML found)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9182b44a35e137d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in high_conflict_df.iterrows():\n",
    "    display_subject_protolog(\n",
    "        subject_iri=row[\"subject\"],\n",
    "        intra_score=row[\"intra_conflict_score\"],\n",
    "        inter_score=row[\"inter_conflict_score\"],\n",
    "        observations_df=observations_df,\n",
    "        classes_df=classes_df\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07757e85bfb616b",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸ“Š Key DataFrames Created in `categorize_temperature_ranges.ipynb`\n",
    "\n",
    "This notebook processes structured temperature phenotype data and creates several intermediate and final DataFrames. Below is a categorized summary of all major DataFrames that may be useful to save or reuse.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Primary Inputs\n",
    "\n",
    "### `observations_df`\n",
    "- **Source**: `../assets/flattened_n4l_temperature_components_manually_filtered_quantitative.tsv`\n",
    "- **Description**: Raw temperature-related annotations from N4L.\n",
    "- **Columns**:\n",
    "  `subject`, `predicate`, `minimum_value`, `maximum_value`, `spot_value`, etc.\n",
    "\n",
    "### `classes_df`\n",
    "- **Source**: `../assets/metpo-temperature-ranges-of-classes.csv`\n",
    "- **Description**: Definitions of temperature class boundaries.\n",
    "- **Columns**:\n",
    "  `class_iri`, `class_label`, `class_min`, `class_max`\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§® Intermediate & Analytical Outputs\n",
    "\n",
    "### `summary`\n",
    "- **Description**: Observation and predicate counts per subject.\n",
    "- **Columns**:\n",
    "  `subject`, `observation_count`, `predicate_count`, `magnitude`\n",
    "\n",
    "### `assignments`\n",
    "- **Description**: Per-subject temperature class assignment results.\n",
    "- **Columns**:\n",
    "  `subject`, `class_label`, `class_iri`, `assignment` (`match` or `excluded`),\n",
    "  `source_range`, `class_range`, `overlap_fraction`, `class_span`, `class_group`\n",
    "\n",
    "### `temperature_conflicts`\n",
    "- **Description**: Per-subject intra- and inter-predicate conflict diagnostics.\n",
    "- **Columns**:\n",
    "  - `[predicate]_spread`\n",
    "  - `[predicate]_clusters`\n",
    "  - `intra_conflict_score`\n",
    "  - `inter_conflict_score`\n",
    "  - `conflict_notes`\n",
    "\n",
    "### `full_summary`\n",
    "- **Description**: Merge of `summary` and `temperature_conflicts`.\n",
    "- **Use**: Ideal for export, scoring, or dashboarding.\n",
    "- **Columns**: All of `summary` + `temperature_conflicts`\n",
    "\n",
    "### `high_conflict_df`\n",
    "- **Description**: Subset of `full_summary` with high conflict scores.\n",
    "- **Filter Logic**:\n",
    "  `intra_conflict_score >= 8 or inter_conflict_score >= 1`\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“Ž Optional Outputs\n",
    "\n",
    "### Per-subject Plots\n",
    "- **Generated by**: `plot_temperature_profile(subject_id, ...)`\n",
    "- **Use**: Diagnostic visualizations (not saved automatically).\n",
    "\n",
    "### Protolog Debug Info\n",
    "- **Generated by**: `display_subject_protolog(...)`\n",
    "- **Use**: XML snippets and alignment evidence for selected high-conflict subjects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba462efbfbb1e060",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_summary.to_csv(summary_tsv, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f27f859829ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments.to_csv(output_tsv, sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
