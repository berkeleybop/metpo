# Literature Mining and Abstract Fact Extraction Analysis

**Yes, you have robust support for extracting facts from abstracts!** Here's what's implemented:

## Current System Architecture

**Large ID dataset**: `n4l/reference_id_mapping.csv` (23,535 entries) with columns:
- `refid,year,pubmedid,pubmedcentralid,doi,uri`

**ID Types Currently Used**: The workflow uses **PubMed IDs (PMIDs)** from column 3 of the Names for Life (N4L) project reference mapping file. Out of 23,535 total records, 18,636 have valid PMIDs available.

**Random selection**: Line 72 in Makefile:
```bash
cut -f3 -d, $< | sort | uniq | grep '^[0-9]*$$' | shuf -n $(N_PMIDS) > $@
```

**Abstract fetching**: Uses `artl-cli get-abstract-from-pubmed-id` 

**Fact extraction**: OntoGPT with comprehensive template covering:
- Organisms, chemical compounds, enzymes, lipids/fatty acids
- Microbial phenotypes, environments  
- Relationship extraction (organism-compound, organism-phenotype, etc.)
- 60+ interaction types from METPO ontology

## Alternative ID Sources Available

**Current**: Names for Life (N4L) project PMIDs (18,636 available)

**Additional options** (Mark has MongoDB collections with):

**bacdive database:**
- `strains_api` - Generated by code in https://github.com/Knowledge-Graph-Hub/kg-microbe/pull/336
- `strains` 
- `strains_old`

**europepmc database:**
- `ijsem_articles` - Generated by code in https://github.com/turbomam/bacphen-awareness/blob/main/src/bacdive_tools/ijsem_from_epmc_to_mongo.py
- `organism_annotations`
- `annotation_state`
- `ijsem_state`

## Your Options

**Alternative ID sources**: Yes! Just modify line 72:
- **Different file**: Change `n4l/reference_id_mapping.csv` to your file
- **Different column**: Change `-f3` (3rd column) to `-f1`, `-f2`, etc.
- **Different format**: Replace the `cut -f3 -d,` with `cut -f1 -d$'\t'` for tab-separated, etc.

**Usage examples**:
```bash
make extract-random N_PMIDS=50  # 50 random PMIDs
make extract-all                # Process all existing abstracts
```

The system extracts to structured YAML with ontology grounding via multiple databases (ChEBI, NCBITaxon, ENVO, etc.).

## OntoGPT Model Configuration

**Default behavior**: OntoGPT uses **OpenAI GPT models** by default (likely `gpt-4o` or similar)

**Available model providers**:
- **OpenAI models**: GPT-4, GPT-4o, GPT-3.5-turbo, o1, o3, etc.
- **Anthropic Claude models**: claude-3-5-sonnet, claude-3-opus, claude-sonnet-4, etc.
- **Google models**: gemini-pro, gemini-1.5-pro, etc.
- **Many others**: Azure, Vertex AI, local models, etc.

**To specify a model**, use the `-m` flag:
```bash
poetry run ontogpt extract -t ontogpt_template.yaml -i abstracts -o all-extractions.yaml -m claude-3-5-sonnet-latest
```

**Configuration**: OntoGPT uses environment variables for API keys:
- `OPENAI_API_KEY` for OpenAI models
- `ANTHROPIC_API_KEY` for Claude models  
- `GOOGLE_API_KEY` for Gemini models

**To use Claude instead of default**:
```bash
make extract-all MODEL=claude-3-5-sonnet-latest
```
(Would require modifying the Makefile to pass the MODEL variable to the ontogpt command)

**To see what model is being used**, add verbose flag:
```bash
poetry run ontogpt extract -v -t ontogpt_template.yaml -i abstracts -o all-extractions.yaml
```

## Recommended Maximum Verbose Mode Command

For maximum debugging and visibility when processing abstracts:

```bash
poetry run ontogpt -v --cache-db taxa-cache.db extract --show-prompt -p 0.1 -t taxa_template.yaml -i abstracts -o taxa-all-extractions.yaml
```

**Options explained:**
- `-v`: Main verbose mode (shows processing steps)
- `--cache-db taxa-cache.db`: Caches results for debugging/re-runs
- `--show-prompt`: Shows all LLM prompts and responses
- `-p 0.1`: Low temperature for more consistent/deterministic results
- Processes full abstracts (no `--cut-input-text` to preserve complete taxonomic information)