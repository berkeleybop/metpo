/Users/MAM/Documents/gitrepos/metpo/.venv/lib/python3.11/site-packages/eutils/__init__.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
INFO:root:Logger root set to level 10
INFO:root:Input file directory: abstracts/test-morphology
INFO:root:Parsed 3 files.
INFO:linkml_runtime.utils.schemaview:Importing linkml:types as /Users/MAM/Documents/gitrepos/metpo/.venv/lib/python3.11/site-packages/linkml_runtime/linkml_model/model/schema/types from source /Users/MAM/Documents/gitrepos/metpo/.venv/lib/python3.11/site-packages/ontogpt/templates/core.yaml; base_dir=None
INFO:ontogpt.io.template_loader:Loading custom schema from templates/morphology_populated.yaml
INFO:linkml_runtime.utils.schemaview:Importing ontogpt:core as http://w3id.org/ontogpt/core from source /Users/MAM/Documents/gitrepos/metpo/.venv/lib/python3.11/site-packages/ontogpt/templates/morphology_populated.yaml; base_dir=None
INFO:linkml_runtime.utils.schemaview:Importing linkml:types as /Users/MAM/Documents/gitrepos/metpo/.venv/lib/python3.11/site-packages/linkml_runtime/linkml_model/model/schema/types from source /Users/MAM/Documents/gitrepos/metpo/.venv/lib/python3.11/site-packages/ontogpt/templates/morphology_populated.yaml; base_dir=None
INFO:linkml_runtime.utils.schemaview:Importing ontogpt:core as http://w3id.org/ontogpt/core from source /Users/MAM/Documents/gitrepos/metpo/.venv/lib/python3.11/site-packages/ontogpt/templates/morphology_populated.yaml; base_dir=None
INFO:linkml_runtime.utils.schemaview:Importing linkml:types as /Users/MAM/Documents/gitrepos/metpo/.venv/lib/python3.11/site-packages/linkml_runtime/linkml_model/model/schema/types from source /Users/MAM/Documents/gitrepos/metpo/.venv/lib/python3.11/site-packages/ontogpt/templates/morphology_populated.yaml; base_dir=None
INFO:ontogpt.io.template_loader:Getting class for template templates/morphology_populated.yaml
INFO:root:Using template MorphologyLiteratureExtraction
INFO:root:Using mappers (currently hardcoded)
INFO:root:Now extracting from file 1 of 3
INFO:root:Cleaning text...
INFO:ontogpt.clients.llm_client:Complete: engine=gpt-4o, prompt[7484]=From the text below, extract the following entities in the following format:

pmid: <PubMed ID of th...
DEBUG:LiteLLM:

DEBUG:LiteLLM:[92mRequest to litellm:[0m
DEBUG:LiteLLM:[92mlitellm.completion(api_key='', api_base='https://api.cborg.lbl.gov', api_version=None, model='gpt-4o', messages=[{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'From the text below, extract the following entities in the following format:\n\npmid: <PubMed ID of the article (e.g., 23996836)>\nstudy_taxa: <semicolon-separated list of the main bacterial or archaeal taxa being studied for morphology>\nstrains: <Extract ONLY the strain designation part (e.g., "DA-C8", "MG1655", "ATCC 25922") WITHOUT genus/species prefixes. Focus on strain numbers, culture collection codes, and isolate identifiers. Automatically remove terminal "T" or "(T)" suffixes as these indicate type strain status (e.g., "DA-C8T" becomes "DA-C8", "K13T" becomes "K13"). Include strain numbers, culture collection numbers, and isolate names, but NOT the full taxonomic context.>\ncell_shape: <Extract all cell shapes mentioned in the text exactly as described in the literature. Include measurements when provided (e.g., "rod-shaped, 0.5 x 2.0 Î¼m"). If no cell shapes are mentioned, leave this field empty. DO NOT write "none".>\ncell_arrangements: <Extract all cell arrangement patterns mentioned in the text (e.g., single cells, pairs, chains, clusters, tetrads, packets, irregular masses, palisades, V-shapes, angular arrangements). If no cell arrangements are mentioned, leave this field empty. DO NOT write "none".>\ngram_staining: <Extract Gram staining results mentioned in the text (e.g., Gram-positive, Gram-negative, Gram-variable, Gram-indeterminate). Include any additional staining properties mentioned. If no Gram staining information is mentioned, leave this field empty. DO NOT write "none".>\nmotility: <Extract all motility characteristics mentioned in the text, including motility presence (motile/non-motile), motility types (flagellar, gliding, twitching, swarming), and flagella arrangements (polar, peritrichous, monotrichous, lophotrichous, amphitrichous). If no motility information is mentioned, leave this field empty. DO NOT write "none".>\nspore_formation: <Extract all spore formation characteristics mentioned in the text, including spore presence (spore-forming/non-spore-forming), spore types (endospores, conidia, arthrospores), and spore positions (terminal, subterminal, central, lateral). Include sporangium or other structures. If no spore formation information is mentioned, leave this field empty. DO NOT write "none".>\ncell_wall_characteristics: <Extract all cell wall characteristics mentioned in the text, including structural features (thick/thin, multilayered), chemical components (peptidoglycan, teichoic acids, mycolic acids, lipopolysaccharide), and anatomical features (outer membrane, periplasmic space, S-layer, capsule). If no cell wall characteristics are mentioned, leave this field empty. DO NOT write "none".>\ncellular_inclusions: <Extract all cellular inclusions and internal structures mentioned in the text, including storage granules (PHB, PHA, polyphosphate, glycogen, sulfur, lipid droplets), specialized structures (gas vesicles, magnetosomes, carboxysomes), and other intracellular bodies. If no cellular inclusions are mentioned, leave this field empty. DO NOT write "none".>\ncell_shape_relationships: <For each cell shape extracted above, create strain-to-shape relationships. Link specific strains to their cell shapes (e.g., "DA-C8 has_cell_shape rod-shaped"). Convert ALL cell shapes mentioned above into structured relationships.>\ncell_arrangement_relationships: <For each cell arrangement extracted above, create strain-to-arrangement relationships. Link specific strains to their arrangements (e.g., "DA-C8 has_arrangement chains"). Convert ALL cell arrangements mentioned above into structured relationships.>\ngram_staining_relationships: <For each Gram staining result extracted above, create strain-to-staining relationships. Link specific strains to their staining results (e.g., "DA-C8 has_gram_staining Gram-positive"). Convert ALL Gram staining results mentioned above into structured relationships.>\nmotility_relationships: <For each motility characteristic extracted above, create strain-to-motility relationships. Link specific strains to their motility characteristics (e.g., "DA-C8 has_motility motile"). Convert ALL motility characteristics mentioned above into structured relationships.>\nspore_formation_relationships: <For each spore formation characteristic extracted above, create strain-to-spore relationships. Link specific strains to their spore characteristics (e.g., "DA-C8 has_spore_formation terminal spores"). Convert ALL spore formation characteristics mentioned above into structured relationships.>\ncell_wall_relationships: <For each cell wall characteristic extracted above, create strain-to-cell-wall relationships. Link specific strains to their cell wall features (e.g., "DA-C8 has_cell_wall_feature peptidoglycan"). Convert ALL cell wall characteristics mentioned above into structured relationships.>\ncellular_inclusion_relationships: <For each cellular inclusion extracted above, create strain-to-inclusion relationships. Link specific strains to their cellular inclusions (e.g., "DA-C8 has_inclusion PHB granules"). Convert ALL cellular inclusions mentioned above into structured relationships.>\npigmentation: <Extract all pigmentation and colony color characteristics mentioned in the text, including colors (yellow, orange, red, pink, white, cream, brown, black, green), pigment types (carotenoid, melanin, flexirubin), and properties (diffusible, non-diffusible, fluorescent). If no pigmentation is mentioned, leave this field empty. DO NOT write "none".>\nstrain_relationships: <A semicolon-separated list of strain-species relationships, where each relationship connects a strain to its parent taxon. Each relationship should have a strain name, relationship type, and parent species/genus. For example: "MG1655 strain_of Escherichia coli; K-12 strain_of Escherichia coli; ATCC 25922 type_strain_of Klebsiella pneumoniae". If no strain relationships are found, leave this field empty. DO NOT write "none".>\narticle_type: <The type of study or article. Choose the most appropriate category based on the content.Must be one of: novel_species, novel_genus, taxonomic_revision, phylogenetic_analysis, comparative_taxonomy, emended_description, genome_sequence, review, biochemical_characterization, ecological_study, morphological_characterization, physiology_study>\n\n\nText:\n{\'content\': \'Classification of metal-resistant bacteria from industrial biotopes as Ralstonia campinensis sp. nov., Ralstonia metallidurans sp. nov. and Ralstonia basilensis Steinle et al. 1998 emend.\\n\\nThirty-one heavy-metal-resistant bacteria isolated from industrial biotopes were subjected to polyphasic characterization, including 16S rDNA sequence analysis, DNA-DNA hybridizations, biochemical tests, whole-cell protein and fatty-acid analyses. All strains were shown to belong to the Ralstonia branch of the beta-Proteobacteria. Whole-cell protein profiles and DNA-DNA hybridizations revealed two clearly distinct groups, showing low similarity to known Ralstonia species. These two groups, of 8 and 17 isolates, were assigned to two new species, for which the names Ralstonia campinensis sp. nov. and Ralstonia metallidurans sp. nov. are proposed. The type strains are WS2T (= LMG 19282T = CCUG 44526T) and CH34T (= LMG 1195T = DSM 2839T), respectively. Six isolates were allocated to Ralstonia basilensis, which presently contains only the type strain; an emendation of the latter species description is therefore proposed.\\n\\nPMID:11594608\', \'saved_to\': None, \'windowed\': False}\n\n\n===\n\n', 'role': 'user'}], temperature=1.0, caching=True, custom_llm_provider='openai')[0m
DEBUG:LiteLLM:

DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:SYNC kwargs[caching]: True; litellm.cache: <litellm.caching.caching.Cache object at 0x105624f90>; kwargs.get('cache')['no-cache']: False
DEBUG:LiteLLM:INSIDE CHECKING SYNC CACHE
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'From the text below, extract the following entities in the following format:\n\npmid: <PubMed ID of the article (e.g., 23996836)>\nstudy_taxa: <semicolon-separated list of the main bacterial or archaeal taxa being studied for morphology>\nstrains: <Extract ONLY the strain designation part (e.g., "DA-C8", "MG1655", "ATCC 25922") WITHOUT genus/species prefixes. Focus on strain numbers, culture collection codes, and isolate identifiers. Automatically remove terminal "T" or "(T)" suffixes as these indicate type strain status (e.g., "DA-C8T" becomes "DA-C8", "K13T" becomes "K13"). Include strain numbers, culture collection numbers, and isolate names, but NOT the full taxonomic context.>\ncell_shape: <Extract all cell shapes mentioned in the text exactly as described in the literature. Include measurements when provided (e.g., "rod-shaped, 0.5 x 2.0 Î¼m"). If no cell shapes are mentioned, leave this field empty. DO NOT write "none".>\ncell_arrangements: <Extract all cell arrangement patterns mentioned in the text (e.g., single cells, pairs, chains, clusters, tetrads, packets, irregular masses, palisades, V-shapes, angular arrangements). If no cell arrangements are mentioned, leave this field empty. DO NOT write "none".>\ngram_staining: <Extract Gram staining results mentioned in the text (e.g., Gram-positive, Gram-negative, Gram-variable, Gram-indeterminate). Include any additional staining properties mentioned. If no Gram staining information is mentioned, leave this field empty. DO NOT write "none".>\nmotility: <Extract all motility characteristics mentioned in the text, including motility presence (motile/non-motile), motility types (flagellar, gliding, twitching, swarming), and flagella arrangements (polar, peritrichous, monotrichous, lophotrichous, amphitrichous). If no motility information is mentioned, leave this field empty. DO NOT write "none".>\nspore_formation: <Extract all spore formation characteristics mentioned in the text, including spore presence (spore-forming/non-spore-forming), spore types (endospores, conidia, arthrospores), and spore positions (terminal, subterminal, central, lateral). Include sporangium or other structures. If no spore formation information is mentioned, leave this field empty. DO NOT write "none".>\ncell_wall_characteristics: <Extract all cell wall characteristics mentioned in the text, including structural features (thick/thin, multilayered), chemical components (peptidoglycan, teichoic acids, mycolic acids, lipopolysaccharide), and anatomical features (outer membrane, periplasmic space, S-layer, capsule). If no cell wall characteristics are mentioned, leave this field empty. DO NOT write "none".>\ncellular_inclusions: <Extract all cellular inclusions and internal structures mentioned in the text, including storage granules (PHB, PHA, polyphosphate, glycogen, sulfur, lipid droplets), specialized structures (gas vesicles, magnetosomes, carboxysomes), and other intracellular bodies. If no cellular inclusions are mentioned, leave this field empty. DO NOT write "none".>\ncell_shape_relationships: <For each cell shape extracted above, create strain-to-shape relationships. Link specific strains to their cell shapes (e.g., "DA-C8 has_cell_shape rod-shaped"). Convert ALL cell shapes mentioned above into structured relationships.>\ncell_arrangement_relationships: <For each cell arrangement extracted above, create strain-to-arrangement relationships. Link specific strains to their arrangements (e.g., "DA-C8 has_arrangement chains"). Convert ALL cell arrangements mentioned above into structured relationships.>\ngram_staining_relationships: <For each Gram staining result extracted above, create strain-to-staining relationships. Link specific strains to their staining results (e.g., "DA-C8 has_gram_staining Gram-positive"). Convert ALL Gram staining results mentioned above into structured relationships.>\nmotility_relationships: <For each motility characteristic extracted above, create strain-to-motility relationships. Link specific strains to their motility characteristics (e.g., "DA-C8 has_motility motile"). Convert ALL motility characteristics mentioned above into structured relationships.>\nspore_formation_relationships: <For each spore formation characteristic extracted above, create strain-to-spore relationships. Link specific strains to their spore characteristics (e.g., "DA-C8 has_spore_formation terminal spores"). Convert ALL spore formation characteristics mentioned above into structured relationships.>\ncell_wall_relationships: <For each cell wall characteristic extracted above, create strain-to-cell-wall relationships. Link specific strains to their cell wall features (e.g., "DA-C8 has_cell_wall_feature peptidoglycan"). Convert ALL cell wall characteristics mentioned above into structured relationships.>\ncellular_inclusion_relationships: <For each cellular inclusion extracted above, create strain-to-inclusion relationships. Link specific strains to their cellular inclusions (e.g., "DA-C8 has_inclusion PHB granules"). Convert ALL cellular inclusions mentioned above into structured relationships.>\npigmentation: <Extract all pigmentation and colony color characteristics mentioned in the text, including colors (yellow, orange, red, pink, white, cream, brown, black, green), pigment types (carotenoid, melanin, flexirubin), and properties (diffusible, non-diffusible, fluorescent). If no pigmentation is mentioned, leave this field empty. DO NOT write "none".>\nstrain_relationships: <A semicolon-separated list of strain-species relationships, where each relationship connects a strain to its parent taxon. Each relationship should have a strain name, relationship type, and parent species/genus. For example: "MG1655 strain_of Escherichia coli; K-12 strain_of Escherichia coli; ATCC 25922 type_strain_of Klebsiella pneumoniae". If no strain relationships are found, leave this field empty. DO NOT write "none".>\narticle_type: <The type of study or article. Choose the most appropriate category based on the content.Must be one of: novel_species, novel_genus, taxonomic_revision, phylogenetic_analysis, comparative_taxonomy, emended_description, genome_sequence, review, biochemical_characterization, ecological_study, morphological_characterization, physiology_study>\n\n\nText:\n{\'content\': \'Classification of metal-resistant bacteria from industrial biotopes as Ralstonia campinensis sp. nov., Ralstonia metallidurans sp. nov. and Ralstonia basilensis Steinle et al. 1998 emend.\\n\\nThirty-one heavy-metal-resistant bacteria isolated from industrial biotopes were subjected to polyphasic characterization, including 16S rDNA sequence analysis, DNA-DNA hybridizations, biochemical tests, whole-cell protein and fatty-acid analyses. All strains were shown to belong to the Ralstonia branch of the beta-Proteobacteria. Whole-cell protein profiles and DNA-DNA hybridizations revealed two clearly distinct groups, showing low similarity to known Ralstonia species. These two groups, of 8 and 17 isolates, were assigned to two new species, for which the names Ralstonia campinensis sp. nov. and Ralstonia metallidurans sp. nov. are proposed. The type strains are WS2T (= LMG 19282T = CCUG 44526T) and CH34T (= LMG 1195T = DSM 2839T), respectively. Six isolates were allocated to Ralstonia basilensis, which presently contains only the type strain; an emendation of the latter species description is therefore proposed.\\n\\nPMID:11594608\', \'saved_to\': None, \'windowed\': False}\n\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 0bf77d19dddc6844f7ad3bcb559d78f130123922d1010fb28e4aed74da3e216a
DEBUG:LiteLLM:Final hashed key: 0bf77d19dddc6844f7ad3bcb559d78f130123922d1010fb28e4aed74da3e216a
INFO:LiteLLM:
LiteLLM completion() model= gpt-4o; provider = openai
DEBUG:LiteLLM:
LiteLLM: Params passed to completion() {'model': 'gpt-4o', 'functions': None, 'function_call': None, 'temperature': 1.0, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'From the text below, extract the following entities in the following format:\n\npmid: <PubMed ID of the article (e.g., 23996836)>\nstudy_taxa: <semicolon-separated list of the main bacterial or archaeal taxa being studied for morphology>\nstrains: <Extract ONLY the strain designation part (e.g., "DA-C8", "MG1655", "ATCC 25922") WITHOUT genus/species prefixes. Focus on strain numbers, culture collection codes, and isolate identifiers. Automatically remove terminal "T" or "(T)" suffixes as these indicate type strain status (e.g., "DA-C8T" becomes "DA-C8", "K13T" becomes "K13"). Include strain numbers, culture collection numbers, and isolate names, but NOT the full taxonomic context.>\ncell_shape: <Extract all cell shapes mentioned in the text exactly as described in the literature. Include measurements when provided (e.g., "rod-shaped, 0.5 x 2.0 Î¼m"). If no cell shapes are mentioned, leave this field empty. DO NOT write "none".>\ncell_arrangements: <Extract all cell arrangement patterns mentioned in the text (e.g., single cells, pairs, chains, clusters, tetrads, packets, irregular masses, palisades, V-shapes, angular arrangements). If no cell arrangements are mentioned, leave this field empty. DO NOT write "none".>\ngram_staining: <Extract Gram staining results mentioned in the text (e.g., Gram-positive, Gram-negative, Gram-variable, Gram-indeterminate). Include any additional staining properties mentioned. If no Gram staining information is mentioned, leave this field empty. DO NOT write "none".>\nmotility: <Extract all motility characteristics mentioned in the text, including motility presence (motile/non-motile), motility types (flagellar, gliding, twitching, swarming), and flagella arrangements (polar, peritrichous, monotrichous, lophotrichous, amphitrichous). If no motility information is mentioned, leave this field empty. DO NOT write "none".>\nspore_formation: <Extract all spore formation characteristics mentioned in the text, including spore presence (spore-forming/non-spore-forming), spore types (endospores, conidia, arthrospores), and spore positions (terminal, subterminal, central, lateral). Include sporangium or other structures. If no spore formation information is mentioned, leave this field empty. DO NOT write "none".>\ncell_wall_characteristics: <Extract all cell wall characteristics mentioned in the text, including structural features (thick/thin, multilayered), chemical components (peptidoglycan, teichoic acids, mycolic acids, lipopolysaccharide), and anatomical features (outer membrane, periplasmic space, S-layer, capsule). If no cell wall characteristics are mentioned, leave this field empty. DO NOT write "none".>\ncellular_inclusions: <Extract all cellular inclusions and internal structures mentioned in the text, including storage granules (PHB, PHA, polyphosphate, glycogen, sulfur, lipid droplets), specialized structures (gas vesicles, magnetosomes, carboxysomes), and other intracellular bodies. If no cellular inclusions are mentioned, leave this field empty. DO NOT write "none".>\ncell_shape_relationships: <For each cell shape extracted above, create strain-to-shape relationships. Link specific strains to their cell shapes (e.g., "DA-C8 has_cell_shape rod-shaped"). Convert ALL cell shapes mentioned above into structured relationships.>\ncell_arrangement_relationships: <For each cell arrangement extracted above, create strain-to-arrangement relationships. Link specific strains to their arrangements (e.g., "DA-C8 has_arrangement chains"). Convert ALL cell arrangements mentioned above into structured relationships.>\ngram_staining_relationships: <For each Gram staining result extracted above, create strain-to-staining relationships. Link specific strains to their staining results (e.g., "DA-C8 has_gram_staining Gram-positive"). Convert ALL Gram staining results mentioned above into structured relationships.>\nmotility_relationships: <For each motility characteristic extracted above, create strain-to-motility relationships. Link specific strains to their motility characteristics (e.g., "DA-C8 has_motility motile"). Convert ALL motility characteristics mentioned above into structured relationships.>\nspore_formation_relationships: <For each spore formation characteristic extracted above, create strain-to-spore relationships. Link specific strains to their spore characteristics (e.g., "DA-C8 has_spore_formation terminal spores"). Convert ALL spore formation characteristics mentioned above into structured relationships.>\ncell_wall_relationships: <For each cell wall characteristic extracted above, create strain-to-cell-wall relationships. Link specific strains to their cell wall features (e.g., "DA-C8 has_cell_wall_feature peptidoglycan"). Convert ALL cell wall characteristics mentioned above into structured relationships.>\ncellular_inclusion_relationships: <For each cellular inclusion extracted above, create strain-to-inclusion relationships. Link specific strains to their cellular inclusions (e.g., "DA-C8 has_inclusion PHB granules"). Convert ALL cellular inclusions mentioned above into structured relationships.>\npigmentation: <Extract all pigmentation and colony color characteristics mentioned in the text, including colors (yellow, orange, red, pink, white, cream, brown, black, green), pigment types (carotenoid, melanin, flexirubin), and properties (diffusible, non-diffusible, fluorescent). If no pigmentation is mentioned, leave this field empty. DO NOT write "none".>\nstrain_relationships: <A semicolon-separated list of strain-species relationships, where each relationship connects a strain to its parent taxon. Each relationship should have a strain name, relationship type, and parent species/genus. For example: "MG1655 strain_of Escherichia coli; K-12 strain_of Escherichia coli; ATCC 25922 type_strain_of Klebsiella pneumoniae". If no strain relationships are found, leave this field empty. DO NOT write "none".>\narticle_type: <The type of study or article. Choose the most appropriate category based on the content.Must be one of: novel_species, novel_genus, taxonomic_revision, phylogenetic_analysis, comparative_taxonomy, emended_description, genome_sequence, review, biochemical_characterization, ecological_study, morphological_characterization, physiology_study>\n\n\nText:\n{\'content\': \'Classification of metal-resistant bacteria from industrial biotopes as Ralstonia campinensis sp. nov., Ralstonia metallidurans sp. nov. and Ralstonia basilensis Steinle et al. 1998 emend.\\n\\nThirty-one heavy-metal-resistant bacteria isolated from industrial biotopes were subjected to polyphasic characterization, including 16S rDNA sequence analysis, DNA-DNA hybridizations, biochemical tests, whole-cell protein and fatty-acid analyses. All strains were shown to belong to the Ralstonia branch of the beta-Proteobacteria. Whole-cell protein profiles and DNA-DNA hybridizations revealed two clearly distinct groups, showing low similarity to known Ralstonia species. These two groups, of 8 and 17 isolates, were assigned to two new species, for which the names Ralstonia campinensis sp. nov. and Ralstonia metallidurans sp. nov. are proposed. The type strains are WS2T (= LMG 19282T = CCUG 44526T) and CH34T (= LMG 1195T = DSM 2839T), respectively. Six isolates were allocated to Ralstonia basilensis, which presently contains only the type strain; an emendation of the latter species description is therefore proposed.\\n\\nPMID:11594608\', \'saved_to\': None, \'windowed\': False}\n\n\n===\n\n', 'role': 'user'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
DEBUG:LiteLLM:
LiteLLM: Non-Default params passed to completion() {'temperature': 1.0}
DEBUG:LiteLLM:Final returned optional params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:self.optional_params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o', 'combined_model_name': 'openai/gpt-4o', 'stripped_model_name': 'gpt-4o', 'combined_stripped_model_name': 'openai/gpt-4o', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.cborg.lbl.gov \
-d '{'model': 'gpt-4o', 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'From the text below, extract the following entities in the following format:\n\npmid: <PubMed ID of the article (e.g., 23996836)>\nstudy_taxa: <semicolon-separated list of the main bacterial or archaeal taxa being studied for morphology>\nstrains: <Extract ONLY the strain designation part (e.g., "DA-C8", "MG1655", "ATCC 25922") WITHOUT genus/species prefixes. Focus on strain numbers, culture collection codes, and isolate identifiers. Automatically remove terminal "T" or "(T)" suffixes as these indicate type strain status (e.g., "DA-C8T" becomes "DA-C8", "K13T" becomes "K13"). Include strain numbers, culture collection numbers, and isolate names, but NOT the full taxonomic context.>\ncell_shape: <Extract all cell shapes mentioned in the text exactly as described in the literature. Include measurements when provided (e.g., "rod-shaped, 0.5 x 2.0 Î¼m"). If no cell shapes are mentioned, leave this field empty. DO NOT write "none".>\ncell_arrangements: <Extract all cell arrangement patterns mentioned in the text (e.g., single cells, pairs, chains, clusters, tetrads, packets, irregular masses, palisades, V-shapes, angular arrangements). If no cell arrangements are mentioned, leave this field empty. DO NOT write "none".>\ngram_staining: <Extract Gram staining results mentioned in the text (e.g., Gram-positive, Gram-negative, Gram-variable, Gram-indeterminate). Include any additional staining properties mentioned. If no Gram staining information is mentioned, leave this field empty. DO NOT write "none".>\nmotility: <Extract all motility characteristics mentioned in the text, including motility presence (motile/non-motile), motility types (flagellar, gliding, twitching, swarming), and flagella arrangements (polar, peritrichous, monotrichous, lophotrichous, amphitrichous). If no motility information is mentioned, leave this field empty. DO NOT write "none".>\nspore_formation: <Extract all spore formation characteristics mentioned in the text, including spore presence (spore-forming/non-spore-forming), spore types (endospores, conidia, arthrospores), and spore positions (terminal, subterminal, central, lateral). Include sporangium or other structures. If no spore formation information is mentioned, leave this field empty. DO NOT write "none".>\ncell_wall_characteristics: <Extract all cell wall characteristics mentioned in the text, including structural features (thick/thin, multilayered), chemical components (peptidoglycan, teichoic acids, mycolic acids, lipopolysaccharide), and anatomical features (outer membrane, periplasmic space, S-layer, capsule). If no cell wall characteristics are mentioned, leave this field empty. DO NOT write "none".>\ncellular_inclusions: <Extract all cellular inclusions and internal structures mentioned in the text, including storage granules (PHB, PHA, polyphosphate, glycogen, sulfur, lipid droplets), specialized structures (gas vesicles, magnetosomes, carboxysomes), and other intracellular bodies. If no cellular inclusions are mentioned, leave this field empty. DO NOT write "none".>\ncell_shape_relationships: <For each cell shape extracted above, create strain-to-shape relationships. Link specific strains to their cell shapes (e.g., "DA-C8 has_cell_shape rod-shaped"). Convert ALL cell shapes mentioned above into structured relationships.>\ncell_arrangement_relationships: <For each cell arrangement extracted above, create strain-to-arrangement relationships. Link specific strains to their arrangements (e.g., "DA-C8 has_arrangement chains"). Convert ALL cell arrangements mentioned above into structured relationships.>\ngram_staining_relationships: <For each Gram staining result extracted above, create strain-to-staining relationships. Link specific strains to their staining results (e.g., "DA-C8 has_gram_staining Gram-positive"). Convert ALL Gram staining results mentioned above into structured relationships.>\nmotility_relationships: <For each motility characteristic extracted above, create strain-to-motility relationships. Link specific strains to their motility characteristics (e.g., "DA-C8 has_motility motile"). Convert ALL motility characteristics mentioned above into structured relationships.>\nspore_formation_relationships: <For each spore formation characteristic extracted above, create strain-to-spore relationships. Link specific strains to their spore characteristics (e.g., "DA-C8 has_spore_formation terminal spores"). Convert ALL spore formation characteristics mentioned above into structured relationships.>\ncell_wall_relationships: <For each cell wall characteristic extracted above, create strain-to-cell-wall relationships. Link specific strains to their cell wall features (e.g., "DA-C8 has_cell_wall_feature peptidoglycan"). Convert ALL cell wall characteristics mentioned above into structured relationships.>\ncellular_inclusion_relationships: <For each cellular inclusion extracted above, create strain-to-inclusion relationships. Link specific strains to their cellular inclusions (e.g., "DA-C8 has_inclusion PHB granules"). Convert ALL cellular inclusions mentioned above into structured relationships.>\npigmentation: <Extract all pigmentation and colony color characteristics mentioned in the text, including colors (yellow, orange, red, pink, white, cream, brown, black, green), pigment types (carotenoid, melanin, flexirubin), and properties (diffusible, non-diffusible, fluorescent). If no pigmentation is mentioned, leave this field empty. DO NOT write "none".>\nstrain_relationships: <A semicolon-separated list of strain-species relationships, where each relationship connects a strain to its parent taxon. Each relationship should have a strain name, relationship type, and parent species/genus. For example: "MG1655 strain_of Escherichia coli; K-12 strain_of Escherichia coli; ATCC 25922 type_strain_of Klebsiella pneumoniae". If no strain relationships are found, leave this field empty. DO NOT write "none".>\narticle_type: <The type of study or article. Choose the most appropriate category based on the content.Must be one of: novel_species, novel_genus, taxonomic_revision, phylogenetic_analysis, comparative_taxonomy, emended_description, genome_sequence, review, biochemical_characterization, ecological_study, morphological_characterization, physiology_study>\n\n\nText:\n{\'content\': \'Classification of metal-resistant bacteria from industrial biotopes as Ralstonia campinensis sp. nov., Ralstonia metallidurans sp. nov. and Ralstonia basilensis Steinle et al. 1998 emend.\\n\\nThirty-one heavy-metal-resistant bacteria isolated from industrial biotopes were subjected to polyphasic characterization, including 16S rDNA sequence analysis, DNA-DNA hybridizations, biochemical tests, whole-cell protein and fatty-acid analyses. All strains were shown to belong to the Ralstonia branch of the beta-Proteobacteria. Whole-cell protein profiles and DNA-DNA hybridizations revealed two clearly distinct groups, showing low similarity to known Ralstonia species. These two groups, of 8 and 17 isolates, were assigned to two new species, for which the names Ralstonia campinensis sp. nov. and Ralstonia metallidurans sp. nov. are proposed. The type strains are WS2T (= LMG 19282T = CCUG 44526T) and CH34T (= LMG 1195T = DSM 2839T), respectively. Six isolates were allocated to Ralstonia basilensis, which presently contains only the type strain; an emendation of the latter species description is therefore proposed.\\n\\nPMID:11594608\', \'saved_to\': None, \'windowed\': False}\n\n\n===\n\n', 'role': 'user'}], 'temperature': 1.0, 'extra_body': {}}'
[0m

DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-7526e3a0-0ed4-4739-96fd-5dffd4201889', 'json_data': {'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'From the text below, extract the following entities in the following format:\n\npmid: <PubMed ID of the article (e.g., 23996836)>\nstudy_taxa: <semicolon-separated list of the main bacterial or archaeal taxa being studied for morphology>\nstrains: <Extract ONLY the strain designation part (e.g., "DA-C8", "MG1655", "ATCC 25922") WITHOUT genus/species prefixes. Focus on strain numbers, culture collection codes, and isolate identifiers. Automatically remove terminal "T" or "(T)" suffixes as these indicate type strain status (e.g., "DA-C8T" becomes "DA-C8", "K13T" becomes "K13"). Include strain numbers, culture collection numbers, and isolate names, but NOT the full taxonomic context.>\ncell_shape: <Extract all cell shapes mentioned in the text exactly as described in the literature. Include measurements when provided (e.g., "rod-shaped, 0.5 x 2.0 Î¼m"). If no cell shapes are mentioned, leave this field empty. DO NOT write "none".>\ncell_arrangements: <Extract all cell arrangement patterns mentioned in the text (e.g., single cells, pairs, chains, clusters, tetrads, packets, irregular masses, palisades, V-shapes, angular arrangements). If no cell arrangements are mentioned, leave this field empty. DO NOT write "none".>\ngram_staining: <Extract Gram staining results mentioned in the text (e.g., Gram-positive, Gram-negative, Gram-variable, Gram-indeterminate). Include any additional staining properties mentioned. If no Gram staining information is mentioned, leave this field empty. DO NOT write "none".>\nmotility: <Extract all motility characteristics mentioned in the text, including motility presence (motile/non-motile), motility types (flagellar, gliding, twitching, swarming), and flagella arrangements (polar, peritrichous, monotrichous, lophotrichous, amphitrichous). If no motility information is mentioned, leave this field empty. DO NOT write "none".>\nspore_formation: <Extract all spore formation characteristics mentioned in the text, including spore presence (spore-forming/non-spore-forming), spore types (endospores, conidia, arthrospores), and spore positions (terminal, subterminal, central, lateral). Include sporangium or other structures. If no spore formation information is mentioned, leave this field empty. DO NOT write "none".>\ncell_wall_characteristics: <Extract all cell wall characteristics mentioned in the text, including structural features (thick/thin, multilayered), chemical components (peptidoglycan, teichoic acids, mycolic acids, lipopolysaccharide), and anatomical features (outer membrane, periplasmic space, S-layer, capsule). If no cell wall characteristics are mentioned, leave this field empty. DO NOT write "none".>\ncellular_inclusions: <Extract all cellular inclusions and internal structures mentioned in the text, including storage granules (PHB, PHA, polyphosphate, glycogen, sulfur, lipid droplets), specialized structures (gas vesicles, magnetosomes, carboxysomes), and other intracellular bodies. If no cellular inclusions are mentioned, leave this field empty. DO NOT write "none".>\ncell_shape_relationships: <For each cell shape extracted above, create strain-to-shape relationships. Link specific strains to their cell shapes (e.g., "DA-C8 has_cell_shape rod-shaped"). Convert ALL cell shapes mentioned above into structured relationships.>\ncell_arrangement_relationships: <For each cell arrangement extracted above, create strain-to-arrangement relationships. Link specific strains to their arrangements (e.g., "DA-C8 has_arrangement chains"). Convert ALL cell arrangements mentioned above into structured relationships.>\ngram_staining_relationships: <For each Gram staining result extracted above, create strain-to-staining relationships. Link specific strains to their staining results (e.g., "DA-C8 has_gram_staining Gram-positive"). Convert ALL Gram staining results mentioned above into structured relationships.>\nmotility_relationships: <For each motility characteristic extracted above, create strain-to-motility relationships. Link specific strains to their motility characteristics (e.g., "DA-C8 has_motility motile"). Convert ALL motility characteristics mentioned above into structured relationships.>\nspore_formation_relationships: <For each spore formation characteristic extracted above, create strain-to-spore relationships. Link specific strains to their spore characteristics (e.g., "DA-C8 has_spore_formation terminal spores"). Convert ALL spore formation characteristics mentioned above into structured relationships.>\ncell_wall_relationships: <For each cell wall characteristic extracted above, create strain-to-cell-wall relationships. Link specific strains to their cell wall features (e.g., "DA-C8 has_cell_wall_feature peptidoglycan"). Convert ALL cell wall characteristics mentioned above into structured relationships.>\ncellular_inclusion_relationships: <For each cellular inclusion extracted above, create strain-to-inclusion relationships. Link specific strains to their cellular inclusions (e.g., "DA-C8 has_inclusion PHB granules"). Convert ALL cellular inclusions mentioned above into structured relationships.>\npigmentation: <Extract all pigmentation and colony color characteristics mentioned in the text, including colors (yellow, orange, red, pink, white, cream, brown, black, green), pigment types (carotenoid, melanin, flexirubin), and properties (diffusible, non-diffusible, fluorescent). If no pigmentation is mentioned, leave this field empty. DO NOT write "none".>\nstrain_relationships: <A semicolon-separated list of strain-species relationships, where each relationship connects a strain to its parent taxon. Each relationship should have a strain name, relationship type, and parent species/genus. For example: "MG1655 strain_of Escherichia coli; K-12 strain_of Escherichia coli; ATCC 25922 type_strain_of Klebsiella pneumoniae". If no strain relationships are found, leave this field empty. DO NOT write "none".>\narticle_type: <The type of study or article. Choose the most appropriate category based on the content.Must be one of: novel_species, novel_genus, taxonomic_revision, phylogenetic_analysis, comparative_taxonomy, emended_description, genome_sequence, review, biochemical_characterization, ecological_study, morphological_characterization, physiology_study>\n\n\nText:\n{\'content\': \'Classification of metal-resistant bacteria from industrial biotopes as Ralstonia campinensis sp. nov., Ralstonia metallidurans sp. nov. and Ralstonia basilensis Steinle et al. 1998 emend.\\n\\nThirty-one heavy-metal-resistant bacteria isolated from industrial biotopes were subjected to polyphasic characterization, including 16S rDNA sequence analysis, DNA-DNA hybridizations, biochemical tests, whole-cell protein and fatty-acid analyses. All strains were shown to belong to the Ralstonia branch of the beta-Proteobacteria. Whole-cell protein profiles and DNA-DNA hybridizations revealed two clearly distinct groups, showing low similarity to known Ralstonia species. These two groups, of 8 and 17 isolates, were assigned to two new species, for which the names Ralstonia campinensis sp. nov. and Ralstonia metallidurans sp. nov. are proposed. The type strains are WS2T (= LMG 19282T = CCUG 44526T) and CH34T (= LMG 1195T = DSM 2839T), respectively. Six isolates were allocated to Ralstonia basilensis, which presently contains only the type strain; an emendation of the latter species description is therefore proposed.\\n\\nPMID:11594608\', \'saved_to\': None, \'windowed\': False}\n\n\n===\n\n', 'role': 'user'}], 'model': 'gpt-4o', 'temperature': 1.0}, 'extra_json': {}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.cborg.lbl.gov/chat/completions
DEBUG:httpcore.connection:connect_tcp.started host='api.cborg.lbl.gov' port=443 local_address=None timeout=600.0 socket_options=None
DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x114d32fd0>
DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x11473c050> server_hostname='api.cborg.lbl.gov' timeout=600.0
DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x114d32f90>
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 30 Oct 2025 21:43:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'llm_provider-apim-request-id', b'c7e5d65b-aca7-4aeb-a6d8-2209b1c7c4b7'), (b'llm_provider-azureml-model-session', b'd015-20251018173616'), (b'llm_provider-content-length', b'1859'), (b'llm_provider-content-type', b'application/json'), (b'llm_provider-date', b'Thu, 30 Oct 2025 21:43:20 GMT'), (b'llm_provider-strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'llm_provider-x-accel-buffering', b'no'), (b'llm_provider-x-content-type-options', b'nosniff'), (b'llm_provider-x-ms-deployment-name', b'gpt-4o'), (b'llm_provider-x-ms-rai-invoked', b'true'), (b'llm_provider-x-ms-region', b'East US'), (b'llm_provider-x-ratelimit-limit-requests', b'150'), (b'llm_provider-x-ratelimit-limit-tokens', b'150000'), (b'llm_provider-x-ratelimit-remaining-requests', b'146'), (b'llm_provider-x-ratelimit-remaining-tokens', b'140273'), (b'llm_provider-x-request-id', b'ac9c3c83-5c9c-4f90-a481-f727a2cff9ae'), (b'Server', b'cloudflare'), (b'x-litellm-attempted-fallbacks', b'0'), (b'x-litellm-attempted-retries', b'0'), (b'x-litellm-call-id', b'8f942371-a7d5-4901-ae6a-13484dfcd65c'), (b'x-litellm-key-spend', b'32.69455805000004'), (b'x-litellm-model-api-base', b'https://science-it-openai.openai.azure.com/'), (b'x-litellm-model-group', b'gpt-4o'), (b'x-litellm-model-id', b'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38'), (b'x-litellm-overhead-duration-ms', b'1.328'), (b'x-litellm-response-cost', b'0.006787500000000001'), (b'x-litellm-response-cost-discount-amount', b'0.0'), (b'x-litellm-response-cost-original', b'0.006787500000000001'), (b'x-litellm-response-duration-ms', b'2064.789'), (b'x-litellm-version', b'1.79.0'), (b'x-ratelimit-limit-requests', b'150'), (b'x-ratelimit-limit-tokens', b'150000'), (b'x-ratelimit-remaining-requests', b'146'), (b'x-ratelimit-remaining-tokens', b'140273'), (b'cf-cache-status', b'DYNAMIC'), (b'vary', b'accept-encoding'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'Set-Cookie', b'__cf_bm=kwRPVK.A3IFnvytHHGx5PAaDzOuz8ZVTkDsc6clQOJc-1761860598.8789163-1.0.1.1-ULWGkIFlJGX5rOWzFQ1As9.loV43sihwdABx6rWOMv2Cax4WVEy3gAVmBXK.Tjhf_wXsOKfhcUVv6YLss4PeeNo0tErWchWvtLhrVyGlJ1_Mz3vYbpup0lhesUkL.sX5; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:13:21 GMT'), (b'Set-Cookie', b'_cfuvid=AdvfdI1QiFK7rgr39bD4NLGSeAxAZwMC2ZThOaQizOI-1761860598.8789163-1.0.1.1-59qRtElNkaQ5JDyqzZTurHF7zY8LOEVEspWTva6j5W0; HttpOnly; SameSite=None; Secure; Path=/; Domain=api.cborg.lbl.gov'), (b'CF-RAY', b'996e1666fcd2862e-EWR')])
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.cborg.lbl.gov/chat/completions "200 OK" Headers([('date', 'Thu, 30 Oct 2025 21:43:21 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('content-encoding', 'gzip'), ('llm_provider-apim-request-id', 'c7e5d65b-aca7-4aeb-a6d8-2209b1c7c4b7'), ('llm_provider-azureml-model-session', 'd015-20251018173616'), ('llm_provider-content-length', '1859'), ('llm_provider-content-type', 'application/json'), ('llm_provider-date', 'Thu, 30 Oct 2025 21:43:20 GMT'), ('llm_provider-strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('llm_provider-x-accel-buffering', 'no'), ('llm_provider-x-content-type-options', 'nosniff'), ('llm_provider-x-ms-deployment-name', 'gpt-4o'), ('llm_provider-x-ms-rai-invoked', 'true'), ('llm_provider-x-ms-region', 'East US'), ('llm_provider-x-ratelimit-limit-requests', '150'), ('llm_provider-x-ratelimit-limit-tokens', '150000'), ('llm_provider-x-ratelimit-remaining-requests', '146'), ('llm_provider-x-ratelimit-remaining-tokens', '140273'), ('llm_provider-x-request-id', 'ac9c3c83-5c9c-4f90-a481-f727a2cff9ae'), ('server', 'cloudflare'), ('x-litellm-attempted-fallbacks', '0'), ('x-litellm-attempted-retries', '0'), ('x-litellm-call-id', '8f942371-a7d5-4901-ae6a-13484dfcd65c'), ('x-litellm-key-spend', '32.69455805000004'), ('x-litellm-model-api-base', 'https://science-it-openai.openai.azure.com/'), ('x-litellm-model-group', 'gpt-4o'), ('x-litellm-model-id', 'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38'), ('x-litellm-overhead-duration-ms', '1.328'), ('x-litellm-response-cost', '0.006787500000000001'), ('x-litellm-response-cost-discount-amount', '0.0'), ('x-litellm-response-cost-original', '0.006787500000000001'), ('x-litellm-response-duration-ms', '2064.789'), ('x-litellm-version', '1.79.0'), ('x-ratelimit-limit-requests', '150'), ('x-ratelimit-limit-tokens', '150000'), ('x-ratelimit-remaining-requests', '146'), ('x-ratelimit-remaining-tokens', '140273'), ('cf-cache-status', 'DYNAMIC'), ('vary', 'accept-encoding'), ('strict-transport-security', 'max-age=31536000'), ('set-cookie', '__cf_bm=kwRPVK.A3IFnvytHHGx5PAaDzOuz8ZVTkDsc6clQOJc-1761860598.8789163-1.0.1.1-ULWGkIFlJGX5rOWzFQ1As9.loV43sihwdABx6rWOMv2Cax4WVEy3gAVmBXK.Tjhf_wXsOKfhcUVv6YLss4PeeNo0tErWchWvtLhrVyGlJ1_Mz3vYbpup0lhesUkL.sX5; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:13:21 GMT'), ('set-cookie', '_cfuvid=AdvfdI1QiFK7rgr39bD4NLGSeAxAZwMC2ZThOaQizOI-1761860598.8789163-1.0.1.1-59qRtElNkaQ5JDyqzZTurHF7zY8LOEVEspWTva6j5W0; HttpOnly; SameSite=None; Secure; Path=/; Domain=api.cborg.lbl.gov'), ('cf-ray', '996e1666fcd2862e-EWR')])
DEBUG:openai._base_client:request_id: None
DEBUG:asyncio:Using selector: KqueueSelector
DEBUG:LiteLLM:RAW RESPONSE:
{"id": "chatcmpl-CWUiN0MrsrdohCJ07lqYhdoSv61v5", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "pmid: 11594608\nstudy_taxa: Ralstonia\nstrains: WS2; LMG 19282; CCUG 44526; CH34; LMG 1195; DSM 2839\ncell_shape: \ncell_arrangements: \ngram_staining: \nmotility: \nspore_formation: \ncell_wall_characteristics: \ncellular_inclusions: \ncell_shape_relationships: \ncell_arrangement_relationships: \ngram_staining_relationships: \nmotility_relationships: \nspore_formation_relationships: \ncell_wall_relationships: \ncellular_inclusion_relationships: \npigmentation: \nstrain_relationships: WS2 type_strain_of Ralstonia campinensis; LMG 19282 type_strain_of Ralstonia campinensis; CCUG 44526 type_strain_of Ralstonia campinensis; CH34 type_strain_of Ralstonia metallidurans; LMG 1195 type_strain_of Ralstonia metallidurans; DSM 2839 type_strain_of Ralstonia metallidurans\narticle_type: novel_species; emended_description", "refusal": null, "role": "assistant", "annotations": [], "audio": null, "function_call": null, "tool_calls": null}, "provider_specific_fields": {"content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}}], "created": 1761860599, "model": "gpt-4o-2024-08-06", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_4a331a0222", "usage": {"completion_tokens": 246, "prompt_tokens": 1731, "total_tokens": 1977, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}


DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'From the text below, extract the following entities in the following format:\n\npmid: <PubMed ID of the article (e.g., 23996836)>\nstudy_taxa: <semicolon-separated list of the main bacterial or archaeal taxa being studied for morphology>\nstrains: <Extract ONLY the strain designation part (e.g., "DA-C8", "MG1655", "ATCC 25922") WITHOUT genus/species prefixes. Focus on strain numbers, culture collection codes, and isolate identifiers. Automatically remove terminal "T" or "(T)" suffixes as these indicate type strain status (e.g., "DA-C8T" becomes "DA-C8", "K13T" becomes "K13"). Include strain numbers, culture collection numbers, and isolate names, but NOT the full taxonomic context.>\ncell_shape: <Extract all cell shapes mentioned in the text exactly as described in the literature. Include measurements when provided (e.g., "rod-shaped, 0.5 x 2.0 Î¼m"). If no cell shapes are mentioned, leave this field empty. DO NOT write "none".>\ncell_arrangements: <Extract all cell arrangement patterns mentioned in the text (e.g., single cells, pairs, chains, clusters, tetrads, packets, irregular masses, palisades, V-shapes, angular arrangements). If no cell arrangements are mentioned, leave this field empty. DO NOT write "none".>\ngram_staining: <Extract Gram staining results mentioned in the text (e.g., Gram-positive, Gram-negative, Gram-variable, Gram-indeterminate). Include any additional staining properties mentioned. If no Gram staining information is mentioned, leave this field empty. DO NOT write "none".>\nmotility: <Extract all motility characteristics mentioned in the text, including motility presence (motile/non-motile), motility types (flagellar, gliding, twitching, swarming), and flagella arrangements (polar, peritrichous, monotrichous, lophotrichous, amphitrichous). If no motility information is mentioned, leave this field empty. DO NOT write "none".>\nspore_formation: <Extract all spore formation characteristics mentioned in the text, including spore presence (spore-forming/non-spore-forming), spore types (endospores, conidia, arthrospores), and spore positions (terminal, subterminal, central, lateral). Include sporangium or other structures. If no spore formation information is mentioned, leave this field empty. DO NOT write "none".>\ncell_wall_characteristics: <Extract all cell wall characteristics mentioned in the text, including structural features (thick/thin, multilayered), chemical components (peptidoglycan, teichoic acids, mycolic acids, lipopolysaccharide), and anatomical features (outer membrane, periplasmic space, S-layer, capsule). If no cell wall characteristics are mentioned, leave this field empty. DO NOT write "none".>\ncellular_inclusions: <Extract all cellular inclusions and internal structures mentioned in the text, including storage granules (PHB, PHA, polyphosphate, glycogen, sulfur, lipid droplets), specialized structures (gas vesicles, magnetosomes, carboxysomes), and other intracellular bodies. If no cellular inclusions are mentioned, leave this field empty. DO NOT write "none".>\ncell_shape_relationships: <For each cell shape extracted above, create strain-to-shape relationships. Link specific strains to their cell shapes (e.g., "DA-C8 has_cell_shape rod-shaped"). Convert ALL cell shapes mentioned above into structured relationships.>\ncell_arrangement_relationships: <For each cell arrangement extracted above, create strain-to-arrangement relationships. Link specific strains to their arrangements (e.g., "DA-C8 has_arrangement chains"). Convert ALL cell arrangements mentioned above into structured relationships.>\ngram_staining_relationships: <For each Gram staining result extracted above, create strain-to-staining relationships. Link specific strains to their staining results (e.g., "DA-C8 has_gram_staining Gram-positive"). Convert ALL Gram staining results mentioned above into structured relationships.>\nmotility_relationships: <For each motility characteristic extracted above, create strain-to-motility relationships. Link specific strains to their motility characteristics (e.g., "DA-C8 has_motility motile"). Convert ALL motility characteristics mentioned above into structured relationships.>\nspore_formation_relationships: <For each spore formation characteristic extracted above, create strain-to-spore relationships. Link specific strains to their spore characteristics (e.g., "DA-C8 has_spore_formation terminal spores"). Convert ALL spore formation characteristics mentioned above into structured relationships.>\ncell_wall_relationships: <For each cell wall characteristic extracted above, create strain-to-cell-wall relationships. Link specific strains to their cell wall features (e.g., "DA-C8 has_cell_wall_feature peptidoglycan"). Convert ALL cell wall characteristics mentioned above into structured relationships.>\ncellular_inclusion_relationships: <For each cellular inclusion extracted above, create strain-to-inclusion relationships. Link specific strains to their cellular inclusions (e.g., "DA-C8 has_inclusion PHB granules"). Convert ALL cellular inclusions mentioned above into structured relationships.>\npigmentation: <Extract all pigmentation and colony color characteristics mentioned in the text, including colors (yellow, orange, red, pink, white, cream, brown, black, green), pigment types (carotenoid, melanin, flexirubin), and properties (diffusible, non-diffusible, fluorescent). If no pigmentation is mentioned, leave this field empty. DO NOT write "none".>\nstrain_relationships: <A semicolon-separated list of strain-species relationships, where each relationship connects a strain to its parent taxon. Each relationship should have a strain name, relationship type, and parent species/genus. For example: "MG1655 strain_of Escherichia coli; K-12 strain_of Escherichia coli; ATCC 25922 type_strain_of Klebsiella pneumoniae". If no strain relationships are found, leave this field empty. DO NOT write "none".>\narticle_type: <The type of study or article. Choose the most appropriate category based on the content.Must be one of: novel_species, novel_genus, taxonomic_revision, phylogenetic_analysis, comparative_taxonomy, emended_description, genome_sequence, review, biochemical_characterization, ecological_study, morphological_characterization, physiology_study>\n\n\nText:\n{\'content\': \'Classification of metal-resistant bacteria from industrial biotopes as Ralstonia campinensis sp. nov., Ralstonia metallidurans sp. nov. and Ralstonia basilensis Steinle et al. 1998 emend.\\n\\nThirty-one heavy-metal-resistant bacteria isolated from industrial biotopes were subjected to polyphasic characterization, including 16S rDNA sequence analysis, DNA-DNA hybridizations, biochemical tests, whole-cell protein and fatty-acid analyses. All strains were shown to belong to the Ralstonia branch of the beta-Proteobacteria. Whole-cell protein profiles and DNA-DNA hybridizations revealed two clearly distinct groups, showing low similarity to known Ralstonia species. These two groups, of 8 and 17 isolates, were assigned to two new species, for which the names Ralstonia campinensis sp. nov. and Ralstonia metallidurans sp. nov. are proposed. The type strains are WS2T (= LMG 19282T = CCUG 44526T) and CH34T (= LMG 1195T = DSM 2839T), respectively. Six isolates were allocated to Ralstonia basilensis, which presently contains only the type strain; an emendation of the latter species description is therefore proposed.\\n\\nPMID:11594608\', \'saved_to\': None, \'windowed\': False}\n\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 0bf77d19dddc6844f7ad3bcb559d78f130123922d1010fb28e4aed74da3e216a
DEBUG:LiteLLM:Final hashed key: 0bf77d19dddc6844f7ad3bcb559d78f130123922d1010fb28e4aed74da3e216a
INFO:LiteLLM:Wrapper: Completed Call, calling success_handler
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call: Cache_hit=None
DEBUG:LiteLLM:response_cost: 0.006787500000000001
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call streaming complete
DEBUG:LiteLLM:response_cost: 0.006787500000000001
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:LiteLLM:response_cost: 0.006787500000000001
INFO:root:RAW TEXT: pmid: 11594608
study_taxa: Ralstonia
strains: WS2; LMG 19282; CCUG 44526; CH34; LMG 1195; DSM 2839
cell_shape: 
cell_arrangements: 
gram_staining: 
motility: 
spore_formation: 
cell_wall_characteristics: 
cellular_inclusions: 
cell_shape_relationships: 
cell_arrangement_relationships: 
gram_staining_relationships: 
motility_relationships: 
spore_formation_relationships: 
cell_wall_relationships: 
cellular_inclusion_relationships: 
pigmentation: 
strain_relationships: WS2 type_strain_of Ralstonia campinensis; LMG 19282 type_strain_of Ralstonia campinensis; CCUG 44526 type_strain_of Ralstonia campinensis; CH34 type_strain_of Ralstonia metallidurans; LMG 1195 type_strain_of Ralstonia metallidurans; DSM 2839 type_strain_of Ralstonia metallidurans
article_type: novel_species; emended_description
INFO:root:PARSING LINE: pmid: 11594608
DEBUG:root:  FIELD: pmid
DEBUG:root:SLOT: pmid INL: None VALS: ['11594608']
INFO:root:PARSING LINE: study_taxa: Ralstonia
DEBUG:root:  FIELD: study_taxa
DEBUG:root:SLOT: study_taxa INL: False VALS: ['Ralstonia']
INFO:root:PARSING LINE: strains: WS2; LMG 19282; CCUG 44526; CH34; LMG 1195; DSM 2839
DEBUG:root:  FIELD: strains
DEBUG:root:SLOT: strains INL: False VALS: ['WS2', 'LMG 19282', 'CCUG 44526', 'CH34', 'LMG 1195', 'DSM 2839']
INFO:root:This line looks empty, assuming continuation: cell_shape:
INFO:root:This line looks empty, assuming continuation: cell_arrangements:
INFO:root:Finishing previous continued line: cell_shape:
INFO:root:PARSING LINE: cell_shape:
DEBUG:root:  FIELD: cell_shape
INFO:root:This line looks empty, assuming continuation: gram_staining:
INFO:root:Finishing previous continued line: cell_arrangements:
INFO:root:PARSING LINE: cell_arrangements:
DEBUG:root:  FIELD: cell_arrangements
INFO:root:This line looks empty, assuming continuation: motility:
INFO:root:Finishing previous continued line: gram_staining:
INFO:root:PARSING LINE: gram_staining:
DEBUG:root:  FIELD: gram_staining
INFO:root:This line looks empty, assuming continuation: spore_formation:
INFO:root:Finishing previous continued line: motility:
INFO:root:PARSING LINE: motility:
DEBUG:root:  FIELD: motility
INFO:root:This line looks empty, assuming continuation: cell_wall_characteristics:
INFO:root:Finishing previous continued line: spore_formation:
INFO:root:PARSING LINE: spore_formation:
DEBUG:root:  FIELD: spore_formation
INFO:root:This line looks empty, assuming continuation: cellular_inclusions:
INFO:root:Finishing previous continued line: cell_wall_characteristics:
INFO:root:PARSING LINE: cell_wall_characteristics:
DEBUG:root:  FIELD: cell_wall_characteristics
INFO:root:This line looks empty, assuming continuation: cell_shape_relationships:
INFO:root:Finishing previous continued line: cellular_inclusions:
INFO:root:PARSING LINE: cellular_inclusions:
DEBUG:root:  FIELD: cellular_inclusions
INFO:root:This line looks empty, assuming continuation: cell_arrangement_relationships:
INFO:root:Finishing previous continued line: cell_shape_relationships:
INFO:root:PARSING LINE: cell_shape_relationships:
DEBUG:root:  FIELD: cell_shape_relationships
INFO:root:This line looks empty, assuming continuation: gram_staining_relationships:
INFO:root:Finishing previous continued line: cell_arrangement_relationships:
INFO:root:PARSING LINE: cell_arrangement_relationships:
DEBUG:root:  FIELD: cell_arrangement_relationships
INFO:root:This line looks empty, assuming continuation: motility_relationships:
INFO:root:Finishing previous continued line: gram_staining_relationships:
INFO:root:PARSING LINE: gram_staining_relationships:
DEBUG:root:  FIELD: gram_staining_relationships
INFO:root:This line looks empty, assuming continuation: spore_formation_relationships:
INFO:root:Finishing previous continued line: motility_relationships:
INFO:root:PARSING LINE: motility_relationships:
DEBUG:root:  FIELD: motility_relationships
INFO:root:This line looks empty, assuming continuation: cell_wall_relationships:
INFO:root:Finishing previous continued line: spore_formation_relationships:
INFO:root:PARSING LINE: spore_formation_relationships:
DEBUG:root:  FIELD: spore_formation_relationships
INFO:root:This line looks empty, assuming continuation: cellular_inclusion_relationships:
INFO:root:Finishing previous continued line: cell_wall_relationships:
INFO:root:PARSING LINE: cell_wall_relationships:
DEBUG:root:  FIELD: cell_wall_relationships
INFO:root:This line looks empty, assuming continuation: pigmentation:
INFO:root:Finishing previous continued line: cellular_inclusion_relationships:
INFO:root:PARSING LINE: cellular_inclusion_relationships:
DEBUG:root:  FIELD: cellular_inclusion_relationships
INFO:root:PARSING LINE: pigmentation:
DEBUG:root:  FIELD: pigmentation
INFO:root:PARSING LINE: article_type: novel_species; emended_description
DEBUG:root:  FIELD: article_type
DEBUG:root:SLOT: article_type INL: None VALS: ['novel_species; emended_description']
DEBUG:root:RAW: {'pmid': '11594608', 'study_taxa': ['Ralstonia'], 'strains': ['WS2', 'LMG 19282', 'CCUG 44526', 'CH34', 'LMG 1195', 'DSM 2839'], 'article_type': 'novel_species; emended_description'}
DEBUG:root:Grounding annotation object {'pmid': '11594608', 'study_taxa': ['Ralstonia'], 'strains': ['WS2', 'LMG 19282', 'CCUG 44526', 'CH34', 'LMG 1195', 'DSM 2839'], 'article_type': 'novel_species; emended_description'}
DEBUG:root:FIELD: pmid SLOT: pmid
DEBUG:root:   VAL: 11594608
DEBUG:root:FIELD: study_taxa SLOT: study_taxa
DEBUG:root:   VAL: Ralstonia
INFO:ontogpt.engines.knowledge_engine:GROUNDING Ralstonia using Taxon
INFO:ontogpt.engines.knowledge_engine:Singularized Ralstonia to ralstonium
INFO:ontogpt.engines.knowledge_engine:GROUNDING ralstonium using Taxon
INFO:ontogpt.engines.knowledge_engine:Loading annotator sqlite:obo:ncbitaxon
INFO:root:Locator: obo:ncbitaxon
INFO:root:Ensuring gunzipped for https://s3.amazonaws.com/bbop-sqlite/ncbitaxon.db.gz
INFO:root:Locator, post-processed: sqlite:////Users/MAM/.data/oaklib/ncbitaxon.db
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:BEGIN (implicit)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[generated in 0.00024s] ('rdfs:label', 'ralstonium')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 14.15s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'ralstonium')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 19.89s ago] ('rdfs:label', 'Ralstonia')
INFO:sqlalchemy.engine.Engine:SELECT rdfs_label_statement.value AS rdfs_label_statement_value 
FROM rdfs_label_statement 
WHERE rdfs_label_statement.subject = ?
INFO:sqlalchemy.engine.Engine:[generated in 0.00037s] ('NCBITaxon:48736',)
INFO:ontogpt.engines.knowledge_engine:Grounding Ralstonia to NCBITaxon:48736; next step is to normalize
INFO:ontogpt.engines.knowledge_engine:Normalized Ralstonia with NCBITaxon:48736 to NCBITaxon:48736
DEBUG:root:FIELD: strains SLOT: strains
DEBUG:root:   VAL: WS2
INFO:ontogpt.engines.knowledge_engine:GROUNDING WS2 using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize WS2 to Strain
DEBUG:root:   VAL: LMG 19282
INFO:ontogpt.engines.knowledge_engine:GROUNDING LMG 19282 using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize LMG 19282 to Strain
DEBUG:root:   VAL: CCUG 44526
INFO:ontogpt.engines.knowledge_engine:GROUNDING CCUG 44526 using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize CCUG 44526 to Strain
DEBUG:root:   VAL: CH34
INFO:ontogpt.engines.knowledge_engine:GROUNDING CH34 using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize CH34 to Strain
DEBUG:root:   VAL: LMG 1195
INFO:ontogpt.engines.knowledge_engine:GROUNDING LMG 1195 using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize LMG 1195 to Strain
DEBUG:root:   VAL: DSM 2839
INFO:ontogpt.engines.knowledge_engine:GROUNDING DSM 2839 using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize DSM 2839 to Strain
DEBUG:root:FIELD: article_type SLOT: article_type
DEBUG:root:   VAL: novel_species; emended_description
INFO:root:Looking for novel_species; emended_description in ArticleType
INFO:root:Cannot find enum value for novel_species; emended_description in ArticleType
DEBUG:root:Creating object from dict {'pmid': '11594608', 'study_taxa': ['NCBITaxon:48736'], 'strains': ['AUTO:WS2', 'AUTO:LMG%2019282', 'AUTO:CCUG%2044526', 'AUTO:CH34', 'AUTO:LMG%201195', 'AUTO:DSM%202839'], 'article_type': None}
INFO:root:{'pmid': '11594608', 'study_taxa': ['NCBITaxon:48736'], 'strains': ['AUTO:WS2', 'AUTO:LMG%2019282', 'AUTO:CCUG%2044526', 'AUTO:CH34', 'AUTO:LMG%201195', 'AUTO:DSM%202839'], 'article_type': None}
INFO:root:Output format: yaml
INFO:root:Now extracting from file 2 of 3
INFO:root:Cleaning text...
INFO:ontogpt.clients.llm_client:Complete: engine=gpt-4o, prompt[7553]=From the text below, extract the following entities in the following format:

pmid: <PubMed ID of th...
DEBUG:LiteLLM:

DEBUG:LiteLLM:[92mRequest to litellm:[0m
DEBUG:LiteLLM:[92mlitellm.completion(api_key='', api_base='https://api.cborg.lbl.gov', api_version=None, model='gpt-4o', messages=[{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'From the text below, extract the following entities in the following format:\n\npmid: <PubMed ID of the article (e.g., 23996836)>\nstudy_taxa: <semicolon-separated list of the main bacterial or archaeal taxa being studied for morphology>\nstrains: <Extract ONLY the strain designation part (e.g., "DA-C8", "MG1655", "ATCC 25922") WITHOUT genus/species prefixes. Focus on strain numbers, culture collection codes, and isolate identifiers. Automatically remove terminal "T" or "(T)" suffixes as these indicate type strain status (e.g., "DA-C8T" becomes "DA-C8", "K13T" becomes "K13"). Include strain numbers, culture collection numbers, and isolate names, but NOT the full taxonomic context.>\ncell_shape: <Extract all cell shapes mentioned in the text exactly as described in the literature. Include measurements when provided (e.g., "rod-shaped, 0.5 x 2.0 Î¼m"). If no cell shapes are mentioned, leave this field empty. DO NOT write "none".>\ncell_arrangements: <Extract all cell arrangement patterns mentioned in the text (e.g., single cells, pairs, chains, clusters, tetrads, packets, irregular masses, palisades, V-shapes, angular arrangements). If no cell arrangements are mentioned, leave this field empty. DO NOT write "none".>\ngram_staining: <Extract Gram staining results mentioned in the text (e.g., Gram-positive, Gram-negative, Gram-variable, Gram-indeterminate). Include any additional staining properties mentioned. If no Gram staining information is mentioned, leave this field empty. DO NOT write "none".>\nmotility: <Extract all motility characteristics mentioned in the text, including motility presence (motile/non-motile), motility types (flagellar, gliding, twitching, swarming), and flagella arrangements (polar, peritrichous, monotrichous, lophotrichous, amphitrichous). If no motility information is mentioned, leave this field empty. DO NOT write "none".>\nspore_formation: <Extract all spore formation characteristics mentioned in the text, including spore presence (spore-forming/non-spore-forming), spore types (endospores, conidia, arthrospores), and spore positions (terminal, subterminal, central, lateral). Include sporangium or other structures. If no spore formation information is mentioned, leave this field empty. DO NOT write "none".>\ncell_wall_characteristics: <Extract all cell wall characteristics mentioned in the text, including structural features (thick/thin, multilayered), chemical components (peptidoglycan, teichoic acids, mycolic acids, lipopolysaccharide), and anatomical features (outer membrane, periplasmic space, S-layer, capsule). If no cell wall characteristics are mentioned, leave this field empty. DO NOT write "none".>\ncellular_inclusions: <Extract all cellular inclusions and internal structures mentioned in the text, including storage granules (PHB, PHA, polyphosphate, glycogen, sulfur, lipid droplets), specialized structures (gas vesicles, magnetosomes, carboxysomes), and other intracellular bodies. If no cellular inclusions are mentioned, leave this field empty. DO NOT write "none".>\ncell_shape_relationships: <For each cell shape extracted above, create strain-to-shape relationships. Link specific strains to their cell shapes (e.g., "DA-C8 has_cell_shape rod-shaped"). Convert ALL cell shapes mentioned above into structured relationships.>\ncell_arrangement_relationships: <For each cell arrangement extracted above, create strain-to-arrangement relationships. Link specific strains to their arrangements (e.g., "DA-C8 has_arrangement chains"). Convert ALL cell arrangements mentioned above into structured relationships.>\ngram_staining_relationships: <For each Gram staining result extracted above, create strain-to-staining relationships. Link specific strains to their staining results (e.g., "DA-C8 has_gram_staining Gram-positive"). Convert ALL Gram staining results mentioned above into structured relationships.>\nmotility_relationships: <For each motility characteristic extracted above, create strain-to-motility relationships. Link specific strains to their motility characteristics (e.g., "DA-C8 has_motility motile"). Convert ALL motility characteristics mentioned above into structured relationships.>\nspore_formation_relationships: <For each spore formation characteristic extracted above, create strain-to-spore relationships. Link specific strains to their spore characteristics (e.g., "DA-C8 has_spore_formation terminal spores"). Convert ALL spore formation characteristics mentioned above into structured relationships.>\ncell_wall_relationships: <For each cell wall characteristic extracted above, create strain-to-cell-wall relationships. Link specific strains to their cell wall features (e.g., "DA-C8 has_cell_wall_feature peptidoglycan"). Convert ALL cell wall characteristics mentioned above into structured relationships.>\ncellular_inclusion_relationships: <For each cellular inclusion extracted above, create strain-to-inclusion relationships. Link specific strains to their cellular inclusions (e.g., "DA-C8 has_inclusion PHB granules"). Convert ALL cellular inclusions mentioned above into structured relationships.>\npigmentation: <Extract all pigmentation and colony color characteristics mentioned in the text, including colors (yellow, orange, red, pink, white, cream, brown, black, green), pigment types (carotenoid, melanin, flexirubin), and properties (diffusible, non-diffusible, fluorescent). If no pigmentation is mentioned, leave this field empty. DO NOT write "none".>\nstrain_relationships: <A semicolon-separated list of strain-species relationships, where each relationship connects a strain to its parent taxon. Each relationship should have a strain name, relationship type, and parent species/genus. For example: "MG1655 strain_of Escherichia coli; K-12 strain_of Escherichia coli; ATCC 25922 type_strain_of Klebsiella pneumoniae". If no strain relationships are found, leave this field empty. DO NOT write "none".>\narticle_type: <The type of study or article. Choose the most appropriate category based on the content.Must be one of: novel_species, novel_genus, taxonomic_revision, phylogenetic_analysis, comparative_taxonomy, emended_description, genome_sequence, review, biochemical_characterization, ecological_study, morphological_characterization, physiology_study>\n\n\nText:\n{\'content\': \'Application of AFLP for taxonomic and epidemiological studies of Photobacterium damselae subsp. piscicida.\\n\\nA collection of 106 Photobacterium damselae subsp. piscicida strains and 19 Photobacterium damselae subsp. damselae strains, including reference and type strains, were genetically characterized using AFLP. The total genomic DNA of each bacterial strain was digested using restriction endonucleases HindIII and TaqI. Using numerical analysis, six clusters were recognized. The largest cluster (n = 106) contained the majority of the strains tested and consisted exclusively of Photobacterium damselae subsp. piscicida. The Photobacterium damselae subsp. damselae strains fell outside this cluster. DNA-DNA hybridization experiments showed 77% DNA binding between the two subspecies, indicating a close genetic relationship. This clearly demonstrates the applicability of AFLP in studying the taxonomic position of Photobacterium damselae subsp. piscicida. In addition, AFLP proved to be a useful genotypic technique for epidemiological surveys of the pathogen, since it was able to discriminate between Mediterranean and Japanese Photobacterium damselae subsp. piscicida isolates.\\n\\nPMID:10843040\', \'saved_to\': None, \'windowed\': False}\n\n\n===\n\n', 'role': 'user'}], temperature=1.0, caching=True, custom_llm_provider='openai')[0m
DEBUG:LiteLLM:

DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:SYNC kwargs[caching]: True; litellm.cache: <litellm.caching.caching.Cache object at 0x105624f90>; kwargs.get('cache')['no-cache']: False
DEBUG:LiteLLM:INSIDE CHECKING SYNC CACHE
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'From the text below, extract the following entities in the following format:\n\npmid: <PubMed ID of the article (e.g., 23996836)>\nstudy_taxa: <semicolon-separated list of the main bacterial or archaeal taxa being studied for morphology>\nstrains: <Extract ONLY the strain designation part (e.g., "DA-C8", "MG1655", "ATCC 25922") WITHOUT genus/species prefixes. Focus on strain numbers, culture collection codes, and isolate identifiers. Automatically remove terminal "T" or "(T)" suffixes as these indicate type strain status (e.g., "DA-C8T" becomes "DA-C8", "K13T" becomes "K13"). Include strain numbers, culture collection numbers, and isolate names, but NOT the full taxonomic context.>\ncell_shape: <Extract all cell shapes mentioned in the text exactly as described in the literature. Include measurements when provided (e.g., "rod-shaped, 0.5 x 2.0 Î¼m"). If no cell shapes are mentioned, leave this field empty. DO NOT write "none".>\ncell_arrangements: <Extract all cell arrangement patterns mentioned in the text (e.g., single cells, pairs, chains, clusters, tetrads, packets, irregular masses, palisades, V-shapes, angular arrangements). If no cell arrangements are mentioned, leave this field empty. DO NOT write "none".>\ngram_staining: <Extract Gram staining results mentioned in the text (e.g., Gram-positive, Gram-negative, Gram-variable, Gram-indeterminate). Include any additional staining properties mentioned. If no Gram staining information is mentioned, leave this field empty. DO NOT write "none".>\nmotility: <Extract all motility characteristics mentioned in the text, including motility presence (motile/non-motile), motility types (flagellar, gliding, twitching, swarming), and flagella arrangements (polar, peritrichous, monotrichous, lophotrichous, amphitrichous). If no motility information is mentioned, leave this field empty. DO NOT write "none".>\nspore_formation: <Extract all spore formation characteristics mentioned in the text, including spore presence (spore-forming/non-spore-forming), spore types (endospores, conidia, arthrospores), and spore positions (terminal, subterminal, central, lateral). Include sporangium or other structures. If no spore formation information is mentioned, leave this field empty. DO NOT write "none".>\ncell_wall_characteristics: <Extract all cell wall characteristics mentioned in the text, including structural features (thick/thin, multilayered), chemical components (peptidoglycan, teichoic acids, mycolic acids, lipopolysaccharide), and anatomical features (outer membrane, periplasmic space, S-layer, capsule). If no cell wall characteristics are mentioned, leave this field empty. DO NOT write "none".>\ncellular_inclusions: <Extract all cellular inclusions and internal structures mentioned in the text, including storage granules (PHB, PHA, polyphosphate, glycogen, sulfur, lipid droplets), specialized structures (gas vesicles, magnetosomes, carboxysomes), and other intracellular bodies. If no cellular inclusions are mentioned, leave this field empty. DO NOT write "none".>\ncell_shape_relationships: <For each cell shape extracted above, create strain-to-shape relationships. Link specific strains to their cell shapes (e.g., "DA-C8 has_cell_shape rod-shaped"). Convert ALL cell shapes mentioned above into structured relationships.>\ncell_arrangement_relationships: <For each cell arrangement extracted above, create strain-to-arrangement relationships. Link specific strains to their arrangements (e.g., "DA-C8 has_arrangement chains"). Convert ALL cell arrangements mentioned above into structured relationships.>\ngram_staining_relationships: <For each Gram staining result extracted above, create strain-to-staining relationships. Link specific strains to their staining results (e.g., "DA-C8 has_gram_staining Gram-positive"). Convert ALL Gram staining results mentioned above into structured relationships.>\nmotility_relationships: <For each motility characteristic extracted above, create strain-to-motility relationships. Link specific strains to their motility characteristics (e.g., "DA-C8 has_motility motile"). Convert ALL motility characteristics mentioned above into structured relationships.>\nspore_formation_relationships: <For each spore formation characteristic extracted above, create strain-to-spore relationships. Link specific strains to their spore characteristics (e.g., "DA-C8 has_spore_formation terminal spores"). Convert ALL spore formation characteristics mentioned above into structured relationships.>\ncell_wall_relationships: <For each cell wall characteristic extracted above, create strain-to-cell-wall relationships. Link specific strains to their cell wall features (e.g., "DA-C8 has_cell_wall_feature peptidoglycan"). Convert ALL cell wall characteristics mentioned above into structured relationships.>\ncellular_inclusion_relationships: <For each cellular inclusion extracted above, create strain-to-inclusion relationships. Link specific strains to their cellular inclusions (e.g., "DA-C8 has_inclusion PHB granules"). Convert ALL cellular inclusions mentioned above into structured relationships.>\npigmentation: <Extract all pigmentation and colony color characteristics mentioned in the text, including colors (yellow, orange, red, pink, white, cream, brown, black, green), pigment types (carotenoid, melanin, flexirubin), and properties (diffusible, non-diffusible, fluorescent). If no pigmentation is mentioned, leave this field empty. DO NOT write "none".>\nstrain_relationships: <A semicolon-separated list of strain-species relationships, where each relationship connects a strain to its parent taxon. Each relationship should have a strain name, relationship type, and parent species/genus. For example: "MG1655 strain_of Escherichia coli; K-12 strain_of Escherichia coli; ATCC 25922 type_strain_of Klebsiella pneumoniae". If no strain relationships are found, leave this field empty. DO NOT write "none".>\narticle_type: <The type of study or article. Choose the most appropriate category based on the content.Must be one of: novel_species, novel_genus, taxonomic_revision, phylogenetic_analysis, comparative_taxonomy, emended_description, genome_sequence, review, biochemical_characterization, ecological_study, morphological_characterization, physiology_study>\n\n\nText:\n{\'content\': \'Application of AFLP for taxonomic and epidemiological studies of Photobacterium damselae subsp. piscicida.\\n\\nA collection of 106 Photobacterium damselae subsp. piscicida strains and 19 Photobacterium damselae subsp. damselae strains, including reference and type strains, were genetically characterized using AFLP. The total genomic DNA of each bacterial strain was digested using restriction endonucleases HindIII and TaqI. Using numerical analysis, six clusters were recognized. The largest cluster (n = 106) contained the majority of the strains tested and consisted exclusively of Photobacterium damselae subsp. piscicida. The Photobacterium damselae subsp. damselae strains fell outside this cluster. DNA-DNA hybridization experiments showed 77% DNA binding between the two subspecies, indicating a close genetic relationship. This clearly demonstrates the applicability of AFLP in studying the taxonomic position of Photobacterium damselae subsp. piscicida. In addition, AFLP proved to be a useful genotypic technique for epidemiological surveys of the pathogen, since it was able to discriminate between Mediterranean and Japanese Photobacterium damselae subsp. piscicida isolates.\\n\\nPMID:10843040\', \'saved_to\': None, \'windowed\': False}\n\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 7db743db0bf2e4b009aa441c39e104393eb7b4ac05fe381b08f390cd9a9c7e85
DEBUG:LiteLLM:Final hashed key: 7db743db0bf2e4b009aa441c39e104393eb7b4ac05fe381b08f390cd9a9c7e85
INFO:LiteLLM:
LiteLLM completion() model= gpt-4o; provider = openai
DEBUG:LiteLLM:
LiteLLM: Params passed to completion() {'model': 'gpt-4o', 'functions': None, 'function_call': None, 'temperature': 1.0, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'From the text below, extract the following entities in the following format:\n\npmid: <PubMed ID of the article (e.g., 23996836)>\nstudy_taxa: <semicolon-separated list of the main bacterial or archaeal taxa being studied for morphology>\nstrains: <Extract ONLY the strain designation part (e.g., "DA-C8", "MG1655", "ATCC 25922") WITHOUT genus/species prefixes. Focus on strain numbers, culture collection codes, and isolate identifiers. Automatically remove terminal "T" or "(T)" suffixes as these indicate type strain status (e.g., "DA-C8T" becomes "DA-C8", "K13T" becomes "K13"). Include strain numbers, culture collection numbers, and isolate names, but NOT the full taxonomic context.>\ncell_shape: <Extract all cell shapes mentioned in the text exactly as described in the literature. Include measurements when provided (e.g., "rod-shaped, 0.5 x 2.0 Î¼m"). If no cell shapes are mentioned, leave this field empty. DO NOT write "none".>\ncell_arrangements: <Extract all cell arrangement patterns mentioned in the text (e.g., single cells, pairs, chains, clusters, tetrads, packets, irregular masses, palisades, V-shapes, angular arrangements). If no cell arrangements are mentioned, leave this field empty. DO NOT write "none".>\ngram_staining: <Extract Gram staining results mentioned in the text (e.g., Gram-positive, Gram-negative, Gram-variable, Gram-indeterminate). Include any additional staining properties mentioned. If no Gram staining information is mentioned, leave this field empty. DO NOT write "none".>\nmotility: <Extract all motility characteristics mentioned in the text, including motility presence (motile/non-motile), motility types (flagellar, gliding, twitching, swarming), and flagella arrangements (polar, peritrichous, monotrichous, lophotrichous, amphitrichous). If no motility information is mentioned, leave this field empty. DO NOT write "none".>\nspore_formation: <Extract all spore formation characteristics mentioned in the text, including spore presence (spore-forming/non-spore-forming), spore types (endospores, conidia, arthrospores), and spore positions (terminal, subterminal, central, lateral). Include sporangium or other structures. If no spore formation information is mentioned, leave this field empty. DO NOT write "none".>\ncell_wall_characteristics: <Extract all cell wall characteristics mentioned in the text, including structural features (thick/thin, multilayered), chemical components (peptidoglycan, teichoic acids, mycolic acids, lipopolysaccharide), and anatomical features (outer membrane, periplasmic space, S-layer, capsule). If no cell wall characteristics are mentioned, leave this field empty. DO NOT write "none".>\ncellular_inclusions: <Extract all cellular inclusions and internal structures mentioned in the text, including storage granules (PHB, PHA, polyphosphate, glycogen, sulfur, lipid droplets), specialized structures (gas vesicles, magnetosomes, carboxysomes), and other intracellular bodies. If no cellular inclusions are mentioned, leave this field empty. DO NOT write "none".>\ncell_shape_relationships: <For each cell shape extracted above, create strain-to-shape relationships. Link specific strains to their cell shapes (e.g., "DA-C8 has_cell_shape rod-shaped"). Convert ALL cell shapes mentioned above into structured relationships.>\ncell_arrangement_relationships: <For each cell arrangement extracted above, create strain-to-arrangement relationships. Link specific strains to their arrangements (e.g., "DA-C8 has_arrangement chains"). Convert ALL cell arrangements mentioned above into structured relationships.>\ngram_staining_relationships: <For each Gram staining result extracted above, create strain-to-staining relationships. Link specific strains to their staining results (e.g., "DA-C8 has_gram_staining Gram-positive"). Convert ALL Gram staining results mentioned above into structured relationships.>\nmotility_relationships: <For each motility characteristic extracted above, create strain-to-motility relationships. Link specific strains to their motility characteristics (e.g., "DA-C8 has_motility motile"). Convert ALL motility characteristics mentioned above into structured relationships.>\nspore_formation_relationships: <For each spore formation characteristic extracted above, create strain-to-spore relationships. Link specific strains to their spore characteristics (e.g., "DA-C8 has_spore_formation terminal spores"). Convert ALL spore formation characteristics mentioned above into structured relationships.>\ncell_wall_relationships: <For each cell wall characteristic extracted above, create strain-to-cell-wall relationships. Link specific strains to their cell wall features (e.g., "DA-C8 has_cell_wall_feature peptidoglycan"). Convert ALL cell wall characteristics mentioned above into structured relationships.>\ncellular_inclusion_relationships: <For each cellular inclusion extracted above, create strain-to-inclusion relationships. Link specific strains to their cellular inclusions (e.g., "DA-C8 has_inclusion PHB granules"). Convert ALL cellular inclusions mentioned above into structured relationships.>\npigmentation: <Extract all pigmentation and colony color characteristics mentioned in the text, including colors (yellow, orange, red, pink, white, cream, brown, black, green), pigment types (carotenoid, melanin, flexirubin), and properties (diffusible, non-diffusible, fluorescent). If no pigmentation is mentioned, leave this field empty. DO NOT write "none".>\nstrain_relationships: <A semicolon-separated list of strain-species relationships, where each relationship connects a strain to its parent taxon. Each relationship should have a strain name, relationship type, and parent species/genus. For example: "MG1655 strain_of Escherichia coli; K-12 strain_of Escherichia coli; ATCC 25922 type_strain_of Klebsiella pneumoniae". If no strain relationships are found, leave this field empty. DO NOT write "none".>\narticle_type: <The type of study or article. Choose the most appropriate category based on the content.Must be one of: novel_species, novel_genus, taxonomic_revision, phylogenetic_analysis, comparative_taxonomy, emended_description, genome_sequence, review, biochemical_characterization, ecological_study, morphological_characterization, physiology_study>\n\n\nText:\n{\'content\': \'Application of AFLP for taxonomic and epidemiological studies of Photobacterium damselae subsp. piscicida.\\n\\nA collection of 106 Photobacterium damselae subsp. piscicida strains and 19 Photobacterium damselae subsp. damselae strains, including reference and type strains, were genetically characterized using AFLP. The total genomic DNA of each bacterial strain was digested using restriction endonucleases HindIII and TaqI. Using numerical analysis, six clusters were recognized. The largest cluster (n = 106) contained the majority of the strains tested and consisted exclusively of Photobacterium damselae subsp. piscicida. The Photobacterium damselae subsp. damselae strains fell outside this cluster. DNA-DNA hybridization experiments showed 77% DNA binding between the two subspecies, indicating a close genetic relationship. This clearly demonstrates the applicability of AFLP in studying the taxonomic position of Photobacterium damselae subsp. piscicida. In addition, AFLP proved to be a useful genotypic technique for epidemiological surveys of the pathogen, since it was able to discriminate between Mediterranean and Japanese Photobacterium damselae subsp. piscicida isolates.\\n\\nPMID:10843040\', \'saved_to\': None, \'windowed\': False}\n\n\n===\n\n', 'role': 'user'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
DEBUG:LiteLLM:
LiteLLM: Non-Default params passed to completion() {'temperature': 1.0}
DEBUG:LiteLLM:Final returned optional params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:self.optional_params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o', 'combined_model_name': 'openai/gpt-4o', 'stripped_model_name': 'gpt-4o', 'combined_stripped_model_name': 'openai/gpt-4o', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.cborg.lbl.gov \
-d '{'model': 'gpt-4o', 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'From the text below, extract the following entities in the following format:\n\npmid: <PubMed ID of the article (e.g., 23996836)>\nstudy_taxa: <semicolon-separated list of the main bacterial or archaeal taxa being studied for morphology>\nstrains: <Extract ONLY the strain designation part (e.g., "DA-C8", "MG1655", "ATCC 25922") WITHOUT genus/species prefixes. Focus on strain numbers, culture collection codes, and isolate identifiers. Automatically remove terminal "T" or "(T)" suffixes as these indicate type strain status (e.g., "DA-C8T" becomes "DA-C8", "K13T" becomes "K13"). Include strain numbers, culture collection numbers, and isolate names, but NOT the full taxonomic context.>\ncell_shape: <Extract all cell shapes mentioned in the text exactly as described in the literature. Include measurements when provided (e.g., "rod-shaped, 0.5 x 2.0 Î¼m"). If no cell shapes are mentioned, leave this field empty. DO NOT write "none".>\ncell_arrangements: <Extract all cell arrangement patterns mentioned in the text (e.g., single cells, pairs, chains, clusters, tetrads, packets, irregular masses, palisades, V-shapes, angular arrangements). If no cell arrangements are mentioned, leave this field empty. DO NOT write "none".>\ngram_staining: <Extract Gram staining results mentioned in the text (e.g., Gram-positive, Gram-negative, Gram-variable, Gram-indeterminate). Include any additional staining properties mentioned. If no Gram staining information is mentioned, leave this field empty. DO NOT write "none".>\nmotility: <Extract all motility characteristics mentioned in the text, including motility presence (motile/non-motile), motility types (flagellar, gliding, twitching, swarming), and flagella arrangements (polar, peritrichous, monotrichous, lophotrichous, amphitrichous). If no motility information is mentioned, leave this field empty. DO NOT write "none".>\nspore_formation: <Extract all spore formation characteristics mentioned in the text, including spore presence (spore-forming/non-spore-forming), spore types (endospores, conidia, arthrospores), and spore positions (terminal, subterminal, central, lateral). Include sporangium or other structures. If no spore formation information is mentioned, leave this field empty. DO NOT write "none".>\ncell_wall_characteristics: <Extract all cell wall characteristics mentioned in the text, including structural features (thick/thin, multilayered), chemical components (peptidoglycan, teichoic acids, mycolic acids, lipopolysaccharide), and anatomical features (outer membrane, periplasmic space, S-layer, capsule). If no cell wall characteristics are mentioned, leave this field empty. DO NOT write "none".>\ncellular_inclusions: <Extract all cellular inclusions and internal structures mentioned in the text, including storage granules (PHB, PHA, polyphosphate, glycogen, sulfur, lipid droplets), specialized structures (gas vesicles, magnetosomes, carboxysomes), and other intracellular bodies. If no cellular inclusions are mentioned, leave this field empty. DO NOT write "none".>\ncell_shape_relationships: <For each cell shape extracted above, create strain-to-shape relationships. Link specific strains to their cell shapes (e.g., "DA-C8 has_cell_shape rod-shaped"). Convert ALL cell shapes mentioned above into structured relationships.>\ncell_arrangement_relationships: <For each cell arrangement extracted above, create strain-to-arrangement relationships. Link specific strains to their arrangements (e.g., "DA-C8 has_arrangement chains"). Convert ALL cell arrangements mentioned above into structured relationships.>\ngram_staining_relationships: <For each Gram staining result extracted above, create strain-to-staining relationships. Link specific strains to their staining results (e.g., "DA-C8 has_gram_staining Gram-positive"). Convert ALL Gram staining results mentioned above into structured relationships.>\nmotility_relationships: <For each motility characteristic extracted above, create strain-to-motility relationships. Link specific strains to their motility characteristics (e.g., "DA-C8 has_motility motile"). Convert ALL motility characteristics mentioned above into structured relationships.>\nspore_formation_relationships: <For each spore formation characteristic extracted above, create strain-to-spore relationships. Link specific strains to their spore characteristics (e.g., "DA-C8 has_spore_formation terminal spores"). Convert ALL spore formation characteristics mentioned above into structured relationships.>\ncell_wall_relationships: <For each cell wall characteristic extracted above, create strain-to-cell-wall relationships. Link specific strains to their cell wall features (e.g., "DA-C8 has_cell_wall_feature peptidoglycan"). Convert ALL cell wall characteristics mentioned above into structured relationships.>\ncellular_inclusion_relationships: <For each cellular inclusion extracted above, create strain-to-inclusion relationships. Link specific strains to their cellular inclusions (e.g., "DA-C8 has_inclusion PHB granules"). Convert ALL cellular inclusions mentioned above into structured relationships.>\npigmentation: <Extract all pigmentation and colony color characteristics mentioned in the text, including colors (yellow, orange, red, pink, white, cream, brown, black, green), pigment types (carotenoid, melanin, flexirubin), and properties (diffusible, non-diffusible, fluorescent). If no pigmentation is mentioned, leave this field empty. DO NOT write "none".>\nstrain_relationships: <A semicolon-separated list of strain-species relationships, where each relationship connects a strain to its parent taxon. Each relationship should have a strain name, relationship type, and parent species/genus. For example: "MG1655 strain_of Escherichia coli; K-12 strain_of Escherichia coli; ATCC 25922 type_strain_of Klebsiella pneumoniae". If no strain relationships are found, leave this field empty. DO NOT write "none".>\narticle_type: <The type of study or article. Choose the most appropriate category based on the content.Must be one of: novel_species, novel_genus, taxonomic_revision, phylogenetic_analysis, comparative_taxonomy, emended_description, genome_sequence, review, biochemical_characterization, ecological_study, morphological_characterization, physiology_study>\n\n\nText:\n{\'content\': \'Application of AFLP for taxonomic and epidemiological studies of Photobacterium damselae subsp. piscicida.\\n\\nA collection of 106 Photobacterium damselae subsp. piscicida strains and 19 Photobacterium damselae subsp. damselae strains, including reference and type strains, were genetically characterized using AFLP. The total genomic DNA of each bacterial strain was digested using restriction endonucleases HindIII and TaqI. Using numerical analysis, six clusters were recognized. The largest cluster (n = 106) contained the majority of the strains tested and consisted exclusively of Photobacterium damselae subsp. piscicida. The Photobacterium damselae subsp. damselae strains fell outside this cluster. DNA-DNA hybridization experiments showed 77% DNA binding between the two subspecies, indicating a close genetic relationship. This clearly demonstrates the applicability of AFLP in studying the taxonomic position of Photobacterium damselae subsp. piscicida. In addition, AFLP proved to be a useful genotypic technique for epidemiological surveys of the pathogen, since it was able to discriminate between Mediterranean and Japanese Photobacterium damselae subsp. piscicida isolates.\\n\\nPMID:10843040\', \'saved_to\': None, \'windowed\': False}\n\n\n===\n\n', 'role': 'user'}], 'temperature': 1.0, 'extra_body': {}}'
[0m

DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-c8af87ca-d053-46a8-ac6c-095875a9f481', 'json_data': {'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'From the text below, extract the following entities in the following format:\n\npmid: <PubMed ID of the article (e.g., 23996836)>\nstudy_taxa: <semicolon-separated list of the main bacterial or archaeal taxa being studied for morphology>\nstrains: <Extract ONLY the strain designation part (e.g., "DA-C8", "MG1655", "ATCC 25922") WITHOUT genus/species prefixes. Focus on strain numbers, culture collection codes, and isolate identifiers. Automatically remove terminal "T" or "(T)" suffixes as these indicate type strain status (e.g., "DA-C8T" becomes "DA-C8", "K13T" becomes "K13"). Include strain numbers, culture collection numbers, and isolate names, but NOT the full taxonomic context.>\ncell_shape: <Extract all cell shapes mentioned in the text exactly as described in the literature. Include measurements when provided (e.g., "rod-shaped, 0.5 x 2.0 Î¼m"). If no cell shapes are mentioned, leave this field empty. DO NOT write "none".>\ncell_arrangements: <Extract all cell arrangement patterns mentioned in the text (e.g., single cells, pairs, chains, clusters, tetrads, packets, irregular masses, palisades, V-shapes, angular arrangements). If no cell arrangements are mentioned, leave this field empty. DO NOT write "none".>\ngram_staining: <Extract Gram staining results mentioned in the text (e.g., Gram-positive, Gram-negative, Gram-variable, Gram-indeterminate). Include any additional staining properties mentioned. If no Gram staining information is mentioned, leave this field empty. DO NOT write "none".>\nmotility: <Extract all motility characteristics mentioned in the text, including motility presence (motile/non-motile), motility types (flagellar, gliding, twitching, swarming), and flagella arrangements (polar, peritrichous, monotrichous, lophotrichous, amphitrichous). If no motility information is mentioned, leave this field empty. DO NOT write "none".>\nspore_formation: <Extract all spore formation characteristics mentioned in the text, including spore presence (spore-forming/non-spore-forming), spore types (endospores, conidia, arthrospores), and spore positions (terminal, subterminal, central, lateral). Include sporangium or other structures. If no spore formation information is mentioned, leave this field empty. DO NOT write "none".>\ncell_wall_characteristics: <Extract all cell wall characteristics mentioned in the text, including structural features (thick/thin, multilayered), chemical components (peptidoglycan, teichoic acids, mycolic acids, lipopolysaccharide), and anatomical features (outer membrane, periplasmic space, S-layer, capsule). If no cell wall characteristics are mentioned, leave this field empty. DO NOT write "none".>\ncellular_inclusions: <Extract all cellular inclusions and internal structures mentioned in the text, including storage granules (PHB, PHA, polyphosphate, glycogen, sulfur, lipid droplets), specialized structures (gas vesicles, magnetosomes, carboxysomes), and other intracellular bodies. If no cellular inclusions are mentioned, leave this field empty. DO NOT write "none".>\ncell_shape_relationships: <For each cell shape extracted above, create strain-to-shape relationships. Link specific strains to their cell shapes (e.g., "DA-C8 has_cell_shape rod-shaped"). Convert ALL cell shapes mentioned above into structured relationships.>\ncell_arrangement_relationships: <For each cell arrangement extracted above, create strain-to-arrangement relationships. Link specific strains to their arrangements (e.g., "DA-C8 has_arrangement chains"). Convert ALL cell arrangements mentioned above into structured relationships.>\ngram_staining_relationships: <For each Gram staining result extracted above, create strain-to-staining relationships. Link specific strains to their staining results (e.g., "DA-C8 has_gram_staining Gram-positive"). Convert ALL Gram staining results mentioned above into structured relationships.>\nmotility_relationships: <For each motility characteristic extracted above, create strain-to-motility relationships. Link specific strains to their motility characteristics (e.g., "DA-C8 has_motility motile"). Convert ALL motility characteristics mentioned above into structured relationships.>\nspore_formation_relationships: <For each spore formation characteristic extracted above, create strain-to-spore relationships. Link specific strains to their spore characteristics (e.g., "DA-C8 has_spore_formation terminal spores"). Convert ALL spore formation characteristics mentioned above into structured relationships.>\ncell_wall_relationships: <For each cell wall characteristic extracted above, create strain-to-cell-wall relationships. Link specific strains to their cell wall features (e.g., "DA-C8 has_cell_wall_feature peptidoglycan"). Convert ALL cell wall characteristics mentioned above into structured relationships.>\ncellular_inclusion_relationships: <For each cellular inclusion extracted above, create strain-to-inclusion relationships. Link specific strains to their cellular inclusions (e.g., "DA-C8 has_inclusion PHB granules"). Convert ALL cellular inclusions mentioned above into structured relationships.>\npigmentation: <Extract all pigmentation and colony color characteristics mentioned in the text, including colors (yellow, orange, red, pink, white, cream, brown, black, green), pigment types (carotenoid, melanin, flexirubin), and properties (diffusible, non-diffusible, fluorescent). If no pigmentation is mentioned, leave this field empty. DO NOT write "none".>\nstrain_relationships: <A semicolon-separated list of strain-species relationships, where each relationship connects a strain to its parent taxon. Each relationship should have a strain name, relationship type, and parent species/genus. For example: "MG1655 strain_of Escherichia coli; K-12 strain_of Escherichia coli; ATCC 25922 type_strain_of Klebsiella pneumoniae". If no strain relationships are found, leave this field empty. DO NOT write "none".>\narticle_type: <The type of study or article. Choose the most appropriate category based on the content.Must be one of: novel_species, novel_genus, taxonomic_revision, phylogenetic_analysis, comparative_taxonomy, emended_description, genome_sequence, review, biochemical_characterization, ecological_study, morphological_characterization, physiology_study>\n\n\nText:\n{\'content\': \'Application of AFLP for taxonomic and epidemiological studies of Photobacterium damselae subsp. piscicida.\\n\\nA collection of 106 Photobacterium damselae subsp. piscicida strains and 19 Photobacterium damselae subsp. damselae strains, including reference and type strains, were genetically characterized using AFLP. The total genomic DNA of each bacterial strain was digested using restriction endonucleases HindIII and TaqI. Using numerical analysis, six clusters were recognized. The largest cluster (n = 106) contained the majority of the strains tested and consisted exclusively of Photobacterium damselae subsp. piscicida. The Photobacterium damselae subsp. damselae strains fell outside this cluster. DNA-DNA hybridization experiments showed 77% DNA binding between the two subspecies, indicating a close genetic relationship. This clearly demonstrates the applicability of AFLP in studying the taxonomic position of Photobacterium damselae subsp. piscicida. In addition, AFLP proved to be a useful genotypic technique for epidemiological surveys of the pathogen, since it was able to discriminate between Mediterranean and Japanese Photobacterium damselae subsp. piscicida isolates.\\n\\nPMID:10843040\', \'saved_to\': None, \'windowed\': False}\n\n\n===\n\n', 'role': 'user'}], 'model': 'gpt-4o', 'temperature': 1.0}, 'extra_json': {}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.cborg.lbl.gov/chat/completions
DEBUG:httpcore.connection:close.started
DEBUG:httpcore.connection:close.complete
DEBUG:httpcore.connection:connect_tcp.started host='api.cborg.lbl.gov' port=443 local_address=None timeout=600.0 socket_options=None
DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x114e4f4d0>
DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x11473c050> server_hostname='api.cborg.lbl.gov' timeout=600.0
DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x114e4f8d0>
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 30 Oct 2025 21:43:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'llm_provider-apim-request-id', b'48654241-ff98-41f1-a998-8ac562efd899'), (b'llm_provider-azureml-model-session', b'd015-20251018173616'), (b'llm_provider-content-length', b'1577'), (b'llm_provider-content-type', b'application/json'), (b'llm_provider-date', b'Thu, 30 Oct 2025 21:43:44 GMT'), (b'llm_provider-strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'llm_provider-x-accel-buffering', b'no'), (b'llm_provider-x-content-type-options', b'nosniff'), (b'llm_provider-x-ms-deployment-name', b'gpt-4o'), (b'llm_provider-x-ms-rai-invoked', b'true'), (b'llm_provider-x-ms-region', b'East US'), (b'llm_provider-x-ratelimit-limit-requests', b'150'), (b'llm_provider-x-ratelimit-limit-tokens', b'150000'), (b'llm_provider-x-ratelimit-remaining-requests', b'146'), (b'llm_provider-x-ratelimit-remaining-tokens', b'121452'), (b'llm_provider-x-request-id', b'34651390-7f57-4275-81cf-f45dd7fe5c66'), (b'Server', b'cloudflare'), (b'x-litellm-attempted-fallbacks', b'0'), (b'x-litellm-attempted-retries', b'0'), (b'x-litellm-call-id', b'ed2a773d-19d8-4eb2-aac8-9a07ce834ae1'), (b'x-litellm-key-spend', b'32.74993940000005'), (b'x-litellm-model-api-base', b'https://science-it-openai.openai.azure.com/'), (b'x-litellm-model-group', b'gpt-4o'), (b'x-litellm-model-id', b'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38'), (b'x-litellm-overhead-duration-ms', b'1.368'), (b'x-litellm-response-cost', b'0.0038825'), (b'x-litellm-response-cost-discount-amount', b'0.0'), (b'x-litellm-response-cost-original', b'0.0038825'), (b'x-litellm-response-duration-ms', b'1364.365'), (b'x-litellm-version', b'1.79.0'), (b'x-ratelimit-limit-requests', b'150'), (b'x-ratelimit-limit-tokens', b'150000'), (b'x-ratelimit-remaining-requests', b'146'), (b'x-ratelimit-remaining-tokens', b'121452'), (b'cf-cache-status', b'DYNAMIC'), (b'vary', b'accept-encoding'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'Set-Cookie', b'__cf_bm=tqUf_s2eVtbexwq1xCZDiEwR0b3vOjW7kS0u8jCX3G8-1761860623.4129333-1.0.1.1-CiBZaCOiRvCUzJeTuWuzTWIaz16.YUb1xdnyLeId868Z5_j4brZj8n8RsE4UpdW__c40NspThw0nMSsSjhf6TUS4u2RnW4cykXldcxWLz57lcsXDwGLYh51YRzzO4HnR; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:13:45 GMT'), (b'CF-RAY', b'996e17005cea83d0-EWR')])
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.cborg.lbl.gov/chat/completions "200 OK" Headers({'date': 'Thu, 30 Oct 2025 21:43:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'content-encoding': 'gzip', 'llm_provider-apim-request-id': '48654241-ff98-41f1-a998-8ac562efd899', 'llm_provider-azureml-model-session': 'd015-20251018173616', 'llm_provider-content-length': '1577', 'llm_provider-content-type': 'application/json', 'llm_provider-date': 'Thu, 30 Oct 2025 21:43:44 GMT', 'llm_provider-strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'llm_provider-x-accel-buffering': 'no', 'llm_provider-x-content-type-options': 'nosniff', 'llm_provider-x-ms-deployment-name': 'gpt-4o', 'llm_provider-x-ms-rai-invoked': 'true', 'llm_provider-x-ms-region': 'East US', 'llm_provider-x-ratelimit-limit-requests': '150', 'llm_provider-x-ratelimit-limit-tokens': '150000', 'llm_provider-x-ratelimit-remaining-requests': '146', 'llm_provider-x-ratelimit-remaining-tokens': '121452', 'llm_provider-x-request-id': '34651390-7f57-4275-81cf-f45dd7fe5c66', 'server': 'cloudflare', 'x-litellm-attempted-fallbacks': '0', 'x-litellm-attempted-retries': '0', 'x-litellm-call-id': 'ed2a773d-19d8-4eb2-aac8-9a07ce834ae1', 'x-litellm-key-spend': '32.74993940000005', 'x-litellm-model-api-base': 'https://science-it-openai.openai.azure.com/', 'x-litellm-model-group': 'gpt-4o', 'x-litellm-model-id': 'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38', 'x-litellm-overhead-duration-ms': '1.368', 'x-litellm-response-cost': '0.0038825', 'x-litellm-response-cost-discount-amount': '0.0', 'x-litellm-response-cost-original': '0.0038825', 'x-litellm-response-duration-ms': '1364.365', 'x-litellm-version': '1.79.0', 'x-ratelimit-limit-requests': '150', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '146', 'x-ratelimit-remaining-tokens': '121452', 'cf-cache-status': 'DYNAMIC', 'vary': 'accept-encoding', 'strict-transport-security': 'max-age=31536000', 'set-cookie': '__cf_bm=tqUf_s2eVtbexwq1xCZDiEwR0b3vOjW7kS0u8jCX3G8-1761860623.4129333-1.0.1.1-CiBZaCOiRvCUzJeTuWuzTWIaz16.YUb1xdnyLeId868Z5_j4brZj8n8RsE4UpdW__c40NspThw0nMSsSjhf6TUS4u2RnW4cykXldcxWLz57lcsXDwGLYh51YRzzO4HnR; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:13:45 GMT', 'cf-ray': '996e17005cea83d0-EWR'})
DEBUG:openai._base_client:request_id: None
DEBUG:LiteLLM:RAW RESPONSE:
{"id": "chatcmpl-CWUimU5etq8ltePltFqWSBoTF6eAQ", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "pmid: 10843040\nstudy_taxa: none\nstrains: none\ncell_shape: none\ncell_arrangements: none\ngram_staining: none\nmotility: none\nspore_formation: none\ncell_wall_characteristics: none\ncellular_inclusions: none\ncell_shape_relationships: none\ncell_arrangement_relationships: none\ngram_staining_relationships: none\nmotility_relationships: none\nspore_formation_relationships: none\ncell_wall_relationships: none\ncellular_inclusion_relationships: none\npigmentation: none\nstrain_relationships: none\narticle_type: taxonomic_revision", "refusal": null, "role": "assistant", "annotations": [], "audio": null, "function_call": null, "tool_calls": null}, "provider_specific_fields": {"content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}}], "created": 1761860624, "model": "gpt-4o-2024-08-06", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_4a331a0222", "usage": {"completion_tokens": 135, "prompt_tokens": 1717, "total_tokens": 1852, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 1408}}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}


DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'From the text below, extract the following entities in the following format:\n\npmid: <PubMed ID of the article (e.g., 23996836)>\nstudy_taxa: <semicolon-separated list of the main bacterial or archaeal taxa being studied for morphology>\nstrains: <Extract ONLY the strain designation part (e.g., "DA-C8", "MG1655", "ATCC 25922") WITHOUT genus/species prefixes. Focus on strain numbers, culture collection codes, and isolate identifiers. Automatically remove terminal "T" or "(T)" suffixes as these indicate type strain status (e.g., "DA-C8T" becomes "DA-C8", "K13T" becomes "K13"). Include strain numbers, culture collection numbers, and isolate names, but NOT the full taxonomic context.>\ncell_shape: <Extract all cell shapes mentioned in the text exactly as described in the literature. Include measurements when provided (e.g., "rod-shaped, 0.5 x 2.0 Î¼m"). If no cell shapes are mentioned, leave this field empty. DO NOT write "none".>\ncell_arrangements: <Extract all cell arrangement patterns mentioned in the text (e.g., single cells, pairs, chains, clusters, tetrads, packets, irregular masses, palisades, V-shapes, angular arrangements). If no cell arrangements are mentioned, leave this field empty. DO NOT write "none".>\ngram_staining: <Extract Gram staining results mentioned in the text (e.g., Gram-positive, Gram-negative, Gram-variable, Gram-indeterminate). Include any additional staining properties mentioned. If no Gram staining information is mentioned, leave this field empty. DO NOT write "none".>\nmotility: <Extract all motility characteristics mentioned in the text, including motility presence (motile/non-motile), motility types (flagellar, gliding, twitching, swarming), and flagella arrangements (polar, peritrichous, monotrichous, lophotrichous, amphitrichous). If no motility information is mentioned, leave this field empty. DO NOT write "none".>\nspore_formation: <Extract all spore formation characteristics mentioned in the text, including spore presence (spore-forming/non-spore-forming), spore types (endospores, conidia, arthrospores), and spore positions (terminal, subterminal, central, lateral). Include sporangium or other structures. If no spore formation information is mentioned, leave this field empty. DO NOT write "none".>\ncell_wall_characteristics: <Extract all cell wall characteristics mentioned in the text, including structural features (thick/thin, multilayered), chemical components (peptidoglycan, teichoic acids, mycolic acids, lipopolysaccharide), and anatomical features (outer membrane, periplasmic space, S-layer, capsule). If no cell wall characteristics are mentioned, leave this field empty. DO NOT write "none".>\ncellular_inclusions: <Extract all cellular inclusions and internal structures mentioned in the text, including storage granules (PHB, PHA, polyphosphate, glycogen, sulfur, lipid droplets), specialized structures (gas vesicles, magnetosomes, carboxysomes), and other intracellular bodies. If no cellular inclusions are mentioned, leave this field empty. DO NOT write "none".>\ncell_shape_relationships: <For each cell shape extracted above, create strain-to-shape relationships. Link specific strains to their cell shapes (e.g., "DA-C8 has_cell_shape rod-shaped"). Convert ALL cell shapes mentioned above into structured relationships.>\ncell_arrangement_relationships: <For each cell arrangement extracted above, create strain-to-arrangement relationships. Link specific strains to their arrangements (e.g., "DA-C8 has_arrangement chains"). Convert ALL cell arrangements mentioned above into structured relationships.>\ngram_staining_relationships: <For each Gram staining result extracted above, create strain-to-staining relationships. Link specific strains to their staining results (e.g., "DA-C8 has_gram_staining Gram-positive"). Convert ALL Gram staining results mentioned above into structured relationships.>\nmotility_relationships: <For each motility characteristic extracted above, create strain-to-motility relationships. Link specific strains to their motility characteristics (e.g., "DA-C8 has_motility motile"). Convert ALL motility characteristics mentioned above into structured relationships.>\nspore_formation_relationships: <For each spore formation characteristic extracted above, create strain-to-spore relationships. Link specific strains to their spore characteristics (e.g., "DA-C8 has_spore_formation terminal spores"). Convert ALL spore formation characteristics mentioned above into structured relationships.>\ncell_wall_relationships: <For each cell wall characteristic extracted above, create strain-to-cell-wall relationships. Link specific strains to their cell wall features (e.g., "DA-C8 has_cell_wall_feature peptidoglycan"). Convert ALL cell wall characteristics mentioned above into structured relationships.>\ncellular_inclusion_relationships: <For each cellular inclusion extracted above, create strain-to-inclusion relationships. Link specific strains to their cellular inclusions (e.g., "DA-C8 has_inclusion PHB granules"). Convert ALL cellular inclusions mentioned above into structured relationships.>\npigmentation: <Extract all pigmentation and colony color characteristics mentioned in the text, including colors (yellow, orange, red, pink, white, cream, brown, black, green), pigment types (carotenoid, melanin, flexirubin), and properties (diffusible, non-diffusible, fluorescent). If no pigmentation is mentioned, leave this field empty. DO NOT write "none".>\nstrain_relationships: <A semicolon-separated list of strain-species relationships, where each relationship connects a strain to its parent taxon. Each relationship should have a strain name, relationship type, and parent species/genus. For example: "MG1655 strain_of Escherichia coli; K-12 strain_of Escherichia coli; ATCC 25922 type_strain_of Klebsiella pneumoniae". If no strain relationships are found, leave this field empty. DO NOT write "none".>\narticle_type: <The type of study or article. Choose the most appropriate category based on the content.Must be one of: novel_species, novel_genus, taxonomic_revision, phylogenetic_analysis, comparative_taxonomy, emended_description, genome_sequence, review, biochemical_characterization, ecological_study, morphological_characterization, physiology_study>\n\n\nText:\n{\'content\': \'Application of AFLP for taxonomic and epidemiological studies of Photobacterium damselae subsp. piscicida.\\n\\nA collection of 106 Photobacterium damselae subsp. piscicida strains and 19 Photobacterium damselae subsp. damselae strains, including reference and type strains, were genetically characterized using AFLP. The total genomic DNA of each bacterial strain was digested using restriction endonucleases HindIII and TaqI. Using numerical analysis, six clusters were recognized. The largest cluster (n = 106) contained the majority of the strains tested and consisted exclusively of Photobacterium damselae subsp. piscicida. The Photobacterium damselae subsp. damselae strains fell outside this cluster. DNA-DNA hybridization experiments showed 77% DNA binding between the two subspecies, indicating a close genetic relationship. This clearly demonstrates the applicability of AFLP in studying the taxonomic position of Photobacterium damselae subsp. piscicida. In addition, AFLP proved to be a useful genotypic technique for epidemiological surveys of the pathogen, since it was able to discriminate between Mediterranean and Japanese Photobacterium damselae subsp. piscicida isolates.\\n\\nPMID:10843040\', \'saved_to\': None, \'windowed\': False}\n\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 7db743db0bf2e4b009aa441c39e104393eb7b4ac05fe381b08f390cd9a9c7e85
DEBUG:LiteLLM:Final hashed key: 7db743db0bf2e4b009aa441c39e104393eb7b4ac05fe381b08f390cd9a9c7e85
INFO:LiteLLM:Wrapper: Completed Call, calling success_handler
DEBUG:LiteLLM:response_cost: 0.0038825
INFO:root:RAW TEXT: pmid: 10843040
study_taxa: none
strains: none
cell_shape: none
cell_arrangements: none
gram_staining: none
motility: none
spore_formation: none
cell_wall_characteristics: none
cellular_inclusions: none
cell_shape_relationships: none
cell_arrangement_relationships: none
gram_staining_relationships: none
motility_relationships: none
spore_formation_relationships: none
cell_wall_relationships: none
cellular_inclusion_relationships: none
pigmentation: none
strain_relationships: none
article_type: taxonomic_revision
INFO:root:PARSING LINE: pmid: 10843040
DEBUG:root:  FIELD: pmid
DEBUG:root:SLOT: pmid INL: None VALS: ['10843040']
INFO:root:PARSING LINE: study_taxa: none
DEBUG:root:  FIELD: study_taxa
DEBUG:root:SLOT: study_taxa INL: False VALS: ['none']
INFO:root:PARSING LINE: strains: none
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call: Cache_hit=None
DEBUG:root:  FIELD: strains
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:SLOT: strains INL: False VALS: ['none']
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
INFO:root:PARSING LINE: cell_shape: none
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call streaming complete
DEBUG:root:  FIELD: cell_shape
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:SLOT: cell_shape INL: False VALS: ['none']
INFO:root:PARSING LINE: cell_arrangements: none
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:root:  FIELD: cell_arrangements
DEBUG:root:SLOT: cell_arrangements INL: False VALS: ['none']
INFO:root:PARSING LINE: gram_staining: none
DEBUG:root:  FIELD: gram_staining
DEBUG:root:SLOT: gram_staining INL: False VALS: ['none']
INFO:root:PARSING LINE: motility: none
DEBUG:root:  FIELD: motility
DEBUG:root:SLOT: motility INL: False VALS: ['none']
INFO:root:PARSING LINE: spore_formation: none
DEBUG:root:  FIELD: spore_formation
DEBUG:root:SLOT: spore_formation INL: False VALS: ['none']
INFO:root:PARSING LINE: cell_wall_characteristics: none
DEBUG:root:  FIELD: cell_wall_characteristics
DEBUG:root:SLOT: cell_wall_characteristics INL: False VALS: ['none']
INFO:root:PARSING LINE: cellular_inclusions: none
DEBUG:root:  FIELD: cellular_inclusions
DEBUG:root:SLOT: cellular_inclusions INL: False VALS: ['none']
INFO:root:PARSING LINE: cell_shape_relationships: none
DEBUG:root:  FIELD: cell_shape_relationships
DEBUG:root:SLOT: cell_shape_relationships INL: True VALS: ['none']
DEBUG:root:  RECURSING ON SLOT: cell_shape_relationships, range=CellShapeRelationship
INFO:ontogpt.clients.llm_client:Complete: engine=gpt-4o, prompt[356]=Split the following piece of text into fields in the following format:

subject: <the strain with th...
DEBUG:LiteLLM:

DEBUG:LiteLLM:[92mRequest to litellm:[0m
DEBUG:LiteLLM:[92mlitellm.completion(api_key='', api_base='https://api.cborg.lbl.gov', api_version=None, model='gpt-4o', messages=[{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cell shape>\npredicate: <the type of cell shape relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cell shape>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], temperature=1.0, caching=True, custom_llm_provider='openai')[0m
DEBUG:LiteLLM:

DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:SYNC kwargs[caching]: True; litellm.cache: <litellm.caching.caching.Cache object at 0x105624f90>; kwargs.get('cache')['no-cache']: False
DEBUG:LiteLLM:INSIDE CHECKING SYNC CACHE
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cell shape>\npredicate: <the type of cell shape relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cell shape>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 588bccab26d813eb132d3ac2c7f2453d7e8164f5fa2f9e281fe9401fe5ba28ed
DEBUG:LiteLLM:Final hashed key: 588bccab26d813eb132d3ac2c7f2453d7e8164f5fa2f9e281fe9401fe5ba28ed
INFO:LiteLLM:
LiteLLM completion() model= gpt-4o; provider = openai
DEBUG:LiteLLM:
LiteLLM: Params passed to completion() {'model': 'gpt-4o', 'functions': None, 'function_call': None, 'temperature': 1.0, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cell shape>\npredicate: <the type of cell shape relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cell shape>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
DEBUG:LiteLLM:
LiteLLM: Non-Default params passed to completion() {'temperature': 1.0}
DEBUG:LiteLLM:Final returned optional params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:self.optional_params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o', 'combined_model_name': 'openai/gpt-4o', 'stripped_model_name': 'gpt-4o', 'combined_stripped_model_name': 'openai/gpt-4o', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.cborg.lbl.gov \
-d '{'model': 'gpt-4o', 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cell shape>\npredicate: <the type of cell shape relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cell shape>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], 'temperature': 1.0, 'extra_body': {}}'
[0m

DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-f81bbd1f-e255-4b0e-a7f3-ae62ce3854b1', 'json_data': {'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cell shape>\npredicate: <the type of cell shape relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cell shape>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], 'model': 'gpt-4o', 'temperature': 1.0}, 'extra_json': {}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.cborg.lbl.gov/chat/completions
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 30 Oct 2025 21:43:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'llm_provider-apim-request-id', b'1ee41efb-1cc8-41b4-a3e7-504cd8543f19'), (b'llm_provider-azureml-model-session', b'd015-20251018173616'), (b'llm_provider-content-length', b'1080'), (b'llm_provider-content-type', b'application/json'), (b'llm_provider-date', b'Thu, 30 Oct 2025 21:43:44 GMT'), (b'llm_provider-strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'llm_provider-x-accel-buffering', b'no'), (b'llm_provider-x-content-type-options', b'nosniff'), (b'llm_provider-x-ms-deployment-name', b'gpt-4o'), (b'llm_provider-x-ms-rai-invoked', b'true'), (b'llm_provider-x-ms-region', b'East US'), (b'llm_provider-x-ratelimit-limit-requests', b'150'), (b'llm_provider-x-ratelimit-limit-tokens', b'150000'), (b'llm_provider-x-ratelimit-remaining-requests', b'145'), (b'llm_provider-x-ratelimit-remaining-tokens', b'121296'), (b'llm_provider-x-request-id', b'015c2c8b-82df-4888-90bb-9caa4f57b31b'), (b'Server', b'cloudflare'), (b'x-litellm-attempted-fallbacks', b'0'), (b'x-litellm-attempted-retries', b'0'), (b'x-litellm-call-id', b'9138bd9b-a10f-4c55-b679-ce2958d4bbd4'), (b'x-litellm-key-spend', b'32.753821900000055'), (b'x-litellm-model-api-base', b'https://science-it-openai.openai.azure.com/'), (b'x-litellm-model-group', b'gpt-4o'), (b'x-litellm-model-id', b'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38'), (b'x-litellm-overhead-duration-ms', b'1.272'), (b'x-litellm-response-cost', b'0.0005'), (b'x-litellm-response-cost-discount-amount', b'0.0'), (b'x-litellm-response-cost-original', b'0.0005'), (b'x-litellm-response-duration-ms', b'370.809'), (b'x-litellm-version', b'1.79.0'), (b'x-ratelimit-limit-requests', b'150'), (b'x-ratelimit-limit-tokens', b'150000'), (b'x-ratelimit-remaining-requests', b'145'), (b'x-ratelimit-remaining-tokens', b'121296'), (b'cf-cache-status', b'DYNAMIC'), (b'vary', b'accept-encoding'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'Set-Cookie', b'__cf_bm=4vnwysjfAvCCDPLqGOkHljVqreop5UHOpGkGOCCrBIc-1761860625.0614295-1.0.1.1-iKsK8haNnbOmFFVXFcW0Pso8yYs7_4V9vqnkt2Mvk8Q2f3v34ff4xBAaNTt5JBMzKFeeo4ifoJM28iCoV.3PDwCJpkeKeYgYcHZs9QjmZRjMXmViG2qhRPKlMbbqdZpi; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:13:45 GMT'), (b'CF-RAY', b'996e170aad9f83d0-EWR')])
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.cborg.lbl.gov/chat/completions "200 OK" Headers({'date': 'Thu, 30 Oct 2025 21:43:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'content-encoding': 'gzip', 'llm_provider-apim-request-id': '1ee41efb-1cc8-41b4-a3e7-504cd8543f19', 'llm_provider-azureml-model-session': 'd015-20251018173616', 'llm_provider-content-length': '1080', 'llm_provider-content-type': 'application/json', 'llm_provider-date': 'Thu, 30 Oct 2025 21:43:44 GMT', 'llm_provider-strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'llm_provider-x-accel-buffering': 'no', 'llm_provider-x-content-type-options': 'nosniff', 'llm_provider-x-ms-deployment-name': 'gpt-4o', 'llm_provider-x-ms-rai-invoked': 'true', 'llm_provider-x-ms-region': 'East US', 'llm_provider-x-ratelimit-limit-requests': '150', 'llm_provider-x-ratelimit-limit-tokens': '150000', 'llm_provider-x-ratelimit-remaining-requests': '145', 'llm_provider-x-ratelimit-remaining-tokens': '121296', 'llm_provider-x-request-id': '015c2c8b-82df-4888-90bb-9caa4f57b31b', 'server': 'cloudflare', 'x-litellm-attempted-fallbacks': '0', 'x-litellm-attempted-retries': '0', 'x-litellm-call-id': '9138bd9b-a10f-4c55-b679-ce2958d4bbd4', 'x-litellm-key-spend': '32.753821900000055', 'x-litellm-model-api-base': 'https://science-it-openai.openai.azure.com/', 'x-litellm-model-group': 'gpt-4o', 'x-litellm-model-id': 'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38', 'x-litellm-overhead-duration-ms': '1.272', 'x-litellm-response-cost': '0.0005', 'x-litellm-response-cost-discount-amount': '0.0', 'x-litellm-response-cost-original': '0.0005', 'x-litellm-response-duration-ms': '370.809', 'x-litellm-version': '1.79.0', 'x-ratelimit-limit-requests': '150', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '145', 'x-ratelimit-remaining-tokens': '121296', 'cf-cache-status': 'DYNAMIC', 'vary': 'accept-encoding', 'strict-transport-security': 'max-age=31536000', 'set-cookie': '__cf_bm=4vnwysjfAvCCDPLqGOkHljVqreop5UHOpGkGOCCrBIc-1761860625.0614295-1.0.1.1-iKsK8haNnbOmFFVXFcW0Pso8yYs7_4V9vqnkt2Mvk8Q2f3v34ff4xBAaNTt5JBMzKFeeo4ifoJM28iCoV.3PDwCJpkeKeYgYcHZs9QjmZRjMXmViG2qhRPKlMbbqdZpi; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:13:45 GMT', 'cf-ray': '996e170aad9f83d0-EWR'})
DEBUG:openai._base_client:request_id: None
DEBUG:LiteLLM:RAW RESPONSE:
{"id": "chatcmpl-CWUinpx1hP7KrNzPKZXmvnwG1y4Es", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "subject: none\npredicate: none\nobject: none", "refusal": null, "role": "assistant", "annotations": [], "audio": null, "function_call": null, "tool_calls": null}, "provider_specific_fields": {"content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}}], "created": 1761860625, "model": "gpt-4o-2024-08-06", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_4a331a0222", "usage": {"completion_tokens": 12, "prompt_tokens": 152, "total_tokens": 164, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}


DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cell shape>\npredicate: <the type of cell shape relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cell shape>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 588bccab26d813eb132d3ac2c7f2453d7e8164f5fa2f9e281fe9401fe5ba28ed
DEBUG:LiteLLM:Final hashed key: 588bccab26d813eb132d3ac2c7f2453d7e8164f5fa2f9e281fe9401fe5ba28ed
INFO:LiteLLM:Wrapper: Completed Call, calling success_handler
DEBUG:LiteLLM:response_cost: 0.0005
INFO:root:PARSING LINE: subject: none
DEBUG:root:  FIELD: subject
DEBUG:root:SLOT: subject INL: False VALS: ['none']
INFO:root:PARSING LINE: predicate: none
DEBUG:root:  FIELD: predicate
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call: Cache_hit=None
DEBUG:root:SLOT: predicate INL: None VALS: ['none']
INFO:root:PARSING LINE: object: none
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:  FIELD: object
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:root:SLOT: object INL: False VALS: ['none']
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call streaming complete
INFO:root:PARSING LINE: cell_arrangement_relationships: none
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:  FIELD: cell_arrangement_relationships
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:root:SLOT: cell_arrangement_relationships INL: True VALS: ['none']
DEBUG:root:  RECURSING ON SLOT: cell_arrangement_relationships, range=CellArrangementRelationship
INFO:ontogpt.clients.llm_client:Complete: engine=gpt-4o, prompt[382]=Split the following piece of text into fields in the following format:

subject: <the strain with th...
DEBUG:LiteLLM:

DEBUG:LiteLLM:[92mRequest to litellm:[0m
DEBUG:LiteLLM:[92mlitellm.completion(api_key='', api_base='https://api.cborg.lbl.gov', api_version=None, model='gpt-4o', messages=[{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cell arrangement>\npredicate: <the type of cell arrangement relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cell arrangement pattern>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], temperature=1.0, caching=True, custom_llm_provider='openai')[0m
DEBUG:LiteLLM:

DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:SYNC kwargs[caching]: True; litellm.cache: <litellm.caching.caching.Cache object at 0x105624f90>; kwargs.get('cache')['no-cache']: False
DEBUG:LiteLLM:INSIDE CHECKING SYNC CACHE
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cell arrangement>\npredicate: <the type of cell arrangement relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cell arrangement pattern>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 1110091faf18f130bbb5d3455231923e5af5d40184a0049c33547bc3e6673adc
DEBUG:LiteLLM:Final hashed key: 1110091faf18f130bbb5d3455231923e5af5d40184a0049c33547bc3e6673adc
INFO:LiteLLM:
LiteLLM completion() model= gpt-4o; provider = openai
DEBUG:LiteLLM:
LiteLLM: Params passed to completion() {'model': 'gpt-4o', 'functions': None, 'function_call': None, 'temperature': 1.0, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cell arrangement>\npredicate: <the type of cell arrangement relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cell arrangement pattern>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
DEBUG:LiteLLM:
LiteLLM: Non-Default params passed to completion() {'temperature': 1.0}
DEBUG:LiteLLM:Final returned optional params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:self.optional_params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o', 'combined_model_name': 'openai/gpt-4o', 'stripped_model_name': 'gpt-4o', 'combined_stripped_model_name': 'openai/gpt-4o', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.cborg.lbl.gov \
-d '{'model': 'gpt-4o', 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cell arrangement>\npredicate: <the type of cell arrangement relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cell arrangement pattern>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], 'temperature': 1.0, 'extra_body': {}}'
[0m

DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-2e115e20-9f9b-4063-a590-bf1679f74d1a', 'json_data': {'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cell arrangement>\npredicate: <the type of cell arrangement relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cell arrangement pattern>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], 'model': 'gpt-4o', 'temperature': 1.0}, 'extra_json': {}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.cborg.lbl.gov/chat/completions
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 30 Oct 2025 21:43:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'llm_provider-apim-request-id', b'3a89a0ef-a493-431d-bcfa-a064df9d9043'), (b'llm_provider-azureml-model-session', b'd015-20251018173616'), (b'llm_provider-content-length', b'1084'), (b'llm_provider-content-type', b'application/json'), (b'llm_provider-date', b'Thu, 30 Oct 2025 21:43:45 GMT'), (b'llm_provider-strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'llm_provider-x-accel-buffering', b'no'), (b'llm_provider-x-content-type-options', b'nosniff'), (b'llm_provider-x-ms-deployment-name', b'gpt-4o'), (b'llm_provider-x-ms-rai-invoked', b'true'), (b'llm_provider-x-ms-region', b'East US'), (b'llm_provider-x-ratelimit-limit-requests', b'150'), (b'llm_provider-x-ratelimit-limit-tokens', b'150000'), (b'llm_provider-x-ratelimit-remaining-requests', b'146'), (b'llm_provider-x-ratelimit-remaining-tokens', b'121134'), (b'llm_provider-x-request-id', b'447ce2d7-0b7e-40a3-9636-3caf063c02ca'), (b'Server', b'cloudflare'), (b'x-litellm-attempted-fallbacks', b'0'), (b'x-litellm-attempted-retries', b'0'), (b'x-litellm-call-id', b'41228bce-635c-4df3-94c8-1ec35d9248fc'), (b'x-litellm-key-spend', b'32.75432190000006'), (b'x-litellm-model-api-base', b'https://science-it-openai.openai.azure.com/'), (b'x-litellm-model-group', b'gpt-4o'), (b'x-litellm-model-id', b'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38'), (b'x-litellm-overhead-duration-ms', b'1.196'), (b'x-litellm-response-cost', b'0.0005025'), (b'x-litellm-response-cost-discount-amount', b'0.0'), (b'x-litellm-response-cost-original', b'0.0005025'), (b'x-litellm-response-duration-ms', b'345.40700000000004'), (b'x-litellm-version', b'1.79.0'), (b'x-ratelimit-limit-requests', b'150'), (b'x-ratelimit-limit-tokens', b'150000'), (b'x-ratelimit-remaining-requests', b'146'), (b'x-ratelimit-remaining-tokens', b'121134'), (b'cf-cache-status', b'DYNAMIC'), (b'vary', b'accept-encoding'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'Set-Cookie', b'__cf_bm=2WTvFQLCK52.suDleX4n6a9aeEGVwyuQ0etGvj1iv.g-1761860625.582655-1.0.1.1-pJBCnx79BiV4b7tlHSkKHgmIZaGlHo9wyWa1ycOCoKb1NjSkw0JEe2BkqGN5ukBNL1LXwQFwYbry7lVuukYwV5tUul1RoSt1jY6Afca7FZad6P5MigjQK_LLfXs_i8jW; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:13:46 GMT'), (b'CF-RAY', b'996e170def1e83d0-EWR')])
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.cborg.lbl.gov/chat/completions "200 OK" Headers({'date': 'Thu, 30 Oct 2025 21:43:46 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'content-encoding': 'gzip', 'llm_provider-apim-request-id': '3a89a0ef-a493-431d-bcfa-a064df9d9043', 'llm_provider-azureml-model-session': 'd015-20251018173616', 'llm_provider-content-length': '1084', 'llm_provider-content-type': 'application/json', 'llm_provider-date': 'Thu, 30 Oct 2025 21:43:45 GMT', 'llm_provider-strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'llm_provider-x-accel-buffering': 'no', 'llm_provider-x-content-type-options': 'nosniff', 'llm_provider-x-ms-deployment-name': 'gpt-4o', 'llm_provider-x-ms-rai-invoked': 'true', 'llm_provider-x-ms-region': 'East US', 'llm_provider-x-ratelimit-limit-requests': '150', 'llm_provider-x-ratelimit-limit-tokens': '150000', 'llm_provider-x-ratelimit-remaining-requests': '146', 'llm_provider-x-ratelimit-remaining-tokens': '121134', 'llm_provider-x-request-id': '447ce2d7-0b7e-40a3-9636-3caf063c02ca', 'server': 'cloudflare', 'x-litellm-attempted-fallbacks': '0', 'x-litellm-attempted-retries': '0', 'x-litellm-call-id': '41228bce-635c-4df3-94c8-1ec35d9248fc', 'x-litellm-key-spend': '32.75432190000006', 'x-litellm-model-api-base': 'https://science-it-openai.openai.azure.com/', 'x-litellm-model-group': 'gpt-4o', 'x-litellm-model-id': 'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38', 'x-litellm-overhead-duration-ms': '1.196', 'x-litellm-response-cost': '0.0005025', 'x-litellm-response-cost-discount-amount': '0.0', 'x-litellm-response-cost-original': '0.0005025', 'x-litellm-response-duration-ms': '345.40700000000004', 'x-litellm-version': '1.79.0', 'x-ratelimit-limit-requests': '150', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '146', 'x-ratelimit-remaining-tokens': '121134', 'cf-cache-status': 'DYNAMIC', 'vary': 'accept-encoding', 'strict-transport-security': 'max-age=31536000', 'set-cookie': '__cf_bm=2WTvFQLCK52.suDleX4n6a9aeEGVwyuQ0etGvj1iv.g-1761860625.582655-1.0.1.1-pJBCnx79BiV4b7tlHSkKHgmIZaGlHo9wyWa1ycOCoKb1NjSkw0JEe2BkqGN5ukBNL1LXwQFwYbry7lVuukYwV5tUul1RoSt1jY6Afca7FZad6P5MigjQK_LLfXs_i8jW; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:13:46 GMT', 'cf-ray': '996e170def1e83d0-EWR'})
DEBUG:openai._base_client:request_id: None
DEBUG:LiteLLM:RAW RESPONSE:
{"id": "chatcmpl-CWUinjtwQRSSnE7pKuFWuhxKRmgp1", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "subject: none  \npredicate: none  \nobject: none", "refusal": null, "role": "assistant", "annotations": [], "audio": null, "function_call": null, "tool_calls": null}, "provider_specific_fields": {"content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}}], "created": 1761860625, "model": "gpt-4o-2024-08-06", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_4a331a0222", "usage": {"completion_tokens": 12, "prompt_tokens": 153, "total_tokens": 165, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}


DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cell arrangement>\npredicate: <the type of cell arrangement relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cell arrangement pattern>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 1110091faf18f130bbb5d3455231923e5af5d40184a0049c33547bc3e6673adc
DEBUG:LiteLLM:Final hashed key: 1110091faf18f130bbb5d3455231923e5af5d40184a0049c33547bc3e6673adc
INFO:LiteLLM:Wrapper: Completed Call, calling success_handler
DEBUG:LiteLLM:response_cost: 0.0005025
INFO:root:PARSING LINE: subject: none
DEBUG:root:  FIELD: subject
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call: Cache_hit=None
DEBUG:root:SLOT: subject INL: False VALS: ['none']
INFO:root:PARSING LINE: predicate: none
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:  FIELD: predicate
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:root:SLOT: predicate INL: None VALS: ['none']
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call streaming complete
INFO:root:PARSING LINE: object: none
DEBUG:root:  FIELD: object
DEBUG:root:SLOT: object INL: False VALS: ['none']
INFO:root:PARSING LINE: gram_staining_relationships: none
DEBUG:root:  FIELD: gram_staining_relationships
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:SLOT: gram_staining_relationships INL: True VALS: ['none']
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:root:  RECURSING ON SLOT: gram_staining_relationships, range=GramStainingRelationship
INFO:ontogpt.clients.llm_client:Complete: engine=gpt-4o, prompt[369]=Split the following piece of text into fields in the following format:

subject: <the strain with th...
DEBUG:LiteLLM:

DEBUG:LiteLLM:[92mRequest to litellm:[0m
DEBUG:LiteLLM:[92mlitellm.completion(api_key='', api_base='https://api.cborg.lbl.gov', api_version=None, model='gpt-4o', messages=[{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], temperature=1.0, caching=True, custom_llm_provider='openai')[0m
DEBUG:LiteLLM:

DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:SYNC kwargs[caching]: True; litellm.cache: <litellm.caching.caching.Cache object at 0x105624f90>; kwargs.get('cache')['no-cache']: False
DEBUG:LiteLLM:INSIDE CHECKING SYNC CACHE
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): f26d70e4f0450afbc4349194d9562c8fab96e9e124d5ff5915aa93802944517f
DEBUG:LiteLLM:Final hashed key: f26d70e4f0450afbc4349194d9562c8fab96e9e124d5ff5915aa93802944517f
INFO:LiteLLM:
LiteLLM completion() model= gpt-4o; provider = openai
DEBUG:LiteLLM:
LiteLLM: Params passed to completion() {'model': 'gpt-4o', 'functions': None, 'function_call': None, 'temperature': 1.0, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
DEBUG:LiteLLM:
LiteLLM: Non-Default params passed to completion() {'temperature': 1.0}
DEBUG:LiteLLM:Final returned optional params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:self.optional_params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o', 'combined_model_name': 'openai/gpt-4o', 'stripped_model_name': 'gpt-4o', 'combined_stripped_model_name': 'openai/gpt-4o', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.cborg.lbl.gov \
-d '{'model': 'gpt-4o', 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], 'temperature': 1.0, 'extra_body': {}}'
[0m

DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-7c499dc9-f66e-48d5-aa0e-71d7ec123d49', 'json_data': {'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], 'model': 'gpt-4o', 'temperature': 1.0}, 'extra_json': {}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.cborg.lbl.gov/chat/completions
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 30 Oct 2025 21:43:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'llm_provider-apim-request-id', b'a2ca7da7-556f-4191-87a7-241b7e3f7630'), (b'llm_provider-azureml-model-session', b'd015-20251018173616'), (b'llm_provider-content-length', b'1080'), (b'llm_provider-content-type', b'application/json'), (b'llm_provider-date', b'Thu, 30 Oct 2025 21:43:45 GMT'), (b'llm_provider-strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'llm_provider-x-accel-buffering', b'no'), (b'llm_provider-x-content-type-options', b'nosniff'), (b'llm_provider-x-ms-deployment-name', b'gpt-4o'), (b'llm_provider-x-ms-rai-invoked', b'true'), (b'llm_provider-x-ms-region', b'East US'), (b'llm_provider-x-ratelimit-limit-requests', b'150'), (b'llm_provider-x-ratelimit-limit-tokens', b'150000'), (b'llm_provider-x-ratelimit-remaining-requests', b'145'), (b'llm_provider-x-ratelimit-remaining-tokens', b'120975'), (b'llm_provider-x-request-id', b'14c0f99a-5217-4807-bd88-2488e16bfca1'), (b'Server', b'cloudflare'), (b'x-litellm-attempted-fallbacks', b'0'), (b'x-litellm-attempted-retries', b'0'), (b'x-litellm-call-id', b'fb434fe9-4f42-4c0f-9597-c98763f927ff'), (b'x-litellm-key-spend', b'32.75482440000006'), (b'x-litellm-model-api-base', b'https://science-it-openai.openai.azure.com/'), (b'x-litellm-model-group', b'gpt-4o'), (b'x-litellm-model-id', b'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38'), (b'x-litellm-overhead-duration-ms', b'1.214'), (b'x-litellm-response-cost', b'0.0005'), (b'x-litellm-response-cost-discount-amount', b'0.0'), (b'x-litellm-response-cost-original', b'0.0005'), (b'x-litellm-response-duration-ms', b'401.412'), (b'x-litellm-version', b'1.79.0'), (b'x-ratelimit-limit-requests', b'150'), (b'x-ratelimit-limit-tokens', b'150000'), (b'x-ratelimit-remaining-requests', b'145'), (b'x-ratelimit-remaining-tokens', b'120975'), (b'cf-cache-status', b'DYNAMIC'), (b'vary', b'accept-encoding'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'Set-Cookie', b'__cf_bm=F1TMqa7bxC314_p.gR8YqLJRYthUfwv7fT_C5I1hdCA-1761860626.0625923-1.0.1.1-6qkbRuPOIzTQlnpNq1cG0Eo4CPVvM05chMMZzl.q10OuI_vybsqjJvqt8jrfDA11n7ZdYYKJ4YGlKiuKE6I5XA5nH1S3mXoNyWifBFOaMdaan_ldvgPekNHHl3oDVCWf; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:13:46 GMT'), (b'CF-RAY', b'996e1710efa083d0-EWR')])
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.cborg.lbl.gov/chat/completions "200 OK" Headers({'date': 'Thu, 30 Oct 2025 21:43:46 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'content-encoding': 'gzip', 'llm_provider-apim-request-id': 'a2ca7da7-556f-4191-87a7-241b7e3f7630', 'llm_provider-azureml-model-session': 'd015-20251018173616', 'llm_provider-content-length': '1080', 'llm_provider-content-type': 'application/json', 'llm_provider-date': 'Thu, 30 Oct 2025 21:43:45 GMT', 'llm_provider-strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'llm_provider-x-accel-buffering': 'no', 'llm_provider-x-content-type-options': 'nosniff', 'llm_provider-x-ms-deployment-name': 'gpt-4o', 'llm_provider-x-ms-rai-invoked': 'true', 'llm_provider-x-ms-region': 'East US', 'llm_provider-x-ratelimit-limit-requests': '150', 'llm_provider-x-ratelimit-limit-tokens': '150000', 'llm_provider-x-ratelimit-remaining-requests': '145', 'llm_provider-x-ratelimit-remaining-tokens': '120975', 'llm_provider-x-request-id': '14c0f99a-5217-4807-bd88-2488e16bfca1', 'server': 'cloudflare', 'x-litellm-attempted-fallbacks': '0', 'x-litellm-attempted-retries': '0', 'x-litellm-call-id': 'fb434fe9-4f42-4c0f-9597-c98763f927ff', 'x-litellm-key-spend': '32.75482440000006', 'x-litellm-model-api-base': 'https://science-it-openai.openai.azure.com/', 'x-litellm-model-group': 'gpt-4o', 'x-litellm-model-id': 'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38', 'x-litellm-overhead-duration-ms': '1.214', 'x-litellm-response-cost': '0.0005', 'x-litellm-response-cost-discount-amount': '0.0', 'x-litellm-response-cost-original': '0.0005', 'x-litellm-response-duration-ms': '401.412', 'x-litellm-version': '1.79.0', 'x-ratelimit-limit-requests': '150', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '145', 'x-ratelimit-remaining-tokens': '120975', 'cf-cache-status': 'DYNAMIC', 'vary': 'accept-encoding', 'strict-transport-security': 'max-age=31536000', 'set-cookie': '__cf_bm=F1TMqa7bxC314_p.gR8YqLJRYthUfwv7fT_C5I1hdCA-1761860626.0625923-1.0.1.1-6qkbRuPOIzTQlnpNq1cG0Eo4CPVvM05chMMZzl.q10OuI_vybsqjJvqt8jrfDA11n7ZdYYKJ4YGlKiuKE6I5XA5nH1S3mXoNyWifBFOaMdaan_ldvgPekNHHl3oDVCWf; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:13:46 GMT', 'cf-ray': '996e1710efa083d0-EWR'})
DEBUG:openai._base_client:request_id: None
DEBUG:LiteLLM:RAW RESPONSE:
{"id": "chatcmpl-CWUiofe6sqrLzs7L1OLz5Kd6IfIXN", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "subject: none\npredicate: none\nobject: none", "refusal": null, "role": "assistant", "annotations": [], "audio": null, "function_call": null, "tool_calls": null}, "provider_specific_fields": {"content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}}], "created": 1761860626, "model": "gpt-4o-2024-08-06", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_4a331a0222", "usage": {"completion_tokens": 12, "prompt_tokens": 152, "total_tokens": 164, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}


DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): f26d70e4f0450afbc4349194d9562c8fab96e9e124d5ff5915aa93802944517f
DEBUG:LiteLLM:Final hashed key: f26d70e4f0450afbc4349194d9562c8fab96e9e124d5ff5915aa93802944517f
INFO:LiteLLM:Wrapper: Completed Call, calling success_handler
DEBUG:LiteLLM:response_cost: 0.0005
INFO:root:PARSING LINE: subject: none
DEBUG:root:  FIELD: subject
DEBUG:root:SLOT: subject INL: False VALS: ['none']
INFO:root:PARSING LINE: predicate: none
DEBUG:root:  FIELD: predicate
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call: Cache_hit=None
DEBUG:root:SLOT: predicate INL: None VALS: ['none']
INFO:root:PARSING LINE: object: none
DEBUG:root:  FIELD: object
DEBUG:root:SLOT: object INL: False VALS: ['none']
INFO:root:PARSING LINE: motility_relationships: none
DEBUG:root:  FIELD: motility_relationships
DEBUG:root:SLOT: motility_relationships INL: True VALS: ['none']
DEBUG:root:  RECURSING ON SLOT: motility_relationships, range=MotilityRelationship
INFO:ontogpt.clients.llm_client:Complete: engine=gpt-4o, prompt[380]=Split the following piece of text into fields in the following format:

subject: <the strain with th...
DEBUG:LiteLLM:

DEBUG:LiteLLM:[92mRequest to litellm:[0m
DEBUG:LiteLLM:[92mlitellm.completion(api_key='', api_base='https://api.cborg.lbl.gov', api_version=None, model='gpt-4o', messages=[{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], temperature=1.0, caching=True, custom_llm_provider='openai')[0m
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:

DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call streaming complete
DEBUG:LiteLLM:SYNC kwargs[caching]: True; litellm.cache: <litellm.caching.caching.Cache object at 0x105624f90>; kwargs.get('cache')['no-cache']: False
DEBUG:LiteLLM:INSIDE CHECKING SYNC CACHE
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 756b705927f3a883926ed906f67f8b635d58bde5a4fa5a2664e605c904894881
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:LiteLLM:Final hashed key: 756b705927f3a883926ed906f67f8b635d58bde5a4fa5a2664e605c904894881
INFO:LiteLLM:
LiteLLM completion() model= gpt-4o; provider = openai
DEBUG:LiteLLM:
LiteLLM: Params passed to completion() {'model': 'gpt-4o', 'functions': None, 'function_call': None, 'temperature': 1.0, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
DEBUG:LiteLLM:
LiteLLM: Non-Default params passed to completion() {'temperature': 1.0}
DEBUG:LiteLLM:Final returned optional params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:self.optional_params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o', 'combined_model_name': 'openai/gpt-4o', 'stripped_model_name': 'gpt-4o', 'combined_stripped_model_name': 'openai/gpt-4o', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.cborg.lbl.gov \
-d '{'model': 'gpt-4o', 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], 'temperature': 1.0, 'extra_body': {}}'
[0m

DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-18b7cea3-1a5f-4b53-8baa-abf04541a352', 'json_data': {'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], 'model': 'gpt-4o', 'temperature': 1.0}, 'extra_json': {}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.cborg.lbl.gov/chat/completions
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 30 Oct 2025 21:43:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'llm_provider-apim-request-id', b'c057b89e-15af-481a-8551-d70bb1ef4b30'), (b'llm_provider-azureml-model-session', b'd015-20251018173616'), (b'llm_provider-content-length', b'1086'), (b'llm_provider-content-type', b'application/json'), (b'llm_provider-date', b'Thu, 30 Oct 2025 21:43:46 GMT'), (b'llm_provider-strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'llm_provider-x-accel-buffering', b'no'), (b'llm_provider-x-content-type-options', b'nosniff'), (b'llm_provider-x-ms-deployment-name', b'gpt-4o'), (b'llm_provider-x-ms-rai-invoked', b'true'), (b'llm_provider-x-ms-region', b'East US'), (b'llm_provider-x-ratelimit-limit-requests', b'150'), (b'llm_provider-x-ratelimit-limit-tokens', b'150000'), (b'llm_provider-x-ratelimit-remaining-requests', b'144'), (b'llm_provider-x-ratelimit-remaining-tokens', b'120813'), (b'llm_provider-x-request-id', b'7170558a-06f4-43a7-a20c-50c9b0419968'), (b'Server', b'cloudflare'), (b'x-litellm-attempted-fallbacks', b'0'), (b'x-litellm-attempted-retries', b'0'), (b'x-litellm-call-id', b'efef5986-1a20-4d2d-a88f-100705b970fe'), (b'x-litellm-key-spend', b'32.75532440000006'), (b'x-litellm-model-api-base', b'https://science-it-openai.openai.azure.com/'), (b'x-litellm-model-group', b'gpt-4o'), (b'x-litellm-model-id', b'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38'), (b'x-litellm-overhead-duration-ms', b'1.227'), (b'x-litellm-response-cost', b'0.000515'), (b'x-litellm-response-cost-discount-amount', b'0.0'), (b'x-litellm-response-cost-original', b'0.000515'), (b'x-litellm-response-duration-ms', b'336.65299999999996'), (b'x-litellm-version', b'1.79.0'), (b'x-ratelimit-limit-requests', b'150'), (b'x-ratelimit-limit-tokens', b'150000'), (b'x-ratelimit-remaining-requests', b'144'), (b'x-ratelimit-remaining-tokens', b'120813'), (b'cf-cache-status', b'DYNAMIC'), (b'vary', b'accept-encoding'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'Set-Cookie', b'__cf_bm=iiPZbU_UK1vFymdoLpvKcStzts6oiqtOC_cvS3rdhfU-1761860626.5989847-1.0.1.1-ezkxi.tESqvgpX6E28gx2TCabzx5gKt0kuiccL8zhTGUA5g2N5.LfRIavyAxA6urI8wi8Wrh_r_MxwFoWuSoeuM60N7.e8hy0YUi5p88Ox4xbXj391eAMGOEyzeDQyD9; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:13:47 GMT'), (b'CF-RAY', b'996e1714397c83d0-EWR')])
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.cborg.lbl.gov/chat/completions "200 OK" Headers({'date': 'Thu, 30 Oct 2025 21:43:47 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'content-encoding': 'gzip', 'llm_provider-apim-request-id': 'c057b89e-15af-481a-8551-d70bb1ef4b30', 'llm_provider-azureml-model-session': 'd015-20251018173616', 'llm_provider-content-length': '1086', 'llm_provider-content-type': 'application/json', 'llm_provider-date': 'Thu, 30 Oct 2025 21:43:46 GMT', 'llm_provider-strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'llm_provider-x-accel-buffering': 'no', 'llm_provider-x-content-type-options': 'nosniff', 'llm_provider-x-ms-deployment-name': 'gpt-4o', 'llm_provider-x-ms-rai-invoked': 'true', 'llm_provider-x-ms-region': 'East US', 'llm_provider-x-ratelimit-limit-requests': '150', 'llm_provider-x-ratelimit-limit-tokens': '150000', 'llm_provider-x-ratelimit-remaining-requests': '144', 'llm_provider-x-ratelimit-remaining-tokens': '120813', 'llm_provider-x-request-id': '7170558a-06f4-43a7-a20c-50c9b0419968', 'server': 'cloudflare', 'x-litellm-attempted-fallbacks': '0', 'x-litellm-attempted-retries': '0', 'x-litellm-call-id': 'efef5986-1a20-4d2d-a88f-100705b970fe', 'x-litellm-key-spend': '32.75532440000006', 'x-litellm-model-api-base': 'https://science-it-openai.openai.azure.com/', 'x-litellm-model-group': 'gpt-4o', 'x-litellm-model-id': 'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38', 'x-litellm-overhead-duration-ms': '1.227', 'x-litellm-response-cost': '0.000515', 'x-litellm-response-cost-discount-amount': '0.0', 'x-litellm-response-cost-original': '0.000515', 'x-litellm-response-duration-ms': '336.65299999999996', 'x-litellm-version': '1.79.0', 'x-ratelimit-limit-requests': '150', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '144', 'x-ratelimit-remaining-tokens': '120813', 'cf-cache-status': 'DYNAMIC', 'vary': 'accept-encoding', 'strict-transport-security': 'max-age=31536000', 'set-cookie': '__cf_bm=iiPZbU_UK1vFymdoLpvKcStzts6oiqtOC_cvS3rdhfU-1761860626.5989847-1.0.1.1-ezkxi.tESqvgpX6E28gx2TCabzx5gKt0kuiccL8zhTGUA5g2N5.LfRIavyAxA6urI8wi8Wrh_r_MxwFoWuSoeuM60N7.e8hy0YUi5p88Ox4xbXj391eAMGOEyzeDQyD9; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:13:47 GMT', 'cf-ray': '996e1714397c83d0-EWR'})
DEBUG:openai._base_client:request_id: None
DEBUG:LiteLLM:RAW RESPONSE:
{"id": "chatcmpl-CWUioBCWwWbl0bw5Auf6gS6tt7y99", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "subject: none  \npredicate: none  \nobject: none  ", "refusal": null, "role": "assistant", "annotations": [], "audio": null, "function_call": null, "tool_calls": null}, "provider_specific_fields": {"content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}}], "created": 1761860626, "model": "gpt-4o-2024-08-06", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_4a331a0222", "usage": {"completion_tokens": 13, "prompt_tokens": 154, "total_tokens": 167, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}


DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 756b705927f3a883926ed906f67f8b635d58bde5a4fa5a2664e605c904894881
DEBUG:LiteLLM:Final hashed key: 756b705927f3a883926ed906f67f8b635d58bde5a4fa5a2664e605c904894881
INFO:LiteLLM:Wrapper: Completed Call, calling success_handler
DEBUG:LiteLLM:response_cost: 0.000515
INFO:root:PARSING LINE: subject: none
DEBUG:root:  FIELD: subject
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call: Cache_hit=None
DEBUG:root:SLOT: subject INL: False VALS: ['none']
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
INFO:root:PARSING LINE: predicate: none
DEBUG:root:  FIELD: predicate
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:root:SLOT: predicate INL: None VALS: ['none']
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call streaming complete
INFO:root:PARSING LINE: object: none
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:  FIELD: object
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:root:SLOT: object INL: False VALS: ['none']
INFO:root:PARSING LINE: spore_formation_relationships: none
DEBUG:root:  FIELD: spore_formation_relationships
DEBUG:root:SLOT: spore_formation_relationships INL: True VALS: ['none']
DEBUG:root:  RECURSING ON SLOT: spore_formation_relationships, range=SporeFormationRelationship
INFO:ontogpt.clients.llm_client:Complete: engine=gpt-4o, prompt[401]=Split the following piece of text into fields in the following format:

subject: <the strain with th...
DEBUG:LiteLLM:

DEBUG:LiteLLM:[92mRequest to litellm:[0m
DEBUG:LiteLLM:[92mlitellm.completion(api_key='', api_base='https://api.cborg.lbl.gov', api_version=None, model='gpt-4o', messages=[{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this spore formation characteristic>\npredicate: <the type of spore formation relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific spore formation characteristic>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], temperature=1.0, caching=True, custom_llm_provider='openai')[0m
DEBUG:LiteLLM:

DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:SYNC kwargs[caching]: True; litellm.cache: <litellm.caching.caching.Cache object at 0x105624f90>; kwargs.get('cache')['no-cache']: False
DEBUG:LiteLLM:INSIDE CHECKING SYNC CACHE
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this spore formation characteristic>\npredicate: <the type of spore formation relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific spore formation characteristic>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 6dbdeb3d8cd28326fa067aec9da0e62ef1c10d5ee4e193856246efb6c1d128eb
DEBUG:LiteLLM:Final hashed key: 6dbdeb3d8cd28326fa067aec9da0e62ef1c10d5ee4e193856246efb6c1d128eb
INFO:LiteLLM:
LiteLLM completion() model= gpt-4o; provider = openai
DEBUG:LiteLLM:
LiteLLM: Params passed to completion() {'model': 'gpt-4o', 'functions': None, 'function_call': None, 'temperature': 1.0, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this spore formation characteristic>\npredicate: <the type of spore formation relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific spore formation characteristic>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
DEBUG:LiteLLM:
LiteLLM: Non-Default params passed to completion() {'temperature': 1.0}
DEBUG:LiteLLM:Final returned optional params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:self.optional_params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o', 'combined_model_name': 'openai/gpt-4o', 'stripped_model_name': 'gpt-4o', 'combined_stripped_model_name': 'openai/gpt-4o', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.cborg.lbl.gov \
-d '{'model': 'gpt-4o', 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this spore formation characteristic>\npredicate: <the type of spore formation relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific spore formation characteristic>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], 'temperature': 1.0, 'extra_body': {}}'
[0m

DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-312fb736-78e5-4e98-9c61-681d98dc63c6', 'json_data': {'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this spore formation characteristic>\npredicate: <the type of spore formation relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific spore formation characteristic>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], 'model': 'gpt-4o', 'temperature': 1.0}, 'extra_json': {}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.cborg.lbl.gov/chat/completions
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 30 Oct 2025 21:43:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'llm_provider-apim-request-id', b'8e801722-8e86-4972-9d22-44dbbef26490'), (b'llm_provider-azureml-model-session', b'd015-20251018173616'), (b'llm_provider-content-length', b'1086'), (b'llm_provider-content-type', b'application/json'), (b'llm_provider-date', b'Thu, 30 Oct 2025 21:43:46 GMT'), (b'llm_provider-strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'llm_provider-x-accel-buffering', b'no'), (b'llm_provider-x-content-type-options', b'nosniff'), (b'llm_provider-x-ms-deployment-name', b'gpt-4o'), (b'llm_provider-x-ms-rai-invoked', b'true'), (b'llm_provider-x-ms-region', b'East US'), (b'llm_provider-x-ratelimit-limit-requests', b'150'), (b'llm_provider-x-ratelimit-limit-tokens', b'150000'), (b'llm_provider-x-ratelimit-remaining-requests', b'143'), (b'llm_provider-x-ratelimit-remaining-tokens', b'120646'), (b'llm_provider-x-request-id', b'20c58243-1990-47da-a997-e5099d600328'), (b'Server', b'cloudflare'), (b'x-litellm-attempted-fallbacks', b'0'), (b'x-litellm-attempted-retries', b'0'), (b'x-litellm-call-id', b'145e187e-65f3-459b-8c4e-e6a65f5d3dce'), (b'x-litellm-key-spend', b'32.75583940000006'), (b'x-litellm-model-api-base', b'https://science-it-openai.openai.azure.com/'), (b'x-litellm-model-group', b'gpt-4o'), (b'x-litellm-model-id', b'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38'), (b'x-litellm-overhead-duration-ms', b'2.348'), (b'x-litellm-response-cost', b'0.0005225000000000001'), (b'x-litellm-response-cost-discount-amount', b'0.0'), (b'x-litellm-response-cost-original', b'0.0005225000000000001'), (b'x-litellm-response-duration-ms', b'330.60200000000003'), (b'x-litellm-version', b'1.79.0'), (b'x-ratelimit-limit-requests', b'150'), (b'x-ratelimit-limit-tokens', b'150000'), (b'x-ratelimit-remaining-requests', b'143'), (b'x-ratelimit-remaining-tokens', b'120646'), (b'cf-cache-status', b'DYNAMIC'), (b'vary', b'accept-encoding'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'Set-Cookie', b'__cf_bm=4oormfP1AzAKF.iZhxxzjgDRGQY534FtqtjikzA7.24-1761860627.065469-1.0.1.1-WrjnQEByWoR3PdnT3FUXJqkwYG60ut3qPRGj5IRo97AR0ugp.oqiMZogdoYlCLlLR5fwcWDdjJX1RmNnK6el_UhBcS4ArL7Oi_NyixD.ye9gFPyuZAKLItW2BDRe69xA; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:13:47 GMT'), (b'CF-RAY', b'996e17172a3283d0-EWR')])
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.cborg.lbl.gov/chat/completions "200 OK" Headers({'date': 'Thu, 30 Oct 2025 21:43:47 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'content-encoding': 'gzip', 'llm_provider-apim-request-id': '8e801722-8e86-4972-9d22-44dbbef26490', 'llm_provider-azureml-model-session': 'd015-20251018173616', 'llm_provider-content-length': '1086', 'llm_provider-content-type': 'application/json', 'llm_provider-date': 'Thu, 30 Oct 2025 21:43:46 GMT', 'llm_provider-strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'llm_provider-x-accel-buffering': 'no', 'llm_provider-x-content-type-options': 'nosniff', 'llm_provider-x-ms-deployment-name': 'gpt-4o', 'llm_provider-x-ms-rai-invoked': 'true', 'llm_provider-x-ms-region': 'East US', 'llm_provider-x-ratelimit-limit-requests': '150', 'llm_provider-x-ratelimit-limit-tokens': '150000', 'llm_provider-x-ratelimit-remaining-requests': '143', 'llm_provider-x-ratelimit-remaining-tokens': '120646', 'llm_provider-x-request-id': '20c58243-1990-47da-a997-e5099d600328', 'server': 'cloudflare', 'x-litellm-attempted-fallbacks': '0', 'x-litellm-attempted-retries': '0', 'x-litellm-call-id': '145e187e-65f3-459b-8c4e-e6a65f5d3dce', 'x-litellm-key-spend': '32.75583940000006', 'x-litellm-model-api-base': 'https://science-it-openai.openai.azure.com/', 'x-litellm-model-group': 'gpt-4o', 'x-litellm-model-id': 'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38', 'x-litellm-overhead-duration-ms': '2.348', 'x-litellm-response-cost': '0.0005225000000000001', 'x-litellm-response-cost-discount-amount': '0.0', 'x-litellm-response-cost-original': '0.0005225000000000001', 'x-litellm-response-duration-ms': '330.60200000000003', 'x-litellm-version': '1.79.0', 'x-ratelimit-limit-requests': '150', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '143', 'x-ratelimit-remaining-tokens': '120646', 'cf-cache-status': 'DYNAMIC', 'vary': 'accept-encoding', 'strict-transport-security': 'max-age=31536000', 'set-cookie': '__cf_bm=4oormfP1AzAKF.iZhxxzjgDRGQY534FtqtjikzA7.24-1761860627.065469-1.0.1.1-WrjnQEByWoR3PdnT3FUXJqkwYG60ut3qPRGj5IRo97AR0ugp.oqiMZogdoYlCLlLR5fwcWDdjJX1RmNnK6el_UhBcS4ArL7Oi_NyixD.ye9gFPyuZAKLItW2BDRe69xA; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:13:47 GMT', 'cf-ray': '996e17172a3283d0-EWR'})
DEBUG:openai._base_client:request_id: None
DEBUG:LiteLLM:RAW RESPONSE:
{"id": "chatcmpl-CWUipxQemtfQaqa6yKDKx2HkR8DN9", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "subject: none  \npredicate: none  \nobject: none  ", "refusal": null, "role": "assistant", "annotations": [], "audio": null, "function_call": null, "tool_calls": null}, "provider_specific_fields": {"content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}}], "created": 1761860627, "model": "gpt-4o-2024-08-06", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_4a331a0222", "usage": {"completion_tokens": 13, "prompt_tokens": 157, "total_tokens": 170, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}


DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this spore formation characteristic>\npredicate: <the type of spore formation relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific spore formation characteristic>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 6dbdeb3d8cd28326fa067aec9da0e62ef1c10d5ee4e193856246efb6c1d128eb
DEBUG:LiteLLM:Final hashed key: 6dbdeb3d8cd28326fa067aec9da0e62ef1c10d5ee4e193856246efb6c1d128eb
INFO:LiteLLM:Wrapper: Completed Call, calling success_handler
DEBUG:LiteLLM:response_cost: 0.0005225000000000001
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call: Cache_hit=None
INFO:root:PARSING LINE: subject: none
DEBUG:root:  FIELD: subject
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:SLOT: subject INL: False VALS: ['none']
INFO:root:PARSING LINE: predicate: none
DEBUG:root:  FIELD: predicate
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:root:SLOT: predicate INL: None VALS: ['none']
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call streaming complete
INFO:root:PARSING LINE: object: none
DEBUG:root:  FIELD: object
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:SLOT: object INL: False VALS: ['none']
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
INFO:root:PARSING LINE: cell_wall_relationships: none
DEBUG:root:  FIELD: cell_wall_relationships
DEBUG:root:SLOT: cell_wall_relationships INL: True VALS: ['none']
DEBUG:root:  RECURSING ON SLOT: cell_wall_relationships, range=CellWallRelationship
INFO:ontogpt.clients.llm_client:Complete: engine=gpt-4o, prompt[383]=Split the following piece of text into fields in the following format:

subject: <the strain with th...
DEBUG:LiteLLM:

DEBUG:LiteLLM:[92mRequest to litellm:[0m
DEBUG:LiteLLM:[92mlitellm.completion(api_key='', api_base='https://api.cborg.lbl.gov', api_version=None, model='gpt-4o', messages=[{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cell wall characteristic>\npredicate: <the type of cell wall relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cell wall characteristic>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], temperature=1.0, caching=True, custom_llm_provider='openai')[0m
DEBUG:LiteLLM:

DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:SYNC kwargs[caching]: True; litellm.cache: <litellm.caching.caching.Cache object at 0x105624f90>; kwargs.get('cache')['no-cache']: False
DEBUG:LiteLLM:INSIDE CHECKING SYNC CACHE
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cell wall characteristic>\npredicate: <the type of cell wall relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cell wall characteristic>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 737e897e73b513c22e3e0e6ed36cdf0f10d4fb603eff7f31b351f35e7658a182
DEBUG:LiteLLM:Final hashed key: 737e897e73b513c22e3e0e6ed36cdf0f10d4fb603eff7f31b351f35e7658a182
INFO:LiteLLM:
LiteLLM completion() model= gpt-4o; provider = openai
DEBUG:LiteLLM:
LiteLLM: Params passed to completion() {'model': 'gpt-4o', 'functions': None, 'function_call': None, 'temperature': 1.0, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cell wall characteristic>\npredicate: <the type of cell wall relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cell wall characteristic>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
DEBUG:LiteLLM:
LiteLLM: Non-Default params passed to completion() {'temperature': 1.0}
DEBUG:LiteLLM:Final returned optional params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:self.optional_params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o', 'combined_model_name': 'openai/gpt-4o', 'stripped_model_name': 'gpt-4o', 'combined_stripped_model_name': 'openai/gpt-4o', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.cborg.lbl.gov \
-d '{'model': 'gpt-4o', 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cell wall characteristic>\npredicate: <the type of cell wall relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cell wall characteristic>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], 'temperature': 1.0, 'extra_body': {}}'
[0m

DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-559ef5d4-02c9-4ce4-800c-2ab6a5200e78', 'json_data': {'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cell wall characteristic>\npredicate: <the type of cell wall relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cell wall characteristic>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], 'model': 'gpt-4o', 'temperature': 1.0}, 'extra_json': {}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.cborg.lbl.gov/chat/completions
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 30 Oct 2025 21:43:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'llm_provider-apim-request-id', b'bac6437e-7248-4e2d-89ee-19806d952ea2'), (b'llm_provider-azureml-model-session', b'd015-20251018173616'), (b'llm_provider-content-length', b'1086'), (b'llm_provider-content-type', b'application/json'), (b'llm_provider-date', b'Thu, 30 Oct 2025 21:43:46 GMT'), (b'llm_provider-strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'llm_provider-x-accel-buffering', b'no'), (b'llm_provider-x-content-type-options', b'nosniff'), (b'llm_provider-x-ms-deployment-name', b'gpt-4o'), (b'llm_provider-x-ms-rai-invoked', b'true'), (b'llm_provider-x-ms-region', b'East US'), (b'llm_provider-x-ratelimit-limit-requests', b'150'), (b'llm_provider-x-ratelimit-limit-tokens', b'150000'), (b'llm_provider-x-ratelimit-remaining-requests', b'141'), (b'llm_provider-x-ratelimit-remaining-tokens', b'118529'), (b'llm_provider-x-request-id', b'a1d2dcd1-750e-4907-9c6a-7b26f084628d'), (b'Server', b'cloudflare'), (b'x-litellm-attempted-fallbacks', b'0'), (b'x-litellm-attempted-retries', b'0'), (b'x-litellm-call-id', b'3bc1dda4-605d-48aa-80b9-7b638a1f2803'), (b'x-litellm-key-spend', b'32.756361900000066'), (b'x-litellm-model-api-base', b'https://science-it-openai.openai.azure.com/'), (b'x-litellm-model-group', b'gpt-4o'), (b'x-litellm-model-id', b'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38'), (b'x-litellm-overhead-duration-ms', b'1.206'), (b'x-litellm-response-cost', b'0.000515'), (b'x-litellm-response-cost-discount-amount', b'0.0'), (b'x-litellm-response-cost-original', b'0.000515'), (b'x-litellm-response-duration-ms', b'335.699'), (b'x-litellm-version', b'1.79.0'), (b'x-ratelimit-limit-requests', b'150'), (b'x-ratelimit-limit-tokens', b'150000'), (b'x-ratelimit-remaining-requests', b'141'), (b'x-ratelimit-remaining-tokens', b'118529'), (b'cf-cache-status', b'DYNAMIC'), (b'vary', b'accept-encoding'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'Set-Cookie', b'__cf_bm=N0uuwXh9QqP4a__P7wrOQ3weSaDFKLG6PgxmKJtw0fQ-1761860627.5334077-1.0.1.1-NcQEsdg9Abg1u.zgXbT6qMo2Q76kkm60usupjlwtNRfJuA4n8EBsSxwGweIYsaV8yy7KEONObPlfkVWgYy3nMkbDVbMj3nSnNGvuB5MQeEnPi45QfsOnOjfw7alHt6OI; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:13:47 GMT'), (b'CF-RAY', b'996e171a1a1f83d0-EWR')])
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.cborg.lbl.gov/chat/completions "200 OK" Headers({'date': 'Thu, 30 Oct 2025 21:43:47 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'content-encoding': 'gzip', 'llm_provider-apim-request-id': 'bac6437e-7248-4e2d-89ee-19806d952ea2', 'llm_provider-azureml-model-session': 'd015-20251018173616', 'llm_provider-content-length': '1086', 'llm_provider-content-type': 'application/json', 'llm_provider-date': 'Thu, 30 Oct 2025 21:43:46 GMT', 'llm_provider-strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'llm_provider-x-accel-buffering': 'no', 'llm_provider-x-content-type-options': 'nosniff', 'llm_provider-x-ms-deployment-name': 'gpt-4o', 'llm_provider-x-ms-rai-invoked': 'true', 'llm_provider-x-ms-region': 'East US', 'llm_provider-x-ratelimit-limit-requests': '150', 'llm_provider-x-ratelimit-limit-tokens': '150000', 'llm_provider-x-ratelimit-remaining-requests': '141', 'llm_provider-x-ratelimit-remaining-tokens': '118529', 'llm_provider-x-request-id': 'a1d2dcd1-750e-4907-9c6a-7b26f084628d', 'server': 'cloudflare', 'x-litellm-attempted-fallbacks': '0', 'x-litellm-attempted-retries': '0', 'x-litellm-call-id': '3bc1dda4-605d-48aa-80b9-7b638a1f2803', 'x-litellm-key-spend': '32.756361900000066', 'x-litellm-model-api-base': 'https://science-it-openai.openai.azure.com/', 'x-litellm-model-group': 'gpt-4o', 'x-litellm-model-id': 'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38', 'x-litellm-overhead-duration-ms': '1.206', 'x-litellm-response-cost': '0.000515', 'x-litellm-response-cost-discount-amount': '0.0', 'x-litellm-response-cost-original': '0.000515', 'x-litellm-response-duration-ms': '335.699', 'x-litellm-version': '1.79.0', 'x-ratelimit-limit-requests': '150', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '141', 'x-ratelimit-remaining-tokens': '118529', 'cf-cache-status': 'DYNAMIC', 'vary': 'accept-encoding', 'strict-transport-security': 'max-age=31536000', 'set-cookie': '__cf_bm=N0uuwXh9QqP4a__P7wrOQ3weSaDFKLG6PgxmKJtw0fQ-1761860627.5334077-1.0.1.1-NcQEsdg9Abg1u.zgXbT6qMo2Q76kkm60usupjlwtNRfJuA4n8EBsSxwGweIYsaV8yy7KEONObPlfkVWgYy3nMkbDVbMj3nSnNGvuB5MQeEnPi45QfsOnOjfw7alHt6OI; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:13:47 GMT', 'cf-ray': '996e171a1a1f83d0-EWR'})
DEBUG:openai._base_client:request_id: None
DEBUG:LiteLLM:RAW RESPONSE:
{"id": "chatcmpl-CWUipfrPsybcje6cV2KsYCGMxEPwI", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "subject: none  \npredicate: none  \nobject: none  ", "refusal": null, "role": "assistant", "annotations": [], "audio": null, "function_call": null, "tool_calls": null}, "provider_specific_fields": {"content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}}], "created": 1761860627, "model": "gpt-4o-2024-08-06", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_4a331a0222", "usage": {"completion_tokens": 13, "prompt_tokens": 154, "total_tokens": 167, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}


DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cell wall characteristic>\npredicate: <the type of cell wall relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cell wall characteristic>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 737e897e73b513c22e3e0e6ed36cdf0f10d4fb603eff7f31b351f35e7658a182
DEBUG:LiteLLM:Final hashed key: 737e897e73b513c22e3e0e6ed36cdf0f10d4fb603eff7f31b351f35e7658a182
INFO:LiteLLM:Wrapper: Completed Call, calling success_handler
DEBUG:LiteLLM:response_cost: 0.000515
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call: Cache_hit=None
INFO:root:PARSING LINE: subject: none
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:  FIELD: subject
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:root:SLOT: subject INL: False VALS: ['none']
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call streaming complete
INFO:root:PARSING LINE: predicate: none
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:  FIELD: predicate
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:root:SLOT: predicate INL: None VALS: ['none']
INFO:root:PARSING LINE: object: none
DEBUG:root:  FIELD: object
DEBUG:root:SLOT: object INL: False VALS: ['none']
INFO:root:PARSING LINE: cellular_inclusion_relationships: none
DEBUG:root:  FIELD: cellular_inclusion_relationships
DEBUG:root:SLOT: cellular_inclusion_relationships INL: True VALS: ['none']
DEBUG:root:  RECURSING ON SLOT: cellular_inclusion_relationships, range=CellularInclusionRelationship
INFO:ontogpt.clients.llm_client:Complete: engine=gpt-4o, prompt[380]=Split the following piece of text into fields in the following format:

subject: <the strain with th...
DEBUG:LiteLLM:

DEBUG:LiteLLM:[92mRequest to litellm:[0m
DEBUG:LiteLLM:[92mlitellm.completion(api_key='', api_base='https://api.cborg.lbl.gov', api_version=None, model='gpt-4o', messages=[{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cellular inclusion>\npredicate: <the type of cellular inclusion relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cellular inclusion>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], temperature=1.0, caching=True, custom_llm_provider='openai')[0m
DEBUG:LiteLLM:

DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:SYNC kwargs[caching]: True; litellm.cache: <litellm.caching.caching.Cache object at 0x105624f90>; kwargs.get('cache')['no-cache']: False
DEBUG:LiteLLM:INSIDE CHECKING SYNC CACHE
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cellular inclusion>\npredicate: <the type of cellular inclusion relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cellular inclusion>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 0b1c626018000ce59bbbd789e9d8cf681e8577779859bf415c3e7685b4dfbb3e
DEBUG:LiteLLM:Final hashed key: 0b1c626018000ce59bbbd789e9d8cf681e8577779859bf415c3e7685b4dfbb3e
INFO:LiteLLM:
LiteLLM completion() model= gpt-4o; provider = openai
DEBUG:LiteLLM:
LiteLLM: Params passed to completion() {'model': 'gpt-4o', 'functions': None, 'function_call': None, 'temperature': 1.0, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cellular inclusion>\npredicate: <the type of cellular inclusion relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cellular inclusion>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
DEBUG:LiteLLM:
LiteLLM: Non-Default params passed to completion() {'temperature': 1.0}
DEBUG:LiteLLM:Final returned optional params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:self.optional_params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o', 'combined_model_name': 'openai/gpt-4o', 'stripped_model_name': 'gpt-4o', 'combined_stripped_model_name': 'openai/gpt-4o', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.cborg.lbl.gov \
-d '{'model': 'gpt-4o', 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cellular inclusion>\npredicate: <the type of cellular inclusion relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cellular inclusion>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], 'temperature': 1.0, 'extra_body': {}}'
[0m

DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-cdc91dad-4544-44dd-80cb-77e918d77adf', 'json_data': {'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cellular inclusion>\npredicate: <the type of cellular inclusion relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cellular inclusion>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], 'model': 'gpt-4o', 'temperature': 1.0}, 'extra_json': {}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.cborg.lbl.gov/chat/completions
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 30 Oct 2025 21:43:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'llm_provider-apim-request-id', b'ac216176-4b27-4678-aefc-b865b4683f97'), (b'llm_provider-azureml-model-session', b'd015-20251018173616'), (b'llm_provider-content-length', b'1084'), (b'llm_provider-content-type', b'application/json'), (b'llm_provider-date', b'Thu, 30 Oct 2025 21:43:48 GMT'), (b'llm_provider-strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'llm_provider-x-accel-buffering', b'no'), (b'llm_provider-x-content-type-options', b'nosniff'), (b'llm_provider-x-ms-deployment-name', b'gpt-4o'), (b'llm_provider-x-ms-rai-invoked', b'true'), (b'llm_provider-x-ms-region', b'East US'), (b'llm_provider-x-ratelimit-limit-requests', b'150'), (b'llm_provider-x-ratelimit-limit-tokens', b'150000'), (b'llm_provider-x-ratelimit-remaining-requests', b'139'), (b'llm_provider-x-ratelimit-remaining-tokens', b'116400'), (b'llm_provider-x-request-id', b'86571a73-a384-40ac-ae4c-f04c789f3f56'), (b'Server', b'cloudflare'), (b'x-litellm-attempted-fallbacks', b'0'), (b'x-litellm-attempted-retries', b'0'), (b'x-litellm-call-id', b'd2d2042c-79f9-4e40-8419-27f80d598eeb'), (b'x-litellm-key-spend', b'32.74315190000005'), (b'x-litellm-model-api-base', b'https://science-it-openai.openai.azure.com/'), (b'x-litellm-model-group', b'gpt-4o'), (b'x-litellm-model-id', b'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38'), (b'x-litellm-overhead-duration-ms', b'1.331'), (b'x-litellm-response-cost', b'0.0005'), (b'x-litellm-response-cost-discount-amount', b'0.0'), (b'x-litellm-response-cost-original', b'0.0005'), (b'x-litellm-response-duration-ms', b'312.654'), (b'x-litellm-version', b'1.79.0'), (b'x-ratelimit-limit-requests', b'150'), (b'x-ratelimit-limit-tokens', b'150000'), (b'x-ratelimit-remaining-requests', b'139'), (b'x-ratelimit-remaining-tokens', b'116400'), (b'cf-cache-status', b'DYNAMIC'), (b'vary', b'accept-encoding'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'Set-Cookie', b'__cf_bm=MhJFUTb70IfJYRPNnF6IuFHOKaFB1OWJK0Lf0MEzz2E-1761860628.0002484-1.0.1.1-TnKD.o9ELN20dfiL7.C7q2uKOqvv2G2iKKNYy6.Z_SyGjyWpWu2FGLOUmfn7IcXj1yKLvtW56mc3mq5JD8CV2vDMHjrogJXLvm5H.whKbpg.mCPNmQTayUwD2P9EnmHQ; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:13:48 GMT'), (b'CF-RAY', b'996e171cfb5083d0-EWR')])
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.cborg.lbl.gov/chat/completions "200 OK" Headers({'date': 'Thu, 30 Oct 2025 21:43:48 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'content-encoding': 'gzip', 'llm_provider-apim-request-id': 'ac216176-4b27-4678-aefc-b865b4683f97', 'llm_provider-azureml-model-session': 'd015-20251018173616', 'llm_provider-content-length': '1084', 'llm_provider-content-type': 'application/json', 'llm_provider-date': 'Thu, 30 Oct 2025 21:43:48 GMT', 'llm_provider-strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'llm_provider-x-accel-buffering': 'no', 'llm_provider-x-content-type-options': 'nosniff', 'llm_provider-x-ms-deployment-name': 'gpt-4o', 'llm_provider-x-ms-rai-invoked': 'true', 'llm_provider-x-ms-region': 'East US', 'llm_provider-x-ratelimit-limit-requests': '150', 'llm_provider-x-ratelimit-limit-tokens': '150000', 'llm_provider-x-ratelimit-remaining-requests': '139', 'llm_provider-x-ratelimit-remaining-tokens': '116400', 'llm_provider-x-request-id': '86571a73-a384-40ac-ae4c-f04c789f3f56', 'server': 'cloudflare', 'x-litellm-attempted-fallbacks': '0', 'x-litellm-attempted-retries': '0', 'x-litellm-call-id': 'd2d2042c-79f9-4e40-8419-27f80d598eeb', 'x-litellm-key-spend': '32.74315190000005', 'x-litellm-model-api-base': 'https://science-it-openai.openai.azure.com/', 'x-litellm-model-group': 'gpt-4o', 'x-litellm-model-id': 'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38', 'x-litellm-overhead-duration-ms': '1.331', 'x-litellm-response-cost': '0.0005', 'x-litellm-response-cost-discount-amount': '0.0', 'x-litellm-response-cost-original': '0.0005', 'x-litellm-response-duration-ms': '312.654', 'x-litellm-version': '1.79.0', 'x-ratelimit-limit-requests': '150', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '139', 'x-ratelimit-remaining-tokens': '116400', 'cf-cache-status': 'DYNAMIC', 'vary': 'accept-encoding', 'strict-transport-security': 'max-age=31536000', 'set-cookie': '__cf_bm=MhJFUTb70IfJYRPNnF6IuFHOKaFB1OWJK0Lf0MEzz2E-1761860628.0002484-1.0.1.1-TnKD.o9ELN20dfiL7.C7q2uKOqvv2G2iKKNYy6.Z_SyGjyWpWu2FGLOUmfn7IcXj1yKLvtW56mc3mq5JD8CV2vDMHjrogJXLvm5H.whKbpg.mCPNmQTayUwD2P9EnmHQ; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:13:48 GMT', 'cf-ray': '996e171cfb5083d0-EWR'})
DEBUG:openai._base_client:request_id: None
DEBUG:LiteLLM:RAW RESPONSE:
{"id": "chatcmpl-CWUiq5s0Fd8FipYDDxkLWr2p1RF6r", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "subject: none  \npredicate: none  \nobject: none", "refusal": null, "role": "assistant", "annotations": [], "audio": null, "function_call": null, "tool_calls": null}, "provider_specific_fields": {"content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}}], "created": 1761860628, "model": "gpt-4o-2024-08-06", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_4a331a0222", "usage": {"completion_tokens": 12, "prompt_tokens": 152, "total_tokens": 164, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}


DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cellular inclusion>\npredicate: <the type of cellular inclusion relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cellular inclusion>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 0b1c626018000ce59bbbd789e9d8cf681e8577779859bf415c3e7685b4dfbb3e
DEBUG:LiteLLM:Final hashed key: 0b1c626018000ce59bbbd789e9d8cf681e8577779859bf415c3e7685b4dfbb3e
INFO:LiteLLM:Wrapper: Completed Call, calling success_handler
DEBUG:LiteLLM:response_cost: 0.0005
INFO:root:PARSING LINE: subject: none
DEBUG:root:  FIELD: subject
DEBUG:root:SLOT: subject INL: False VALS: ['none']
INFO:root:PARSING LINE: predicate: none
DEBUG:root:  FIELD: predicate
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call: Cache_hit=None
DEBUG:root:SLOT: predicate INL: None VALS: ['none']
INFO:root:PARSING LINE: object: none
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:  FIELD: object
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:root:SLOT: object INL: False VALS: ['none']
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call streaming complete
INFO:root:PARSING LINE: pigmentation: none
DEBUG:root:  FIELD: pigmentation
DEBUG:root:SLOT: pigmentation INL: False VALS: ['none']
INFO:root:PARSING LINE: strain_relationships: none
DEBUG:root:  FIELD: strain_relationships
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:SLOT: strain_relationships INL: True VALS: ['none']
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:root:  RECURSING ON SLOT: strain_relationships, range=StrainRelationship
INFO:ontogpt.clients.llm_client:Complete: engine=gpt-4o, prompt[434]=Split the following piece of text into fields in the following format:

subject: <the specific strai...
DEBUG:LiteLLM:

DEBUG:LiteLLM:[92mRequest to litellm:[0m
DEBUG:LiteLLM:[92mlitellm.completion(api_key='', api_base='https://api.cborg.lbl.gov', api_version=None, model='gpt-4o', messages=[{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], temperature=1.0, caching=True, custom_llm_provider='openai')[0m
DEBUG:LiteLLM:

DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:SYNC kwargs[caching]: True; litellm.cache: <litellm.caching.caching.Cache object at 0x105624f90>; kwargs.get('cache')['no-cache']: False
DEBUG:LiteLLM:INSIDE CHECKING SYNC CACHE
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): e7b924127315fb8bce3bce84af7e669ab4ccf9ac8ad7c097013c9450a1d51d69
DEBUG:LiteLLM:Final hashed key: e7b924127315fb8bce3bce84af7e669ab4ccf9ac8ad7c097013c9450a1d51d69
INFO:LiteLLM:
LiteLLM completion() model= gpt-4o; provider = openai
DEBUG:LiteLLM:
LiteLLM: Params passed to completion() {'model': 'gpt-4o', 'functions': None, 'function_call': None, 'temperature': 1.0, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
DEBUG:LiteLLM:
LiteLLM: Non-Default params passed to completion() {'temperature': 1.0}
DEBUG:LiteLLM:Final returned optional params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:self.optional_params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o', 'combined_model_name': 'openai/gpt-4o', 'stripped_model_name': 'gpt-4o', 'combined_stripped_model_name': 'openai/gpt-4o', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.cborg.lbl.gov \
-d '{'model': 'gpt-4o', 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], 'temperature': 1.0, 'extra_body': {}}'
[0m

DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-98417c91-fb12-4d6e-bc50-d73cbb9896be', 'json_data': {'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], 'model': 'gpt-4o', 'temperature': 1.0}, 'extra_json': {}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.cborg.lbl.gov/chat/completions
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 30 Oct 2025 21:43:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'llm_provider-apim-request-id', b'4494e726-5922-4929-b454-7845b93471ae'), (b'llm_provider-azureml-model-session', b'd015-20251018173616'), (b'llm_provider-content-length', b'1080'), (b'llm_provider-content-type', b'application/json'), (b'llm_provider-date', b'Thu, 30 Oct 2025 21:43:48 GMT'), (b'llm_provider-strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'llm_provider-x-accel-buffering', b'no'), (b'llm_provider-x-content-type-options', b'nosniff'), (b'llm_provider-x-ms-deployment-name', b'gpt-4o'), (b'llm_provider-x-ms-rai-invoked', b'true'), (b'llm_provider-x-ms-region', b'East US'), (b'llm_provider-x-ratelimit-limit-requests', b'150'), (b'llm_provider-x-ratelimit-limit-tokens', b'150000'), (b'llm_provider-x-ratelimit-remaining-requests', b'138'), (b'llm_provider-x-ratelimit-remaining-tokens', b'116225'), (b'llm_provider-x-request-id', b'dce08558-a37d-41d7-a898-dc40881d8e2c'), (b'Server', b'cloudflare'), (b'x-litellm-attempted-fallbacks', b'0'), (b'x-litellm-attempted-retries', b'0'), (b'x-litellm-call-id', b'30ad692b-bc48-4c31-ab5d-2b068cd942ed'), (b'x-litellm-key-spend', b'32.74365190000005'), (b'x-litellm-model-api-base', b'https://science-it-openai.openai.azure.com/'), (b'x-litellm-model-group', b'gpt-4o'), (b'x-litellm-model-id', b'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38'), (b'x-litellm-overhead-duration-ms', b'1.308'), (b'x-litellm-response-cost', b'0.0005350000000000001'), (b'x-litellm-response-cost-discount-amount', b'0.0'), (b'x-litellm-response-cost-original', b'0.0005350000000000001'), (b'x-litellm-response-duration-ms', b'384.46799999999996'), (b'x-litellm-version', b'1.79.0'), (b'x-ratelimit-limit-requests', b'150'), (b'x-ratelimit-limit-tokens', b'150000'), (b'x-ratelimit-remaining-requests', b'138'), (b'x-ratelimit-remaining-tokens', b'116225'), (b'cf-cache-status', b'DYNAMIC'), (b'vary', b'accept-encoding'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'Set-Cookie', b'__cf_bm=NyUgXcvRYHpv85J1hu7XXub_q2bSIpUHjaYyiN0gxaU-1761860628.5143378-1.0.1.1-Er3502wdnvGgC5eWvaxMGr31QGcQTPcMIyppQIi2oC4wNasajUgb3LJyATEsaN6d_FLhAfch3evF1DlGLxgyT0WllUrZAGnMMhgU4OEEyFOy_8S9rB_0qJ6e6_vhrlBK; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:13:48 GMT'), (b'CF-RAY', b'996e17203ba183d0-EWR')])
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.cborg.lbl.gov/chat/completions "200 OK" Headers({'date': 'Thu, 30 Oct 2025 21:43:48 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'content-encoding': 'gzip', 'llm_provider-apim-request-id': '4494e726-5922-4929-b454-7845b93471ae', 'llm_provider-azureml-model-session': 'd015-20251018173616', 'llm_provider-content-length': '1080', 'llm_provider-content-type': 'application/json', 'llm_provider-date': 'Thu, 30 Oct 2025 21:43:48 GMT', 'llm_provider-strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'llm_provider-x-accel-buffering': 'no', 'llm_provider-x-content-type-options': 'nosniff', 'llm_provider-x-ms-deployment-name': 'gpt-4o', 'llm_provider-x-ms-rai-invoked': 'true', 'llm_provider-x-ms-region': 'East US', 'llm_provider-x-ratelimit-limit-requests': '150', 'llm_provider-x-ratelimit-limit-tokens': '150000', 'llm_provider-x-ratelimit-remaining-requests': '138', 'llm_provider-x-ratelimit-remaining-tokens': '116225', 'llm_provider-x-request-id': 'dce08558-a37d-41d7-a898-dc40881d8e2c', 'server': 'cloudflare', 'x-litellm-attempted-fallbacks': '0', 'x-litellm-attempted-retries': '0', 'x-litellm-call-id': '30ad692b-bc48-4c31-ab5d-2b068cd942ed', 'x-litellm-key-spend': '32.74365190000005', 'x-litellm-model-api-base': 'https://science-it-openai.openai.azure.com/', 'x-litellm-model-group': 'gpt-4o', 'x-litellm-model-id': 'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38', 'x-litellm-overhead-duration-ms': '1.308', 'x-litellm-response-cost': '0.0005350000000000001', 'x-litellm-response-cost-discount-amount': '0.0', 'x-litellm-response-cost-original': '0.0005350000000000001', 'x-litellm-response-duration-ms': '384.46799999999996', 'x-litellm-version': '1.79.0', 'x-ratelimit-limit-requests': '150', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '138', 'x-ratelimit-remaining-tokens': '116225', 'cf-cache-status': 'DYNAMIC', 'vary': 'accept-encoding', 'strict-transport-security': 'max-age=31536000', 'set-cookie': '__cf_bm=NyUgXcvRYHpv85J1hu7XXub_q2bSIpUHjaYyiN0gxaU-1761860628.5143378-1.0.1.1-Er3502wdnvGgC5eWvaxMGr31QGcQTPcMIyppQIi2oC4wNasajUgb3LJyATEsaN6d_FLhAfch3evF1DlGLxgyT0WllUrZAGnMMhgU4OEEyFOy_8S9rB_0qJ6e6_vhrlBK; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:13:48 GMT', 'cf-ray': '996e17203ba183d0-EWR'})
DEBUG:openai._base_client:request_id: None
DEBUG:LiteLLM:RAW RESPONSE:
{"id": "chatcmpl-CWUiqHrzx4NZMyfEatU4dUt4xEQOw", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "subject: none\npredicate: none\nobject: none", "refusal": null, "role": "assistant", "annotations": [], "audio": null, "function_call": null, "tool_calls": null}, "provider_specific_fields": {"content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}}], "created": 1761860628, "model": "gpt-4o-2024-08-06", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_4a331a0222", "usage": {"completion_tokens": 12, "prompt_tokens": 166, "total_tokens": 178, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}


DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): e7b924127315fb8bce3bce84af7e669ab4ccf9ac8ad7c097013c9450a1d51d69
DEBUG:LiteLLM:Final hashed key: e7b924127315fb8bce3bce84af7e669ab4ccf9ac8ad7c097013c9450a1d51d69
INFO:LiteLLM:Wrapper: Completed Call, calling success_handler
DEBUG:LiteLLM:response_cost: 0.0005350000000000001
INFO:root:PARSING LINE: subject: none
DEBUG:root:  FIELD: subject
DEBUG:root:SLOT: subject INL: False VALS: ['none']
INFO:root:PARSING LINE: predicate: none
DEBUG:root:  FIELD: predicate
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call: Cache_hit=None
DEBUG:root:SLOT: predicate INL: None VALS: ['none']
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
INFO:root:PARSING LINE: object: none
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:root:  FIELD: object
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call streaming complete
DEBUG:root:SLOT: object INL: False VALS: ['none']
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
INFO:root:PARSING LINE: article_type: taxonomic_revision
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:root:  FIELD: article_type
DEBUG:root:SLOT: article_type INL: None VALS: ['taxonomic_revision']
DEBUG:root:RAW: {'pmid': '10843040', 'study_taxa': ['none'], 'strains': ['none'], 'cell_shape': ['none'], 'cell_arrangements': ['none'], 'gram_staining': ['none'], 'motility': ['none'], 'spore_formation': ['none'], 'cell_wall_characteristics': ['none'], 'cellular_inclusions': ['none'], 'cell_shape_relationships': [{'subject': 'none', 'predicate': 'none', 'object': 'none'}], 'cell_arrangement_relationships': [{'subject': 'none', 'predicate': 'none', 'object': 'none'}], 'gram_staining_relationships': [{'subject': 'none', 'predicate': 'none', 'object': 'none'}], 'motility_relationships': [{'subject': 'none', 'predicate': 'none', 'object': 'none'}], 'spore_formation_relationships': [{'subject': 'none', 'predicate': 'none', 'object': 'none'}], 'cell_wall_relationships': [{'subject': 'none', 'predicate': 'none', 'object': 'none'}], 'cellular_inclusion_relationships': [{'subject': 'none', 'predicate': 'none', 'object': 'none'}], 'pigmentation': ['none'], 'strain_relationships': [{'subject': 'none', 'predicate': 'none', 'object': 'none'}], 'article_type': 'taxonomic_revision'}
DEBUG:root:Grounding annotation object {'pmid': '10843040', 'study_taxa': ['none'], 'strains': ['none'], 'cell_shape': ['none'], 'cell_arrangements': ['none'], 'gram_staining': ['none'], 'motility': ['none'], 'spore_formation': ['none'], 'cell_wall_characteristics': ['none'], 'cellular_inclusions': ['none'], 'cell_shape_relationships': [{'subject': 'none', 'predicate': 'none', 'object': 'none'}], 'cell_arrangement_relationships': [{'subject': 'none', 'predicate': 'none', 'object': 'none'}], 'gram_staining_relationships': [{'subject': 'none', 'predicate': 'none', 'object': 'none'}], 'motility_relationships': [{'subject': 'none', 'predicate': 'none', 'object': 'none'}], 'spore_formation_relationships': [{'subject': 'none', 'predicate': 'none', 'object': 'none'}], 'cell_wall_relationships': [{'subject': 'none', 'predicate': 'none', 'object': 'none'}], 'cellular_inclusion_relationships': [{'subject': 'none', 'predicate': 'none', 'object': 'none'}], 'pigmentation': ['none'], 'strain_relationships': [{'subject': 'none', 'predicate': 'none', 'object': 'none'}], 'article_type': 'taxonomic_revision'}
DEBUG:root:FIELD: pmid SLOT: pmid
DEBUG:root:   VAL: 10843040
DEBUG:root:FIELD: study_taxa SLOT: study_taxa
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using Taxon
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 27.79s ago] ('rdfs:label', 'none')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 29.76s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'none')
INFO:sqlalchemy.engine.Engine:SELECT rdfs_label_statement.value AS rdfs_label_statement_value 
FROM rdfs_label_statement 
WHERE rdfs_label_statement.subject = ?
INFO:sqlalchemy.engine.Engine:[cached since 10.51s ago] ('NCBITaxon:32644',)
INFO:ontogpt.engines.knowledge_engine:Grounding none to NCBITaxon:32644; next step is to normalize
INFO:ontogpt.engines.knowledge_engine:Normalized none with NCBITaxon:32644 to NCBITaxon:32644
DEBUG:root:FIELD: strains SLOT: strains
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to Strain
DEBUG:root:FIELD: cell_shape SLOT: cell_shape
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using CellShape
INFO:ontogpt.engines.knowledge_engine:Loading annotator sqlite:obo:metpo
INFO:root:Locator: obo:metpo
INFO:root:Ensuring gunzipped for https://s3.amazonaws.com/bbop-sqlite/metpo.db.gz
INFO:root:Locator, post-processed: sqlite:////Users/MAM/.data/oaklib/metpo.db
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:BEGIN (implicit)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[generated in 0.00016s] ('rdfs:label', 'none')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.01208s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'none')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to CellShape
DEBUG:root:FIELD: cell_arrangements SLOT: cell_arrangements
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using CellArrangement
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.01435s ago] ('rdfs:label', 'none')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.01524s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'none')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to CellArrangement
DEBUG:root:FIELD: gram_staining SLOT: gram_staining
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using GramStaining
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.01637s ago] ('rdfs:label', 'none')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.01715s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'none')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to GramStaining
DEBUG:root:FIELD: motility SLOT: motility
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using Motility
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.01822s ago] ('rdfs:label', 'none')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.01898s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'none')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to Motility
DEBUG:root:FIELD: spore_formation SLOT: spore_formation
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using SporeFormation
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.02069s ago] ('rdfs:label', 'none')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.02174s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'none')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to SporeFormation
DEBUG:root:FIELD: cell_wall_characteristics SLOT: cell_wall_characteristics
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using CellWallCharacteristic
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.0228s ago] ('rdfs:label', 'none')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.02357s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'none')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to CellWallCharacteristic
DEBUG:root:FIELD: cellular_inclusions SLOT: cellular_inclusions
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using CellularInclusion
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.02465s ago] ('rdfs:label', 'none')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.0254s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'none')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to CellularInclusion
DEBUG:root:FIELD: cell_shape_relationships SLOT: cell_shape_relationships
DEBUG:root:   VAL: {'subject': 'none', 'predicate': 'none', 'object': 'none'}
DEBUG:root:Grounding annotation object {'subject': 'none', 'predicate': 'none', 'object': 'none'}
DEBUG:root:FIELD: subject SLOT: subject
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to Strain
DEBUG:root:FIELD: predicate SLOT: predicate
DEBUG:root:   VAL: none
INFO:root:Looking for none in MorphologyType
INFO:root:Cannot find enum value for none in MorphologyType
DEBUG:root:FIELD: object SLOT: object
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using CellShape
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.02714s ago] ('rdfs:label', 'none')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.028s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'none')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to CellShape
DEBUG:root:Creating object from dict {'subject': 'AUTO:none', 'predicate': None, 'object': 'AUTO:none'}
INFO:root:{'subject': 'AUTO:none', 'predicate': None, 'object': 'AUTO:none'}
DEBUG:root:FIELD: cell_arrangement_relationships SLOT: cell_arrangement_relationships
DEBUG:root:   VAL: {'subject': 'none', 'predicate': 'none', 'object': 'none'}
DEBUG:root:Grounding annotation object {'subject': 'none', 'predicate': 'none', 'object': 'none'}
DEBUG:root:FIELD: subject SLOT: subject
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to Strain
DEBUG:root:FIELD: predicate SLOT: predicate
DEBUG:root:   VAL: none
INFO:root:Looking for none in MorphologyType
INFO:root:Cannot find enum value for none in MorphologyType
DEBUG:root:FIELD: object SLOT: object
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using CellArrangement
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.02948s ago] ('rdfs:label', 'none')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.03029s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'none')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to CellArrangement
DEBUG:root:Creating object from dict {'subject': 'AUTO:none', 'predicate': None, 'object': 'AUTO:none'}
INFO:root:{'subject': 'AUTO:none', 'predicate': None, 'object': 'AUTO:none'}
DEBUG:root:FIELD: gram_staining_relationships SLOT: gram_staining_relationships
DEBUG:root:   VAL: {'subject': 'none', 'predicate': 'none', 'object': 'none'}
DEBUG:root:Grounding annotation object {'subject': 'none', 'predicate': 'none', 'object': 'none'}
DEBUG:root:FIELD: subject SLOT: subject
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to Strain
DEBUG:root:FIELD: predicate SLOT: predicate
DEBUG:root:   VAL: none
INFO:root:Looking for none in MorphologyType
INFO:root:Cannot find enum value for none in MorphologyType
DEBUG:root:FIELD: object SLOT: object
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using GramStaining
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.032s ago] ('rdfs:label', 'none')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.03304s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'none')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to GramStaining
DEBUG:root:Creating object from dict {'subject': 'AUTO:none', 'predicate': None, 'object': 'AUTO:none'}
INFO:root:{'subject': 'AUTO:none', 'predicate': None, 'object': 'AUTO:none'}
DEBUG:root:FIELD: motility_relationships SLOT: motility_relationships
DEBUG:root:   VAL: {'subject': 'none', 'predicate': 'none', 'object': 'none'}
DEBUG:root:Grounding annotation object {'subject': 'none', 'predicate': 'none', 'object': 'none'}
DEBUG:root:FIELD: subject SLOT: subject
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to Strain
DEBUG:root:FIELD: predicate SLOT: predicate
DEBUG:root:   VAL: none
INFO:root:Looking for none in MorphologyType
INFO:root:Cannot find enum value for none in MorphologyType
DEBUG:root:FIELD: object SLOT: object
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using Motility
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.03631s ago] ('rdfs:label', 'none')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.03785s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'none')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to Motility
DEBUG:root:Creating object from dict {'subject': 'AUTO:none', 'predicate': None, 'object': 'AUTO:none'}
INFO:root:{'subject': 'AUTO:none', 'predicate': None, 'object': 'AUTO:none'}
DEBUG:root:FIELD: spore_formation_relationships SLOT: spore_formation_relationships
DEBUG:root:   VAL: {'subject': 'none', 'predicate': 'none', 'object': 'none'}
DEBUG:root:Grounding annotation object {'subject': 'none', 'predicate': 'none', 'object': 'none'}
DEBUG:root:FIELD: subject SLOT: subject
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to Strain
DEBUG:root:FIELD: predicate SLOT: predicate
DEBUG:root:   VAL: none
INFO:root:Looking for none in MorphologyType
INFO:root:Cannot find enum value for none in MorphologyType
DEBUG:root:FIELD: object SLOT: object
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using SporeFormation
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.03985s ago] ('rdfs:label', 'none')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.04114s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'none')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to SporeFormation
DEBUG:root:Creating object from dict {'subject': 'AUTO:none', 'predicate': None, 'object': 'AUTO:none'}
INFO:root:{'subject': 'AUTO:none', 'predicate': None, 'object': 'AUTO:none'}
DEBUG:root:FIELD: cell_wall_relationships SLOT: cell_wall_relationships
DEBUG:root:   VAL: {'subject': 'none', 'predicate': 'none', 'object': 'none'}
DEBUG:root:Grounding annotation object {'subject': 'none', 'predicate': 'none', 'object': 'none'}
DEBUG:root:FIELD: subject SLOT: subject
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to Strain
DEBUG:root:FIELD: predicate SLOT: predicate
DEBUG:root:   VAL: none
INFO:root:Looking for none in MorphologyType
INFO:root:Cannot find enum value for none in MorphologyType
DEBUG:root:FIELD: object SLOT: object
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using CellWallCharacteristic
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.043s ago] ('rdfs:label', 'none')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.04391s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'none')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to CellWallCharacteristic
DEBUG:root:Creating object from dict {'subject': 'AUTO:none', 'predicate': None, 'object': 'AUTO:none'}
INFO:root:{'subject': 'AUTO:none', 'predicate': None, 'object': 'AUTO:none'}
DEBUG:root:FIELD: cellular_inclusion_relationships SLOT: cellular_inclusion_relationships
DEBUG:root:   VAL: {'subject': 'none', 'predicate': 'none', 'object': 'none'}
DEBUG:root:Grounding annotation object {'subject': 'none', 'predicate': 'none', 'object': 'none'}
DEBUG:root:FIELD: subject SLOT: subject
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to Strain
DEBUG:root:FIELD: predicate SLOT: predicate
DEBUG:root:   VAL: none
INFO:root:Looking for none in MorphologyType
INFO:root:Cannot find enum value for none in MorphologyType
DEBUG:root:FIELD: object SLOT: object
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using CellularInclusion
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.04568s ago] ('rdfs:label', 'none')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.04655s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'none')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to CellularInclusion
DEBUG:root:Creating object from dict {'subject': 'AUTO:none', 'predicate': None, 'object': 'AUTO:none'}
INFO:root:{'subject': 'AUTO:none', 'predicate': None, 'object': 'AUTO:none'}
DEBUG:root:FIELD: pigmentation SLOT: pigmentation
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using Pigmentation
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.04783s ago] ('rdfs:label', 'none')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 0.04863s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'none')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to Pigmentation
DEBUG:root:FIELD: strain_relationships SLOT: strain_relationships
DEBUG:root:   VAL: {'subject': 'none', 'predicate': 'none', 'object': 'none'}
DEBUG:root:Grounding annotation object {'subject': 'none', 'predicate': 'none', 'object': 'none'}
DEBUG:root:FIELD: subject SLOT: subject
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to Strain
DEBUG:root:FIELD: predicate SLOT: predicate
DEBUG:root:   VAL: none
INFO:root:Looking for none in StrainRelationshipType
INFO:root:Cannot find enum value for none in StrainRelationshipType
DEBUG:root:FIELD: object SLOT: object
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using Taxon
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 32.55s ago] ('rdfs:label', 'none')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 34.45s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'none')
INFO:sqlalchemy.engine.Engine:SELECT rdfs_label_statement.value AS rdfs_label_statement_value 
FROM rdfs_label_statement 
WHERE rdfs_label_statement.subject = ?
INFO:sqlalchemy.engine.Engine:[cached since 15.43s ago] ('NCBITaxon:32644',)
INFO:ontogpt.engines.knowledge_engine:Grounding none to NCBITaxon:32644; next step is to normalize
INFO:ontogpt.engines.knowledge_engine:Normalized none with NCBITaxon:32644 to NCBITaxon:32644
DEBUG:root:Creating object from dict {'subject': 'AUTO:none', 'predicate': None, 'object': 'NCBITaxon:32644'}
INFO:root:{'subject': 'AUTO:none', 'predicate': None, 'object': 'NCBITaxon:32644'}
DEBUG:root:FIELD: article_type SLOT: article_type
DEBUG:root:   VAL: taxonomic_revision
INFO:root:Looking for taxonomic_revision in ArticleType
DEBUG:root:Creating object from dict {'pmid': '10843040', 'study_taxa': ['NCBITaxon:32644'], 'strains': ['AUTO:none'], 'cell_shape': ['AUTO:none'], 'cell_arrangements': ['AUTO:none'], 'gram_staining': ['AUTO:none'], 'motility': ['AUTO:none'], 'spore_formation': ['AUTO:none'], 'cell_wall_characteristics': ['AUTO:none'], 'cellular_inclusions': ['AUTO:none'], 'cell_shape_relationships': [CellShapeRelationship(subject='AUTO:none', predicate=None, object='AUTO:none')], 'cell_arrangement_relationships': [CellArrangementRelationship(subject='AUTO:none', predicate=None, object='AUTO:none')], 'gram_staining_relationships': [GramStainingRelationship(subject='AUTO:none', predicate=None, object='AUTO:none')], 'motility_relationships': [MotilityRelationship(subject='AUTO:none', predicate=None, object='AUTO:none')], 'spore_formation_relationships': [SporeFormationRelationship(subject='AUTO:none', predicate=None, object='AUTO:none')], 'cell_wall_relationships': [CellWallRelationship(subject='AUTO:none', predicate=None, object='AUTO:none')], 'cellular_inclusion_relationships': [CellularInclusionRelationship(subject='AUTO:none', predicate=None, object='AUTO:none')], 'pigmentation': ['AUTO:none'], 'strain_relationships': [StrainRelationship(subject='AUTO:none', predicate=None, object='NCBITaxon:32644')], 'article_type': 'taxonomic_revision'}
INFO:root:{'pmid': '10843040', 'study_taxa': ['NCBITaxon:32644'], 'strains': ['AUTO:none'], 'cell_shape': ['AUTO:none'], 'cell_arrangements': ['AUTO:none'], 'gram_staining': ['AUTO:none'], 'motility': ['AUTO:none'], 'spore_formation': ['AUTO:none'], 'cell_wall_characteristics': ['AUTO:none'], 'cellular_inclusions': ['AUTO:none'], 'cell_shape_relationships': [CellShapeRelationship(subject='AUTO:none', predicate=None, object='AUTO:none')], 'cell_arrangement_relationships': [CellArrangementRelationship(subject='AUTO:none', predicate=None, object='AUTO:none')], 'gram_staining_relationships': [GramStainingRelationship(subject='AUTO:none', predicate=None, object='AUTO:none')], 'motility_relationships': [MotilityRelationship(subject='AUTO:none', predicate=None, object='AUTO:none')], 'spore_formation_relationships': [SporeFormationRelationship(subject='AUTO:none', predicate=None, object='AUTO:none')], 'cell_wall_relationships': [CellWallRelationship(subject='AUTO:none', predicate=None, object='AUTO:none')], 'cellular_inclusion_relationships': [CellularInclusionRelationship(subject='AUTO:none', predicate=None, object='AUTO:none')], 'pigmentation': ['AUTO:none'], 'strain_relationships': [StrainRelationship(subject='AUTO:none', predicate=None, object='NCBITaxon:32644')], 'article_type': 'taxonomic_revision'}
INFO:root:Output format: yaml
INFO:root:Now extracting from file 3 of 3
INFO:root:Cleaning text...
INFO:ontogpt.clients.llm_client:Complete: engine=gpt-4o, prompt[8001]=From the text below, extract the following entities in the following format:

pmid: <PubMed ID of th...
DEBUG:LiteLLM:

DEBUG:LiteLLM:[92mRequest to litellm:[0m
DEBUG:LiteLLM:[92mlitellm.completion(api_key='', api_base='https://api.cborg.lbl.gov', api_version=None, model='gpt-4o', messages=[{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'From the text below, extract the following entities in the following format:\n\npmid: <PubMed ID of the article (e.g., 23996836)>\nstudy_taxa: <semicolon-separated list of the main bacterial or archaeal taxa being studied for morphology>\nstrains: <Extract ONLY the strain designation part (e.g., "DA-C8", "MG1655", "ATCC 25922") WITHOUT genus/species prefixes. Focus on strain numbers, culture collection codes, and isolate identifiers. Automatically remove terminal "T" or "(T)" suffixes as these indicate type strain status (e.g., "DA-C8T" becomes "DA-C8", "K13T" becomes "K13"). Include strain numbers, culture collection numbers, and isolate names, but NOT the full taxonomic context.>\ncell_shape: <Extract all cell shapes mentioned in the text exactly as described in the literature. Include measurements when provided (e.g., "rod-shaped, 0.5 x 2.0 Î¼m"). If no cell shapes are mentioned, leave this field empty. DO NOT write "none".>\ncell_arrangements: <Extract all cell arrangement patterns mentioned in the text (e.g., single cells, pairs, chains, clusters, tetrads, packets, irregular masses, palisades, V-shapes, angular arrangements). If no cell arrangements are mentioned, leave this field empty. DO NOT write "none".>\ngram_staining: <Extract Gram staining results mentioned in the text (e.g., Gram-positive, Gram-negative, Gram-variable, Gram-indeterminate). Include any additional staining properties mentioned. If no Gram staining information is mentioned, leave this field empty. DO NOT write "none".>\nmotility: <Extract all motility characteristics mentioned in the text, including motility presence (motile/non-motile), motility types (flagellar, gliding, twitching, swarming), and flagella arrangements (polar, peritrichous, monotrichous, lophotrichous, amphitrichous). If no motility information is mentioned, leave this field empty. DO NOT write "none".>\nspore_formation: <Extract all spore formation characteristics mentioned in the text, including spore presence (spore-forming/non-spore-forming), spore types (endospores, conidia, arthrospores), and spore positions (terminal, subterminal, central, lateral). Include sporangium or other structures. If no spore formation information is mentioned, leave this field empty. DO NOT write "none".>\ncell_wall_characteristics: <Extract all cell wall characteristics mentioned in the text, including structural features (thick/thin, multilayered), chemical components (peptidoglycan, teichoic acids, mycolic acids, lipopolysaccharide), and anatomical features (outer membrane, periplasmic space, S-layer, capsule). If no cell wall characteristics are mentioned, leave this field empty. DO NOT write "none".>\ncellular_inclusions: <Extract all cellular inclusions and internal structures mentioned in the text, including storage granules (PHB, PHA, polyphosphate, glycogen, sulfur, lipid droplets), specialized structures (gas vesicles, magnetosomes, carboxysomes), and other intracellular bodies. If no cellular inclusions are mentioned, leave this field empty. DO NOT write "none".>\ncell_shape_relationships: <For each cell shape extracted above, create strain-to-shape relationships. Link specific strains to their cell shapes (e.g., "DA-C8 has_cell_shape rod-shaped"). Convert ALL cell shapes mentioned above into structured relationships.>\ncell_arrangement_relationships: <For each cell arrangement extracted above, create strain-to-arrangement relationships. Link specific strains to their arrangements (e.g., "DA-C8 has_arrangement chains"). Convert ALL cell arrangements mentioned above into structured relationships.>\ngram_staining_relationships: <For each Gram staining result extracted above, create strain-to-staining relationships. Link specific strains to their staining results (e.g., "DA-C8 has_gram_staining Gram-positive"). Convert ALL Gram staining results mentioned above into structured relationships.>\nmotility_relationships: <For each motility characteristic extracted above, create strain-to-motility relationships. Link specific strains to their motility characteristics (e.g., "DA-C8 has_motility motile"). Convert ALL motility characteristics mentioned above into structured relationships.>\nspore_formation_relationships: <For each spore formation characteristic extracted above, create strain-to-spore relationships. Link specific strains to their spore characteristics (e.g., "DA-C8 has_spore_formation terminal spores"). Convert ALL spore formation characteristics mentioned above into structured relationships.>\ncell_wall_relationships: <For each cell wall characteristic extracted above, create strain-to-cell-wall relationships. Link specific strains to their cell wall features (e.g., "DA-C8 has_cell_wall_feature peptidoglycan"). Convert ALL cell wall characteristics mentioned above into structured relationships.>\ncellular_inclusion_relationships: <For each cellular inclusion extracted above, create strain-to-inclusion relationships. Link specific strains to their cellular inclusions (e.g., "DA-C8 has_inclusion PHB granules"). Convert ALL cellular inclusions mentioned above into structured relationships.>\npigmentation: <Extract all pigmentation and colony color characteristics mentioned in the text, including colors (yellow, orange, red, pink, white, cream, brown, black, green), pigment types (carotenoid, melanin, flexirubin), and properties (diffusible, non-diffusible, fluorescent). If no pigmentation is mentioned, leave this field empty. DO NOT write "none".>\nstrain_relationships: <A semicolon-separated list of strain-species relationships, where each relationship connects a strain to its parent taxon. Each relationship should have a strain name, relationship type, and parent species/genus. For example: "MG1655 strain_of Escherichia coli; K-12 strain_of Escherichia coli; ATCC 25922 type_strain_of Klebsiella pneumoniae". If no strain relationships are found, leave this field empty. DO NOT write "none".>\narticle_type: <The type of study or article. Choose the most appropriate category based on the content.Must be one of: novel_species, novel_genus, taxonomic_revision, phylogenetic_analysis, comparative_taxonomy, emended_description, genome_sequence, review, biochemical_characterization, ecological_study, morphological_characterization, physiology_study>\n\n\nText:\n{\'content\': \'Geobacter hydrogenophilus, Geobacter chapellei and Geobacter grbiciae, three new, strictly anaerobic, dissimilatory Fe(III)-reducers.\\n\\nRecent studies on the diversity and ubiquity of Fe(III)-reducing organisms in different environments led to the isolation and identification of four new dissimilatory Fe(III)-reducers (strains H-2T, 172T, TACP-2T and TACP-5). All four isolates are non-motile, Gram-negative, freshwater, mesophilic, strict anaerobes with morphology identical to that of Geobacter metallireducens strain GS-15T. Analysis of the 16S rRNA sequences indicated that the new isolates belong to the genus Geobacter, in the delta-Proteobacteria. Significant differences in phenotypic characteristics, DNA-DNA homology and G+C content indicated that the four isolates represent three new species of the genus. The names Geobacter hydrogenophilus sp. nov. (strain H-2T), Geobacter chapellei sp. nov. (strain 172T) and Geobacter grbiciae sp. nov. (strains TACP-2T and TACP-5) are proposed. Geobacter hydrogenophilus and Geobacter chapellei were isolated from a petroleum-contaminated aquifer and a pristine, deep, subsurface aquifer, respectively. Geobacter grbiciae was isolated from aquatic sediments. All of the isolates can obtain energy for growth by coupling the oxidation of acetate to the reduction of Fe(III). The four isolates also coupled Fe(III) reduction to the oxidation of other simple, volatile fatty acids. In addition, Geobacter hydrogenophilus and Geobacter grbiciae were able to oxidize aromatic compounds such as benzoate, whilst Geobacter grbiciae was also able to use the monoaromatic hydrocarbon toluene.\\n\\nPMID:11321104\', \'saved_to\': None, \'windowed\': False}\n\n\n===\n\n', 'role': 'user'}], temperature=1.0, caching=True, custom_llm_provider='openai')[0m
DEBUG:LiteLLM:

DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:SYNC kwargs[caching]: True; litellm.cache: <litellm.caching.caching.Cache object at 0x105624f90>; kwargs.get('cache')['no-cache']: False
DEBUG:LiteLLM:INSIDE CHECKING SYNC CACHE
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'From the text below, extract the following entities in the following format:\n\npmid: <PubMed ID of the article (e.g., 23996836)>\nstudy_taxa: <semicolon-separated list of the main bacterial or archaeal taxa being studied for morphology>\nstrains: <Extract ONLY the strain designation part (e.g., "DA-C8", "MG1655", "ATCC 25922") WITHOUT genus/species prefixes. Focus on strain numbers, culture collection codes, and isolate identifiers. Automatically remove terminal "T" or "(T)" suffixes as these indicate type strain status (e.g., "DA-C8T" becomes "DA-C8", "K13T" becomes "K13"). Include strain numbers, culture collection numbers, and isolate names, but NOT the full taxonomic context.>\ncell_shape: <Extract all cell shapes mentioned in the text exactly as described in the literature. Include measurements when provided (e.g., "rod-shaped, 0.5 x 2.0 Î¼m"). If no cell shapes are mentioned, leave this field empty. DO NOT write "none".>\ncell_arrangements: <Extract all cell arrangement patterns mentioned in the text (e.g., single cells, pairs, chains, clusters, tetrads, packets, irregular masses, palisades, V-shapes, angular arrangements). If no cell arrangements are mentioned, leave this field empty. DO NOT write "none".>\ngram_staining: <Extract Gram staining results mentioned in the text (e.g., Gram-positive, Gram-negative, Gram-variable, Gram-indeterminate). Include any additional staining properties mentioned. If no Gram staining information is mentioned, leave this field empty. DO NOT write "none".>\nmotility: <Extract all motility characteristics mentioned in the text, including motility presence (motile/non-motile), motility types (flagellar, gliding, twitching, swarming), and flagella arrangements (polar, peritrichous, monotrichous, lophotrichous, amphitrichous). If no motility information is mentioned, leave this field empty. DO NOT write "none".>\nspore_formation: <Extract all spore formation characteristics mentioned in the text, including spore presence (spore-forming/non-spore-forming), spore types (endospores, conidia, arthrospores), and spore positions (terminal, subterminal, central, lateral). Include sporangium or other structures. If no spore formation information is mentioned, leave this field empty. DO NOT write "none".>\ncell_wall_characteristics: <Extract all cell wall characteristics mentioned in the text, including structural features (thick/thin, multilayered), chemical components (peptidoglycan, teichoic acids, mycolic acids, lipopolysaccharide), and anatomical features (outer membrane, periplasmic space, S-layer, capsule). If no cell wall characteristics are mentioned, leave this field empty. DO NOT write "none".>\ncellular_inclusions: <Extract all cellular inclusions and internal structures mentioned in the text, including storage granules (PHB, PHA, polyphosphate, glycogen, sulfur, lipid droplets), specialized structures (gas vesicles, magnetosomes, carboxysomes), and other intracellular bodies. If no cellular inclusions are mentioned, leave this field empty. DO NOT write "none".>\ncell_shape_relationships: <For each cell shape extracted above, create strain-to-shape relationships. Link specific strains to their cell shapes (e.g., "DA-C8 has_cell_shape rod-shaped"). Convert ALL cell shapes mentioned above into structured relationships.>\ncell_arrangement_relationships: <For each cell arrangement extracted above, create strain-to-arrangement relationships. Link specific strains to their arrangements (e.g., "DA-C8 has_arrangement chains"). Convert ALL cell arrangements mentioned above into structured relationships.>\ngram_staining_relationships: <For each Gram staining result extracted above, create strain-to-staining relationships. Link specific strains to their staining results (e.g., "DA-C8 has_gram_staining Gram-positive"). Convert ALL Gram staining results mentioned above into structured relationships.>\nmotility_relationships: <For each motility characteristic extracted above, create strain-to-motility relationships. Link specific strains to their motility characteristics (e.g., "DA-C8 has_motility motile"). Convert ALL motility characteristics mentioned above into structured relationships.>\nspore_formation_relationships: <For each spore formation characteristic extracted above, create strain-to-spore relationships. Link specific strains to their spore characteristics (e.g., "DA-C8 has_spore_formation terminal spores"). Convert ALL spore formation characteristics mentioned above into structured relationships.>\ncell_wall_relationships: <For each cell wall characteristic extracted above, create strain-to-cell-wall relationships. Link specific strains to their cell wall features (e.g., "DA-C8 has_cell_wall_feature peptidoglycan"). Convert ALL cell wall characteristics mentioned above into structured relationships.>\ncellular_inclusion_relationships: <For each cellular inclusion extracted above, create strain-to-inclusion relationships. Link specific strains to their cellular inclusions (e.g., "DA-C8 has_inclusion PHB granules"). Convert ALL cellular inclusions mentioned above into structured relationships.>\npigmentation: <Extract all pigmentation and colony color characteristics mentioned in the text, including colors (yellow, orange, red, pink, white, cream, brown, black, green), pigment types (carotenoid, melanin, flexirubin), and properties (diffusible, non-diffusible, fluorescent). If no pigmentation is mentioned, leave this field empty. DO NOT write "none".>\nstrain_relationships: <A semicolon-separated list of strain-species relationships, where each relationship connects a strain to its parent taxon. Each relationship should have a strain name, relationship type, and parent species/genus. For example: "MG1655 strain_of Escherichia coli; K-12 strain_of Escherichia coli; ATCC 25922 type_strain_of Klebsiella pneumoniae". If no strain relationships are found, leave this field empty. DO NOT write "none".>\narticle_type: <The type of study or article. Choose the most appropriate category based on the content.Must be one of: novel_species, novel_genus, taxonomic_revision, phylogenetic_analysis, comparative_taxonomy, emended_description, genome_sequence, review, biochemical_characterization, ecological_study, morphological_characterization, physiology_study>\n\n\nText:\n{\'content\': \'Geobacter hydrogenophilus, Geobacter chapellei and Geobacter grbiciae, three new, strictly anaerobic, dissimilatory Fe(III)-reducers.\\n\\nRecent studies on the diversity and ubiquity of Fe(III)-reducing organisms in different environments led to the isolation and identification of four new dissimilatory Fe(III)-reducers (strains H-2T, 172T, TACP-2T and TACP-5). All four isolates are non-motile, Gram-negative, freshwater, mesophilic, strict anaerobes with morphology identical to that of Geobacter metallireducens strain GS-15T. Analysis of the 16S rRNA sequences indicated that the new isolates belong to the genus Geobacter, in the delta-Proteobacteria. Significant differences in phenotypic characteristics, DNA-DNA homology and G+C content indicated that the four isolates represent three new species of the genus. The names Geobacter hydrogenophilus sp. nov. (strain H-2T), Geobacter chapellei sp. nov. (strain 172T) and Geobacter grbiciae sp. nov. (strains TACP-2T and TACP-5) are proposed. Geobacter hydrogenophilus and Geobacter chapellei were isolated from a petroleum-contaminated aquifer and a pristine, deep, subsurface aquifer, respectively. Geobacter grbiciae was isolated from aquatic sediments. All of the isolates can obtain energy for growth by coupling the oxidation of acetate to the reduction of Fe(III). The four isolates also coupled Fe(III) reduction to the oxidation of other simple, volatile fatty acids. In addition, Geobacter hydrogenophilus and Geobacter grbiciae were able to oxidize aromatic compounds such as benzoate, whilst Geobacter grbiciae was also able to use the monoaromatic hydrocarbon toluene.\\n\\nPMID:11321104\', \'saved_to\': None, \'windowed\': False}\n\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): dd186017288e2c14ca8e7a047394a1218462444c2348a7ba980c5bd0f4699b7b
DEBUG:LiteLLM:Final hashed key: dd186017288e2c14ca8e7a047394a1218462444c2348a7ba980c5bd0f4699b7b
INFO:LiteLLM:
LiteLLM completion() model= gpt-4o; provider = openai
DEBUG:LiteLLM:
LiteLLM: Params passed to completion() {'model': 'gpt-4o', 'functions': None, 'function_call': None, 'temperature': 1.0, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'From the text below, extract the following entities in the following format:\n\npmid: <PubMed ID of the article (e.g., 23996836)>\nstudy_taxa: <semicolon-separated list of the main bacterial or archaeal taxa being studied for morphology>\nstrains: <Extract ONLY the strain designation part (e.g., "DA-C8", "MG1655", "ATCC 25922") WITHOUT genus/species prefixes. Focus on strain numbers, culture collection codes, and isolate identifiers. Automatically remove terminal "T" or "(T)" suffixes as these indicate type strain status (e.g., "DA-C8T" becomes "DA-C8", "K13T" becomes "K13"). Include strain numbers, culture collection numbers, and isolate names, but NOT the full taxonomic context.>\ncell_shape: <Extract all cell shapes mentioned in the text exactly as described in the literature. Include measurements when provided (e.g., "rod-shaped, 0.5 x 2.0 Î¼m"). If no cell shapes are mentioned, leave this field empty. DO NOT write "none".>\ncell_arrangements: <Extract all cell arrangement patterns mentioned in the text (e.g., single cells, pairs, chains, clusters, tetrads, packets, irregular masses, palisades, V-shapes, angular arrangements). If no cell arrangements are mentioned, leave this field empty. DO NOT write "none".>\ngram_staining: <Extract Gram staining results mentioned in the text (e.g., Gram-positive, Gram-negative, Gram-variable, Gram-indeterminate). Include any additional staining properties mentioned. If no Gram staining information is mentioned, leave this field empty. DO NOT write "none".>\nmotility: <Extract all motility characteristics mentioned in the text, including motility presence (motile/non-motile), motility types (flagellar, gliding, twitching, swarming), and flagella arrangements (polar, peritrichous, monotrichous, lophotrichous, amphitrichous). If no motility information is mentioned, leave this field empty. DO NOT write "none".>\nspore_formation: <Extract all spore formation characteristics mentioned in the text, including spore presence (spore-forming/non-spore-forming), spore types (endospores, conidia, arthrospores), and spore positions (terminal, subterminal, central, lateral). Include sporangium or other structures. If no spore formation information is mentioned, leave this field empty. DO NOT write "none".>\ncell_wall_characteristics: <Extract all cell wall characteristics mentioned in the text, including structural features (thick/thin, multilayered), chemical components (peptidoglycan, teichoic acids, mycolic acids, lipopolysaccharide), and anatomical features (outer membrane, periplasmic space, S-layer, capsule). If no cell wall characteristics are mentioned, leave this field empty. DO NOT write "none".>\ncellular_inclusions: <Extract all cellular inclusions and internal structures mentioned in the text, including storage granules (PHB, PHA, polyphosphate, glycogen, sulfur, lipid droplets), specialized structures (gas vesicles, magnetosomes, carboxysomes), and other intracellular bodies. If no cellular inclusions are mentioned, leave this field empty. DO NOT write "none".>\ncell_shape_relationships: <For each cell shape extracted above, create strain-to-shape relationships. Link specific strains to their cell shapes (e.g., "DA-C8 has_cell_shape rod-shaped"). Convert ALL cell shapes mentioned above into structured relationships.>\ncell_arrangement_relationships: <For each cell arrangement extracted above, create strain-to-arrangement relationships. Link specific strains to their arrangements (e.g., "DA-C8 has_arrangement chains"). Convert ALL cell arrangements mentioned above into structured relationships.>\ngram_staining_relationships: <For each Gram staining result extracted above, create strain-to-staining relationships. Link specific strains to their staining results (e.g., "DA-C8 has_gram_staining Gram-positive"). Convert ALL Gram staining results mentioned above into structured relationships.>\nmotility_relationships: <For each motility characteristic extracted above, create strain-to-motility relationships. Link specific strains to their motility characteristics (e.g., "DA-C8 has_motility motile"). Convert ALL motility characteristics mentioned above into structured relationships.>\nspore_formation_relationships: <For each spore formation characteristic extracted above, create strain-to-spore relationships. Link specific strains to their spore characteristics (e.g., "DA-C8 has_spore_formation terminal spores"). Convert ALL spore formation characteristics mentioned above into structured relationships.>\ncell_wall_relationships: <For each cell wall characteristic extracted above, create strain-to-cell-wall relationships. Link specific strains to their cell wall features (e.g., "DA-C8 has_cell_wall_feature peptidoglycan"). Convert ALL cell wall characteristics mentioned above into structured relationships.>\ncellular_inclusion_relationships: <For each cellular inclusion extracted above, create strain-to-inclusion relationships. Link specific strains to their cellular inclusions (e.g., "DA-C8 has_inclusion PHB granules"). Convert ALL cellular inclusions mentioned above into structured relationships.>\npigmentation: <Extract all pigmentation and colony color characteristics mentioned in the text, including colors (yellow, orange, red, pink, white, cream, brown, black, green), pigment types (carotenoid, melanin, flexirubin), and properties (diffusible, non-diffusible, fluorescent). If no pigmentation is mentioned, leave this field empty. DO NOT write "none".>\nstrain_relationships: <A semicolon-separated list of strain-species relationships, where each relationship connects a strain to its parent taxon. Each relationship should have a strain name, relationship type, and parent species/genus. For example: "MG1655 strain_of Escherichia coli; K-12 strain_of Escherichia coli; ATCC 25922 type_strain_of Klebsiella pneumoniae". If no strain relationships are found, leave this field empty. DO NOT write "none".>\narticle_type: <The type of study or article. Choose the most appropriate category based on the content.Must be one of: novel_species, novel_genus, taxonomic_revision, phylogenetic_analysis, comparative_taxonomy, emended_description, genome_sequence, review, biochemical_characterization, ecological_study, morphological_characterization, physiology_study>\n\n\nText:\n{\'content\': \'Geobacter hydrogenophilus, Geobacter chapellei and Geobacter grbiciae, three new, strictly anaerobic, dissimilatory Fe(III)-reducers.\\n\\nRecent studies on the diversity and ubiquity of Fe(III)-reducing organisms in different environments led to the isolation and identification of four new dissimilatory Fe(III)-reducers (strains H-2T, 172T, TACP-2T and TACP-5). All four isolates are non-motile, Gram-negative, freshwater, mesophilic, strict anaerobes with morphology identical to that of Geobacter metallireducens strain GS-15T. Analysis of the 16S rRNA sequences indicated that the new isolates belong to the genus Geobacter, in the delta-Proteobacteria. Significant differences in phenotypic characteristics, DNA-DNA homology and G+C content indicated that the four isolates represent three new species of the genus. The names Geobacter hydrogenophilus sp. nov. (strain H-2T), Geobacter chapellei sp. nov. (strain 172T) and Geobacter grbiciae sp. nov. (strains TACP-2T and TACP-5) are proposed. Geobacter hydrogenophilus and Geobacter chapellei were isolated from a petroleum-contaminated aquifer and a pristine, deep, subsurface aquifer, respectively. Geobacter grbiciae was isolated from aquatic sediments. All of the isolates can obtain energy for growth by coupling the oxidation of acetate to the reduction of Fe(III). The four isolates also coupled Fe(III) reduction to the oxidation of other simple, volatile fatty acids. In addition, Geobacter hydrogenophilus and Geobacter grbiciae were able to oxidize aromatic compounds such as benzoate, whilst Geobacter grbiciae was also able to use the monoaromatic hydrocarbon toluene.\\n\\nPMID:11321104\', \'saved_to\': None, \'windowed\': False}\n\n\n===\n\n', 'role': 'user'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
DEBUG:LiteLLM:
LiteLLM: Non-Default params passed to completion() {'temperature': 1.0}
DEBUG:LiteLLM:Final returned optional params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:self.optional_params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o', 'combined_model_name': 'openai/gpt-4o', 'stripped_model_name': 'gpt-4o', 'combined_stripped_model_name': 'openai/gpt-4o', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.cborg.lbl.gov \
-d '{'model': 'gpt-4o', 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'From the text below, extract the following entities in the following format:\n\npmid: <PubMed ID of the article (e.g., 23996836)>\nstudy_taxa: <semicolon-separated list of the main bacterial or archaeal taxa being studied for morphology>\nstrains: <Extract ONLY the strain designation part (e.g., "DA-C8", "MG1655", "ATCC 25922") WITHOUT genus/species prefixes. Focus on strain numbers, culture collection codes, and isolate identifiers. Automatically remove terminal "T" or "(T)" suffixes as these indicate type strain status (e.g., "DA-C8T" becomes "DA-C8", "K13T" becomes "K13"). Include strain numbers, culture collection numbers, and isolate names, but NOT the full taxonomic context.>\ncell_shape: <Extract all cell shapes mentioned in the text exactly as described in the literature. Include measurements when provided (e.g., "rod-shaped, 0.5 x 2.0 Î¼m"). If no cell shapes are mentioned, leave this field empty. DO NOT write "none".>\ncell_arrangements: <Extract all cell arrangement patterns mentioned in the text (e.g., single cells, pairs, chains, clusters, tetrads, packets, irregular masses, palisades, V-shapes, angular arrangements). If no cell arrangements are mentioned, leave this field empty. DO NOT write "none".>\ngram_staining: <Extract Gram staining results mentioned in the text (e.g., Gram-positive, Gram-negative, Gram-variable, Gram-indeterminate). Include any additional staining properties mentioned. If no Gram staining information is mentioned, leave this field empty. DO NOT write "none".>\nmotility: <Extract all motility characteristics mentioned in the text, including motility presence (motile/non-motile), motility types (flagellar, gliding, twitching, swarming), and flagella arrangements (polar, peritrichous, monotrichous, lophotrichous, amphitrichous). If no motility information is mentioned, leave this field empty. DO NOT write "none".>\nspore_formation: <Extract all spore formation characteristics mentioned in the text, including spore presence (spore-forming/non-spore-forming), spore types (endospores, conidia, arthrospores), and spore positions (terminal, subterminal, central, lateral). Include sporangium or other structures. If no spore formation information is mentioned, leave this field empty. DO NOT write "none".>\ncell_wall_characteristics: <Extract all cell wall characteristics mentioned in the text, including structural features (thick/thin, multilayered), chemical components (peptidoglycan, teichoic acids, mycolic acids, lipopolysaccharide), and anatomical features (outer membrane, periplasmic space, S-layer, capsule). If no cell wall characteristics are mentioned, leave this field empty. DO NOT write "none".>\ncellular_inclusions: <Extract all cellular inclusions and internal structures mentioned in the text, including storage granules (PHB, PHA, polyphosphate, glycogen, sulfur, lipid droplets), specialized structures (gas vesicles, magnetosomes, carboxysomes), and other intracellular bodies. If no cellular inclusions are mentioned, leave this field empty. DO NOT write "none".>\ncell_shape_relationships: <For each cell shape extracted above, create strain-to-shape relationships. Link specific strains to their cell shapes (e.g., "DA-C8 has_cell_shape rod-shaped"). Convert ALL cell shapes mentioned above into structured relationships.>\ncell_arrangement_relationships: <For each cell arrangement extracted above, create strain-to-arrangement relationships. Link specific strains to their arrangements (e.g., "DA-C8 has_arrangement chains"). Convert ALL cell arrangements mentioned above into structured relationships.>\ngram_staining_relationships: <For each Gram staining result extracted above, create strain-to-staining relationships. Link specific strains to their staining results (e.g., "DA-C8 has_gram_staining Gram-positive"). Convert ALL Gram staining results mentioned above into structured relationships.>\nmotility_relationships: <For each motility characteristic extracted above, create strain-to-motility relationships. Link specific strains to their motility characteristics (e.g., "DA-C8 has_motility motile"). Convert ALL motility characteristics mentioned above into structured relationships.>\nspore_formation_relationships: <For each spore formation characteristic extracted above, create strain-to-spore relationships. Link specific strains to their spore characteristics (e.g., "DA-C8 has_spore_formation terminal spores"). Convert ALL spore formation characteristics mentioned above into structured relationships.>\ncell_wall_relationships: <For each cell wall characteristic extracted above, create strain-to-cell-wall relationships. Link specific strains to their cell wall features (e.g., "DA-C8 has_cell_wall_feature peptidoglycan"). Convert ALL cell wall characteristics mentioned above into structured relationships.>\ncellular_inclusion_relationships: <For each cellular inclusion extracted above, create strain-to-inclusion relationships. Link specific strains to their cellular inclusions (e.g., "DA-C8 has_inclusion PHB granules"). Convert ALL cellular inclusions mentioned above into structured relationships.>\npigmentation: <Extract all pigmentation and colony color characteristics mentioned in the text, including colors (yellow, orange, red, pink, white, cream, brown, black, green), pigment types (carotenoid, melanin, flexirubin), and properties (diffusible, non-diffusible, fluorescent). If no pigmentation is mentioned, leave this field empty. DO NOT write "none".>\nstrain_relationships: <A semicolon-separated list of strain-species relationships, where each relationship connects a strain to its parent taxon. Each relationship should have a strain name, relationship type, and parent species/genus. For example: "MG1655 strain_of Escherichia coli; K-12 strain_of Escherichia coli; ATCC 25922 type_strain_of Klebsiella pneumoniae". If no strain relationships are found, leave this field empty. DO NOT write "none".>\narticle_type: <The type of study or article. Choose the most appropriate category based on the content.Must be one of: novel_species, novel_genus, taxonomic_revision, phylogenetic_analysis, comparative_taxonomy, emended_description, genome_sequence, review, biochemical_characterization, ecological_study, morphological_characterization, physiology_study>\n\n\nText:\n{\'content\': \'Geobacter hydrogenophilus, Geobacter chapellei and Geobacter grbiciae, three new, strictly anaerobic, dissimilatory Fe(III)-reducers.\\n\\nRecent studies on the diversity and ubiquity of Fe(III)-reducing organisms in different environments led to the isolation and identification of four new dissimilatory Fe(III)-reducers (strains H-2T, 172T, TACP-2T and TACP-5). All four isolates are non-motile, Gram-negative, freshwater, mesophilic, strict anaerobes with morphology identical to that of Geobacter metallireducens strain GS-15T. Analysis of the 16S rRNA sequences indicated that the new isolates belong to the genus Geobacter, in the delta-Proteobacteria. Significant differences in phenotypic characteristics, DNA-DNA homology and G+C content indicated that the four isolates represent three new species of the genus. The names Geobacter hydrogenophilus sp. nov. (strain H-2T), Geobacter chapellei sp. nov. (strain 172T) and Geobacter grbiciae sp. nov. (strains TACP-2T and TACP-5) are proposed. Geobacter hydrogenophilus and Geobacter chapellei were isolated from a petroleum-contaminated aquifer and a pristine, deep, subsurface aquifer, respectively. Geobacter grbiciae was isolated from aquatic sediments. All of the isolates can obtain energy for growth by coupling the oxidation of acetate to the reduction of Fe(III). The four isolates also coupled Fe(III) reduction to the oxidation of other simple, volatile fatty acids. In addition, Geobacter hydrogenophilus and Geobacter grbiciae were able to oxidize aromatic compounds such as benzoate, whilst Geobacter grbiciae was also able to use the monoaromatic hydrocarbon toluene.\\n\\nPMID:11321104\', \'saved_to\': None, \'windowed\': False}\n\n\n===\n\n', 'role': 'user'}], 'temperature': 1.0, 'extra_body': {}}'
[0m

DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-c2c44d72-4f8e-4b0d-873e-6f2b5249ccb8', 'json_data': {'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'From the text below, extract the following entities in the following format:\n\npmid: <PubMed ID of the article (e.g., 23996836)>\nstudy_taxa: <semicolon-separated list of the main bacterial or archaeal taxa being studied for morphology>\nstrains: <Extract ONLY the strain designation part (e.g., "DA-C8", "MG1655", "ATCC 25922") WITHOUT genus/species prefixes. Focus on strain numbers, culture collection codes, and isolate identifiers. Automatically remove terminal "T" or "(T)" suffixes as these indicate type strain status (e.g., "DA-C8T" becomes "DA-C8", "K13T" becomes "K13"). Include strain numbers, culture collection numbers, and isolate names, but NOT the full taxonomic context.>\ncell_shape: <Extract all cell shapes mentioned in the text exactly as described in the literature. Include measurements when provided (e.g., "rod-shaped, 0.5 x 2.0 Î¼m"). If no cell shapes are mentioned, leave this field empty. DO NOT write "none".>\ncell_arrangements: <Extract all cell arrangement patterns mentioned in the text (e.g., single cells, pairs, chains, clusters, tetrads, packets, irregular masses, palisades, V-shapes, angular arrangements). If no cell arrangements are mentioned, leave this field empty. DO NOT write "none".>\ngram_staining: <Extract Gram staining results mentioned in the text (e.g., Gram-positive, Gram-negative, Gram-variable, Gram-indeterminate). Include any additional staining properties mentioned. If no Gram staining information is mentioned, leave this field empty. DO NOT write "none".>\nmotility: <Extract all motility characteristics mentioned in the text, including motility presence (motile/non-motile), motility types (flagellar, gliding, twitching, swarming), and flagella arrangements (polar, peritrichous, monotrichous, lophotrichous, amphitrichous). If no motility information is mentioned, leave this field empty. DO NOT write "none".>\nspore_formation: <Extract all spore formation characteristics mentioned in the text, including spore presence (spore-forming/non-spore-forming), spore types (endospores, conidia, arthrospores), and spore positions (terminal, subterminal, central, lateral). Include sporangium or other structures. If no spore formation information is mentioned, leave this field empty. DO NOT write "none".>\ncell_wall_characteristics: <Extract all cell wall characteristics mentioned in the text, including structural features (thick/thin, multilayered), chemical components (peptidoglycan, teichoic acids, mycolic acids, lipopolysaccharide), and anatomical features (outer membrane, periplasmic space, S-layer, capsule). If no cell wall characteristics are mentioned, leave this field empty. DO NOT write "none".>\ncellular_inclusions: <Extract all cellular inclusions and internal structures mentioned in the text, including storage granules (PHB, PHA, polyphosphate, glycogen, sulfur, lipid droplets), specialized structures (gas vesicles, magnetosomes, carboxysomes), and other intracellular bodies. If no cellular inclusions are mentioned, leave this field empty. DO NOT write "none".>\ncell_shape_relationships: <For each cell shape extracted above, create strain-to-shape relationships. Link specific strains to their cell shapes (e.g., "DA-C8 has_cell_shape rod-shaped"). Convert ALL cell shapes mentioned above into structured relationships.>\ncell_arrangement_relationships: <For each cell arrangement extracted above, create strain-to-arrangement relationships. Link specific strains to their arrangements (e.g., "DA-C8 has_arrangement chains"). Convert ALL cell arrangements mentioned above into structured relationships.>\ngram_staining_relationships: <For each Gram staining result extracted above, create strain-to-staining relationships. Link specific strains to their staining results (e.g., "DA-C8 has_gram_staining Gram-positive"). Convert ALL Gram staining results mentioned above into structured relationships.>\nmotility_relationships: <For each motility characteristic extracted above, create strain-to-motility relationships. Link specific strains to their motility characteristics (e.g., "DA-C8 has_motility motile"). Convert ALL motility characteristics mentioned above into structured relationships.>\nspore_formation_relationships: <For each spore formation characteristic extracted above, create strain-to-spore relationships. Link specific strains to their spore characteristics (e.g., "DA-C8 has_spore_formation terminal spores"). Convert ALL spore formation characteristics mentioned above into structured relationships.>\ncell_wall_relationships: <For each cell wall characteristic extracted above, create strain-to-cell-wall relationships. Link specific strains to their cell wall features (e.g., "DA-C8 has_cell_wall_feature peptidoglycan"). Convert ALL cell wall characteristics mentioned above into structured relationships.>\ncellular_inclusion_relationships: <For each cellular inclusion extracted above, create strain-to-inclusion relationships. Link specific strains to their cellular inclusions (e.g., "DA-C8 has_inclusion PHB granules"). Convert ALL cellular inclusions mentioned above into structured relationships.>\npigmentation: <Extract all pigmentation and colony color characteristics mentioned in the text, including colors (yellow, orange, red, pink, white, cream, brown, black, green), pigment types (carotenoid, melanin, flexirubin), and properties (diffusible, non-diffusible, fluorescent). If no pigmentation is mentioned, leave this field empty. DO NOT write "none".>\nstrain_relationships: <A semicolon-separated list of strain-species relationships, where each relationship connects a strain to its parent taxon. Each relationship should have a strain name, relationship type, and parent species/genus. For example: "MG1655 strain_of Escherichia coli; K-12 strain_of Escherichia coli; ATCC 25922 type_strain_of Klebsiella pneumoniae". If no strain relationships are found, leave this field empty. DO NOT write "none".>\narticle_type: <The type of study or article. Choose the most appropriate category based on the content.Must be one of: novel_species, novel_genus, taxonomic_revision, phylogenetic_analysis, comparative_taxonomy, emended_description, genome_sequence, review, biochemical_characterization, ecological_study, morphological_characterization, physiology_study>\n\n\nText:\n{\'content\': \'Geobacter hydrogenophilus, Geobacter chapellei and Geobacter grbiciae, three new, strictly anaerobic, dissimilatory Fe(III)-reducers.\\n\\nRecent studies on the diversity and ubiquity of Fe(III)-reducing organisms in different environments led to the isolation and identification of four new dissimilatory Fe(III)-reducers (strains H-2T, 172T, TACP-2T and TACP-5). All four isolates are non-motile, Gram-negative, freshwater, mesophilic, strict anaerobes with morphology identical to that of Geobacter metallireducens strain GS-15T. Analysis of the 16S rRNA sequences indicated that the new isolates belong to the genus Geobacter, in the delta-Proteobacteria. Significant differences in phenotypic characteristics, DNA-DNA homology and G+C content indicated that the four isolates represent three new species of the genus. The names Geobacter hydrogenophilus sp. nov. (strain H-2T), Geobacter chapellei sp. nov. (strain 172T) and Geobacter grbiciae sp. nov. (strains TACP-2T and TACP-5) are proposed. Geobacter hydrogenophilus and Geobacter chapellei were isolated from a petroleum-contaminated aquifer and a pristine, deep, subsurface aquifer, respectively. Geobacter grbiciae was isolated from aquatic sediments. All of the isolates can obtain energy for growth by coupling the oxidation of acetate to the reduction of Fe(III). The four isolates also coupled Fe(III) reduction to the oxidation of other simple, volatile fatty acids. In addition, Geobacter hydrogenophilus and Geobacter grbiciae were able to oxidize aromatic compounds such as benzoate, whilst Geobacter grbiciae was also able to use the monoaromatic hydrocarbon toluene.\\n\\nPMID:11321104\', \'saved_to\': None, \'windowed\': False}\n\n\n===\n\n', 'role': 'user'}], 'model': 'gpt-4o', 'temperature': 1.0}, 'extra_json': {}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.cborg.lbl.gov/chat/completions
DEBUG:httpcore.connection:close.started
DEBUG:httpcore.connection:close.complete
DEBUG:httpcore.connection:connect_tcp.started host='api.cborg.lbl.gov' port=443 local_address=None timeout=600.0 socket_options=None
DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x114e7bc50>
DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x11473c050> server_hostname='api.cborg.lbl.gov' timeout=600.0
DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x114e7a810>
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 30 Oct 2025 21:44:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'llm_provider-apim-request-id', b'e3a7f3db-026c-4801-bf10-84296e7bf1cd'), (b'llm_provider-azureml-model-session', b'd015-20251018173616'), (b'llm_provider-content-length', b'2078'), (b'llm_provider-content-type', b'application/json'), (b'llm_provider-date', b'Thu, 30 Oct 2025 21:44:00 GMT'), (b'llm_provider-strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'llm_provider-x-accel-buffering', b'no'), (b'llm_provider-x-content-type-options', b'nosniff'), (b'llm_provider-x-ms-deployment-name', b'gpt-4o'), (b'llm_provider-x-ms-rai-invoked', b'true'), (b'llm_provider-x-ms-region', b'East US'), (b'llm_provider-x-ratelimit-limit-requests', b'150'), (b'llm_provider-x-ratelimit-limit-tokens', b'150000'), (b'llm_provider-x-ratelimit-remaining-requests', b'146'), (b'llm_provider-x-ratelimit-remaining-tokens', b'106395'), (b'llm_provider-x-request-id', b'9a2b8ef8-1e76-4b8f-8f24-e6102701b9d0'), (b'Server', b'cloudflare'), (b'x-litellm-attempted-fallbacks', b'0'), (b'x-litellm-attempted-retries', b'0'), (b'x-litellm-call-id', b'afcd45ee-b1c6-4a02-84b4-32935e9521b9'), (b'x-litellm-key-spend', b'32.756876900000066'), (b'x-litellm-model-api-base', b'https://science-it-openai.openai.azure.com/'), (b'x-litellm-model-group', b'gpt-4o'), (b'x-litellm-model-id', b'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38'), (b'x-litellm-overhead-duration-ms', b'2.535'), (b'x-litellm-response-cost', b'0.005955'), (b'x-litellm-response-cost-discount-amount', b'0.0'), (b'x-litellm-response-cost-original', b'0.005955'), (b'x-litellm-response-duration-ms', b'2407.27'), (b'x-litellm-version', b'1.79.0'), (b'x-ratelimit-limit-requests', b'150'), (b'x-ratelimit-limit-tokens', b'150000'), (b'x-ratelimit-remaining-requests', b'146'), (b'x-ratelimit-remaining-tokens', b'106395'), (b'cf-cache-status', b'DYNAMIC'), (b'vary', b'accept-encoding'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'Set-Cookie', b'__cf_bm=C0OxOqilgf6e_0UpEGj0tiUV6ICRrsiQtJGbBJtkxdE-1761860638.8179798-1.0.1.1-V6soHYImWJ0SBu8kjxGXiutxHhfB5r7a_miR.dlInTmdrWKOiV_wKwpx252HerHbc9pELqLeU3kZMeIB7dAjel23NRVfC1_ZV5wmBg10yGJaKgl32pRkzlT2uOSFkNQ1; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:14:01 GMT'), (b'CF-RAY', b'996e176098234f3a-EWR')])
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.cborg.lbl.gov/chat/completions "200 OK" Headers({'date': 'Thu, 30 Oct 2025 21:44:01 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'content-encoding': 'gzip', 'llm_provider-apim-request-id': 'e3a7f3db-026c-4801-bf10-84296e7bf1cd', 'llm_provider-azureml-model-session': 'd015-20251018173616', 'llm_provider-content-length': '2078', 'llm_provider-content-type': 'application/json', 'llm_provider-date': 'Thu, 30 Oct 2025 21:44:00 GMT', 'llm_provider-strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'llm_provider-x-accel-buffering': 'no', 'llm_provider-x-content-type-options': 'nosniff', 'llm_provider-x-ms-deployment-name': 'gpt-4o', 'llm_provider-x-ms-rai-invoked': 'true', 'llm_provider-x-ms-region': 'East US', 'llm_provider-x-ratelimit-limit-requests': '150', 'llm_provider-x-ratelimit-limit-tokens': '150000', 'llm_provider-x-ratelimit-remaining-requests': '146', 'llm_provider-x-ratelimit-remaining-tokens': '106395', 'llm_provider-x-request-id': '9a2b8ef8-1e76-4b8f-8f24-e6102701b9d0', 'server': 'cloudflare', 'x-litellm-attempted-fallbacks': '0', 'x-litellm-attempted-retries': '0', 'x-litellm-call-id': 'afcd45ee-b1c6-4a02-84b4-32935e9521b9', 'x-litellm-key-spend': '32.756876900000066', 'x-litellm-model-api-base': 'https://science-it-openai.openai.azure.com/', 'x-litellm-model-group': 'gpt-4o', 'x-litellm-model-id': 'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38', 'x-litellm-overhead-duration-ms': '2.535', 'x-litellm-response-cost': '0.005955', 'x-litellm-response-cost-discount-amount': '0.0', 'x-litellm-response-cost-original': '0.005955', 'x-litellm-response-duration-ms': '2407.27', 'x-litellm-version': '1.79.0', 'x-ratelimit-limit-requests': '150', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '146', 'x-ratelimit-remaining-tokens': '106395', 'cf-cache-status': 'DYNAMIC', 'vary': 'accept-encoding', 'strict-transport-security': 'max-age=31536000', 'set-cookie': '__cf_bm=C0OxOqilgf6e_0UpEGj0tiUV6ICRrsiQtJGbBJtkxdE-1761860638.8179798-1.0.1.1-V6soHYImWJ0SBu8kjxGXiutxHhfB5r7a_miR.dlInTmdrWKOiV_wKwpx252HerHbc9pELqLeU3kZMeIB7dAjel23NRVfC1_ZV5wmBg10yGJaKgl32pRkzlT2uOSFkNQ1; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:14:01 GMT', 'cf-ray': '996e176098234f3a-EWR'})
DEBUG:openai._base_client:request_id: None
DEBUG:LiteLLM:RAW RESPONSE:
{"id": "chatcmpl-CWUj1MDJVlfVCpKjC3yg0zaapKLbj", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "pmid: 11321104\nstudy_taxa: Geobacter hydrogenophilus;Geobacter chapellei;Geobacter grbiciae\nstrains: H-2;172;TACP-2;TACP-5\ncell_shape: none\ncell_arrangements: none\ngram_staining: Gram-negative\nmotility: non-motile\nspore_formation: none\ncell_wall_characteristics: none\ncellular_inclusions: none\ncell_shape_relationships: none\ncell_arrangement_relationships: none\ngram_staining_relationships: H-2 has_gram_staining Gram-negative;172 has_gram_staining Gram-negative;TACP-2 has_gram_staining Gram-negative;TACP-5 has_gram_staining Gram-negative\nmotility_relationships: H-2 has_motility non-motile;172 has_motility non-motile;TACP-2 has_motility non-motile;TACP-5 has_motility non-motile\nspore_formation_relationships: none\ncell_wall_relationships: none\ncellular_inclusion_relationships: none\npigmentation: none\nstrain_relationships: H-2 type_strain_of Geobacter hydrogenophilus;172 type_strain_of Geobacter chapellei;TACP-2 type_strain_of Geobacter grbiciae;TACP-5 strain_of Geobacter grbiciae\narticle_type: novel_species", "refusal": null, "role": "assistant", "annotations": [], "audio": null, "function_call": null, "tool_calls": null}, "provider_specific_fields": {"content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}}], "created": 1761860639, "model": "gpt-4o-2024-08-06", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_4a331a0222", "usage": {"completion_tokens": 307, "prompt_tokens": 1858, "total_tokens": 2165, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 1408}}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}


DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'From the text below, extract the following entities in the following format:\n\npmid: <PubMed ID of the article (e.g., 23996836)>\nstudy_taxa: <semicolon-separated list of the main bacterial or archaeal taxa being studied for morphology>\nstrains: <Extract ONLY the strain designation part (e.g., "DA-C8", "MG1655", "ATCC 25922") WITHOUT genus/species prefixes. Focus on strain numbers, culture collection codes, and isolate identifiers. Automatically remove terminal "T" or "(T)" suffixes as these indicate type strain status (e.g., "DA-C8T" becomes "DA-C8", "K13T" becomes "K13"). Include strain numbers, culture collection numbers, and isolate names, but NOT the full taxonomic context.>\ncell_shape: <Extract all cell shapes mentioned in the text exactly as described in the literature. Include measurements when provided (e.g., "rod-shaped, 0.5 x 2.0 Î¼m"). If no cell shapes are mentioned, leave this field empty. DO NOT write "none".>\ncell_arrangements: <Extract all cell arrangement patterns mentioned in the text (e.g., single cells, pairs, chains, clusters, tetrads, packets, irregular masses, palisades, V-shapes, angular arrangements). If no cell arrangements are mentioned, leave this field empty. DO NOT write "none".>\ngram_staining: <Extract Gram staining results mentioned in the text (e.g., Gram-positive, Gram-negative, Gram-variable, Gram-indeterminate). Include any additional staining properties mentioned. If no Gram staining information is mentioned, leave this field empty. DO NOT write "none".>\nmotility: <Extract all motility characteristics mentioned in the text, including motility presence (motile/non-motile), motility types (flagellar, gliding, twitching, swarming), and flagella arrangements (polar, peritrichous, monotrichous, lophotrichous, amphitrichous). If no motility information is mentioned, leave this field empty. DO NOT write "none".>\nspore_formation: <Extract all spore formation characteristics mentioned in the text, including spore presence (spore-forming/non-spore-forming), spore types (endospores, conidia, arthrospores), and spore positions (terminal, subterminal, central, lateral). Include sporangium or other structures. If no spore formation information is mentioned, leave this field empty. DO NOT write "none".>\ncell_wall_characteristics: <Extract all cell wall characteristics mentioned in the text, including structural features (thick/thin, multilayered), chemical components (peptidoglycan, teichoic acids, mycolic acids, lipopolysaccharide), and anatomical features (outer membrane, periplasmic space, S-layer, capsule). If no cell wall characteristics are mentioned, leave this field empty. DO NOT write "none".>\ncellular_inclusions: <Extract all cellular inclusions and internal structures mentioned in the text, including storage granules (PHB, PHA, polyphosphate, glycogen, sulfur, lipid droplets), specialized structures (gas vesicles, magnetosomes, carboxysomes), and other intracellular bodies. If no cellular inclusions are mentioned, leave this field empty. DO NOT write "none".>\ncell_shape_relationships: <For each cell shape extracted above, create strain-to-shape relationships. Link specific strains to their cell shapes (e.g., "DA-C8 has_cell_shape rod-shaped"). Convert ALL cell shapes mentioned above into structured relationships.>\ncell_arrangement_relationships: <For each cell arrangement extracted above, create strain-to-arrangement relationships. Link specific strains to their arrangements (e.g., "DA-C8 has_arrangement chains"). Convert ALL cell arrangements mentioned above into structured relationships.>\ngram_staining_relationships: <For each Gram staining result extracted above, create strain-to-staining relationships. Link specific strains to their staining results (e.g., "DA-C8 has_gram_staining Gram-positive"). Convert ALL Gram staining results mentioned above into structured relationships.>\nmotility_relationships: <For each motility characteristic extracted above, create strain-to-motility relationships. Link specific strains to their motility characteristics (e.g., "DA-C8 has_motility motile"). Convert ALL motility characteristics mentioned above into structured relationships.>\nspore_formation_relationships: <For each spore formation characteristic extracted above, create strain-to-spore relationships. Link specific strains to their spore characteristics (e.g., "DA-C8 has_spore_formation terminal spores"). Convert ALL spore formation characteristics mentioned above into structured relationships.>\ncell_wall_relationships: <For each cell wall characteristic extracted above, create strain-to-cell-wall relationships. Link specific strains to their cell wall features (e.g., "DA-C8 has_cell_wall_feature peptidoglycan"). Convert ALL cell wall characteristics mentioned above into structured relationships.>\ncellular_inclusion_relationships: <For each cellular inclusion extracted above, create strain-to-inclusion relationships. Link specific strains to their cellular inclusions (e.g., "DA-C8 has_inclusion PHB granules"). Convert ALL cellular inclusions mentioned above into structured relationships.>\npigmentation: <Extract all pigmentation and colony color characteristics mentioned in the text, including colors (yellow, orange, red, pink, white, cream, brown, black, green), pigment types (carotenoid, melanin, flexirubin), and properties (diffusible, non-diffusible, fluorescent). If no pigmentation is mentioned, leave this field empty. DO NOT write "none".>\nstrain_relationships: <A semicolon-separated list of strain-species relationships, where each relationship connects a strain to its parent taxon. Each relationship should have a strain name, relationship type, and parent species/genus. For example: "MG1655 strain_of Escherichia coli; K-12 strain_of Escherichia coli; ATCC 25922 type_strain_of Klebsiella pneumoniae". If no strain relationships are found, leave this field empty. DO NOT write "none".>\narticle_type: <The type of study or article. Choose the most appropriate category based on the content.Must be one of: novel_species, novel_genus, taxonomic_revision, phylogenetic_analysis, comparative_taxonomy, emended_description, genome_sequence, review, biochemical_characterization, ecological_study, morphological_characterization, physiology_study>\n\n\nText:\n{\'content\': \'Geobacter hydrogenophilus, Geobacter chapellei and Geobacter grbiciae, three new, strictly anaerobic, dissimilatory Fe(III)-reducers.\\n\\nRecent studies on the diversity and ubiquity of Fe(III)-reducing organisms in different environments led to the isolation and identification of four new dissimilatory Fe(III)-reducers (strains H-2T, 172T, TACP-2T and TACP-5). All four isolates are non-motile, Gram-negative, freshwater, mesophilic, strict anaerobes with morphology identical to that of Geobacter metallireducens strain GS-15T. Analysis of the 16S rRNA sequences indicated that the new isolates belong to the genus Geobacter, in the delta-Proteobacteria. Significant differences in phenotypic characteristics, DNA-DNA homology and G+C content indicated that the four isolates represent three new species of the genus. The names Geobacter hydrogenophilus sp. nov. (strain H-2T), Geobacter chapellei sp. nov. (strain 172T) and Geobacter grbiciae sp. nov. (strains TACP-2T and TACP-5) are proposed. Geobacter hydrogenophilus and Geobacter chapellei were isolated from a petroleum-contaminated aquifer and a pristine, deep, subsurface aquifer, respectively. Geobacter grbiciae was isolated from aquatic sediments. All of the isolates can obtain energy for growth by coupling the oxidation of acetate to the reduction of Fe(III). The four isolates also coupled Fe(III) reduction to the oxidation of other simple, volatile fatty acids. In addition, Geobacter hydrogenophilus and Geobacter grbiciae were able to oxidize aromatic compounds such as benzoate, whilst Geobacter grbiciae was also able to use the monoaromatic hydrocarbon toluene.\\n\\nPMID:11321104\', \'saved_to\': None, \'windowed\': False}\n\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): dd186017288e2c14ca8e7a047394a1218462444c2348a7ba980c5bd0f4699b7b
DEBUG:LiteLLM:Final hashed key: dd186017288e2c14ca8e7a047394a1218462444c2348a7ba980c5bd0f4699b7b
INFO:LiteLLM:Wrapper: Completed Call, calling success_handler
DEBUG:LiteLLM:response_cost: 0.005955
INFO:root:RAW TEXT: pmid: 11321104
study_taxa: Geobacter hydrogenophilus;Geobacter chapellei;Geobacter grbiciae
strains: H-2;172;TACP-2;TACP-5
cell_shape: none
cell_arrangements: none
gram_staining: Gram-negative
motility: non-motile
spore_formation: none
cell_wall_characteristics: none
cellular_inclusions: none
cell_shape_relationships: none
cell_arrangement_relationships: none
gram_staining_relationships: H-2 has_gram_staining Gram-negative;172 has_gram_staining Gram-negative;TACP-2 has_gram_staining Gram-negative;TACP-5 has_gram_staining Gram-negative
motility_relationships: H-2 has_motility non-motile;172 has_motility non-motile;TACP-2 has_motility non-motile;TACP-5 has_motility non-motile
spore_formation_relationships: none
cell_wall_relationships: none
cellular_inclusion_relationships: none
pigmentation: none
strain_relationships: H-2 type_strain_of Geobacter hydrogenophilus;172 type_strain_of Geobacter chapellei;TACP-2 type_strain_of Geobacter grbiciae;TACP-5 strain_of Geobacter grbiciae
article_type: novel_species
INFO:root:PARSING LINE: pmid: 11321104
DEBUG:root:  FIELD: pmid
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call: Cache_hit=None
DEBUG:root:SLOT: pmid INL: None VALS: ['11321104']
INFO:root:PARSING LINE: study_taxa: Geobacter hydrogenophilus;Geobacter chapellei;Geobacter grbiciae
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:  FIELD: study_taxa
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:root:SLOT: study_taxa INL: False VALS: ['Geobacter hydrogenophilus', 'Geobacter chapellei', 'Geobacter grbiciae']
INFO:root:PARSING LINE: strains: H-2;172;TACP-2;TACP-5
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call streaming complete
DEBUG:root:  FIELD: strains
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:SLOT: strains INL: False VALS: ['H-2', '172', 'TACP-2', 'TACP-5']
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
INFO:root:PARSING LINE: cell_shape: none
DEBUG:root:  FIELD: cell_shape
DEBUG:root:SLOT: cell_shape INL: False VALS: ['none']
INFO:root:PARSING LINE: cell_arrangements: none
DEBUG:root:  FIELD: cell_arrangements
DEBUG:root:SLOT: cell_arrangements INL: False VALS: ['none']
INFO:root:PARSING LINE: gram_staining: Gram-negative
DEBUG:root:  FIELD: gram_staining
DEBUG:root:SLOT: gram_staining INL: False VALS: ['Gram-negative']
INFO:root:PARSING LINE: motility: non-motile
DEBUG:root:  FIELD: motility
DEBUG:root:SLOT: motility INL: False VALS: ['non-motile']
INFO:root:PARSING LINE: spore_formation: none
DEBUG:root:  FIELD: spore_formation
DEBUG:root:SLOT: spore_formation INL: False VALS: ['none']
INFO:root:PARSING LINE: cell_wall_characteristics: none
DEBUG:root:  FIELD: cell_wall_characteristics
DEBUG:root:SLOT: cell_wall_characteristics INL: False VALS: ['none']
INFO:root:PARSING LINE: cellular_inclusions: none
DEBUG:root:  FIELD: cellular_inclusions
DEBUG:root:SLOT: cellular_inclusions INL: False VALS: ['none']
INFO:root:PARSING LINE: cell_shape_relationships: none
DEBUG:root:  FIELD: cell_shape_relationships
DEBUG:root:SLOT: cell_shape_relationships INL: True VALS: ['none']
DEBUG:root:  RECURSING ON SLOT: cell_shape_relationships, range=CellShapeRelationship
INFO:ontogpt.clients.llm_client:Complete: engine=gpt-4o, prompt[356]=Split the following piece of text into fields in the following format:

subject: <the strain with th...
DEBUG:LiteLLM:

DEBUG:LiteLLM:[92mRequest to litellm:[0m
DEBUG:LiteLLM:[92mlitellm.completion(api_key='', api_base='https://api.cborg.lbl.gov', api_version=None, model='gpt-4o', messages=[{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cell shape>\npredicate: <the type of cell shape relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cell shape>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], temperature=1.0, caching=True, custom_llm_provider='openai')[0m
DEBUG:LiteLLM:

DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:SYNC kwargs[caching]: True; litellm.cache: <litellm.caching.caching.Cache object at 0x105624f90>; kwargs.get('cache')['no-cache']: False
DEBUG:LiteLLM:INSIDE CHECKING SYNC CACHE
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cell shape>\npredicate: <the type of cell shape relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cell shape>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 588bccab26d813eb132d3ac2c7f2453d7e8164f5fa2f9e281fe9401fe5ba28ed
DEBUG:LiteLLM:Final hashed key: 588bccab26d813eb132d3ac2c7f2453d7e8164f5fa2f9e281fe9401fe5ba28ed
DEBUG:LiteLLM:selected model name for cost calculation: openai/gpt-4o-2024-08-06
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:LiteLLM:response_cost: 0.0005
DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:Filtered callbacks: ['cache']
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cell shape>\npredicate: <the type of cell shape relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cell shape>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 588bccab26d813eb132d3ac2c7f2453d7e8164f5fa2f9e281fe9401fe5ba28ed
DEBUG:LiteLLM:Final hashed key: 588bccab26d813eb132d3ac2c7f2453d7e8164f5fa2f9e281fe9401fe5ba28ed
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call: Cache_hit=True
DEBUG:LiteLLM:Cache hit!
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
INFO:root:PARSING LINE: subject: none
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:root:  FIELD: subject
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call streaming complete
DEBUG:root:SLOT: subject INL: False VALS: ['none']
INFO:root:PARSING LINE: predicate: none
DEBUG:root:  FIELD: predicate
DEBUG:root:SLOT: predicate INL: None VALS: ['none']
INFO:root:PARSING LINE: object: none
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:  FIELD: object
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:root:SLOT: object INL: False VALS: ['none']
INFO:root:PARSING LINE: cell_arrangement_relationships: none
DEBUG:root:  FIELD: cell_arrangement_relationships
DEBUG:root:SLOT: cell_arrangement_relationships INL: True VALS: ['none']
DEBUG:root:  RECURSING ON SLOT: cell_arrangement_relationships, range=CellArrangementRelationship
INFO:ontogpt.clients.llm_client:Complete: engine=gpt-4o, prompt[382]=Split the following piece of text into fields in the following format:

subject: <the strain with th...
DEBUG:LiteLLM:

DEBUG:LiteLLM:[92mRequest to litellm:[0m
DEBUG:LiteLLM:[92mlitellm.completion(api_key='', api_base='https://api.cborg.lbl.gov', api_version=None, model='gpt-4o', messages=[{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cell arrangement>\npredicate: <the type of cell arrangement relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cell arrangement pattern>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], temperature=1.0, caching=True, custom_llm_provider='openai')[0m
DEBUG:LiteLLM:

DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:SYNC kwargs[caching]: True; litellm.cache: <litellm.caching.caching.Cache object at 0x105624f90>; kwargs.get('cache')['no-cache']: False
DEBUG:LiteLLM:INSIDE CHECKING SYNC CACHE
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cell arrangement>\npredicate: <the type of cell arrangement relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cell arrangement pattern>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 1110091faf18f130bbb5d3455231923e5af5d40184a0049c33547bc3e6673adc
DEBUG:LiteLLM:Final hashed key: 1110091faf18f130bbb5d3455231923e5af5d40184a0049c33547bc3e6673adc
DEBUG:LiteLLM:selected model name for cost calculation: openai/gpt-4o-2024-08-06
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:LiteLLM:response_cost: 0.0005025
DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:Filtered callbacks: ['cache']
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cell arrangement>\npredicate: <the type of cell arrangement relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cell arrangement pattern>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call: Cache_hit=True
DEBUG:LiteLLM:Hashed cache key (SHA-256): 1110091faf18f130bbb5d3455231923e5af5d40184a0049c33547bc3e6673adc
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:Final hashed key: 1110091faf18f130bbb5d3455231923e5af5d40184a0049c33547bc3e6673adc
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:LiteLLM:Cache hit!
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call streaming complete
INFO:root:PARSING LINE: subject: none
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:  FIELD: subject
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:root:SLOT: subject INL: False VALS: ['none']
INFO:root:PARSING LINE: predicate: none
DEBUG:root:  FIELD: predicate
DEBUG:root:SLOT: predicate INL: None VALS: ['none']
INFO:root:PARSING LINE: object: none
DEBUG:root:  FIELD: object
DEBUG:root:SLOT: object INL: False VALS: ['none']
INFO:root:PARSING LINE: gram_staining_relationships: H-2 has_gram_staining Gram-negative;172 has_gram_staining Gram-negative;TACP-2 has_gram_staining Gram-negative;TACP-5 has_gram_staining Gram-negative
DEBUG:root:  FIELD: gram_staining_relationships
DEBUG:root:SLOT: gram_staining_relationships INL: True VALS: ['H-2 has_gram_staining Gram-negative', '172 has_gram_staining Gram-negative', 'TACP-2 has_gram_staining Gram-negative', 'TACP-5 has_gram_staining Gram-negative']
DEBUG:root:  RECURSING ON SLOT: gram_staining_relationships, range=GramStainingRelationship
INFO:ontogpt.clients.llm_client:Complete: engine=gpt-4o, prompt[400]=Split the following piece of text into fields in the following format:

subject: <the strain with th...
DEBUG:LiteLLM:

DEBUG:LiteLLM:[92mRequest to litellm:[0m
DEBUG:LiteLLM:[92mlitellm.completion(api_key='', api_base='https://api.cborg.lbl.gov', api_version=None, model='gpt-4o', messages=[{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\nH-2 has_gram_staining Gram-negative\n\n===\n\n', 'role': 'user'}], temperature=1.0, caching=True, custom_llm_provider='openai')[0m
DEBUG:LiteLLM:

DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:SYNC kwargs[caching]: True; litellm.cache: <litellm.caching.caching.Cache object at 0x105624f90>; kwargs.get('cache')['no-cache']: False
DEBUG:LiteLLM:INSIDE CHECKING SYNC CACHE
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\nH-2 has_gram_staining Gram-negative\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): a18e44fc33eab64412cee240a8c1bb963c90a5843eb633dea64fea25f2fd3a61
DEBUG:LiteLLM:Final hashed key: a18e44fc33eab64412cee240a8c1bb963c90a5843eb633dea64fea25f2fd3a61
INFO:LiteLLM:
LiteLLM completion() model= gpt-4o; provider = openai
DEBUG:LiteLLM:
LiteLLM: Params passed to completion() {'model': 'gpt-4o', 'functions': None, 'function_call': None, 'temperature': 1.0, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\nH-2 has_gram_staining Gram-negative\n\n===\n\n', 'role': 'user'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
DEBUG:LiteLLM:
LiteLLM: Non-Default params passed to completion() {'temperature': 1.0}
DEBUG:LiteLLM:Final returned optional params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:self.optional_params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o', 'combined_model_name': 'openai/gpt-4o', 'stripped_model_name': 'gpt-4o', 'combined_stripped_model_name': 'openai/gpt-4o', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.cborg.lbl.gov \
-d '{'model': 'gpt-4o', 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\nH-2 has_gram_staining Gram-negative\n\n===\n\n', 'role': 'user'}], 'temperature': 1.0, 'extra_body': {}}'
[0m

DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-7c1c7a41-ab47-4fb7-9d7c-1347d180ede2', 'json_data': {'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\nH-2 has_gram_staining Gram-negative\n\n===\n\n', 'role': 'user'}], 'model': 'gpt-4o', 'temperature': 1.0}, 'extra_json': {}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.cborg.lbl.gov/chat/completions
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 30 Oct 2025 21:44:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'llm_provider-apim-request-id', b'08f5d481-1e52-45ec-9be9-6c2aa80231c3'), (b'llm_provider-azureml-model-session', b'd015-20251018173616'), (b'llm_provider-content-length', b'1105'), (b'llm_provider-content-type', b'application/json'), (b'llm_provider-date', b'Thu, 30 Oct 2025 21:44:01 GMT'), (b'llm_provider-strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'llm_provider-x-accel-buffering', b'no'), (b'llm_provider-x-content-type-options', b'nosniff'), (b'llm_provider-x-ms-deployment-name', b'gpt-4o'), (b'llm_provider-x-ms-rai-invoked', b'true'), (b'llm_provider-x-ms-region', b'East US'), (b'llm_provider-x-ratelimit-limit-requests', b'150'), (b'llm_provider-x-ratelimit-limit-tokens', b'150000'), (b'llm_provider-x-ratelimit-remaining-requests', b'143'), (b'llm_provider-x-ratelimit-remaining-tokens', b'101632'), (b'llm_provider-x-request-id', b'ff417c92-ed7d-40f3-bcee-c51d5e1c1598'), (b'Server', b'cloudflare'), (b'x-litellm-attempted-fallbacks', b'0'), (b'x-litellm-attempted-retries', b'0'), (b'x-litellm-call-id', b'ef6bcb7d-897a-419c-9cf9-fa02367fe380'), (b'x-litellm-key-spend', b'32.762831900000066'), (b'x-litellm-model-api-base', b'https://science-it-openai.openai.azure.com/'), (b'x-litellm-model-group', b'gpt-4o'), (b'x-litellm-model-id', b'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38'), (b'x-litellm-overhead-duration-ms', b'1.292'), (b'x-litellm-response-cost', b'0.0005925'), (b'x-litellm-response-cost-discount-amount', b'0.0'), (b'x-litellm-response-cost-original', b'0.0005925'), (b'x-litellm-response-duration-ms', b'381.60699999999997'), (b'x-litellm-version', b'1.79.0'), (b'x-ratelimit-limit-requests', b'150'), (b'x-ratelimit-limit-tokens', b'150000'), (b'x-ratelimit-remaining-requests', b'143'), (b'x-ratelimit-remaining-tokens', b'101632'), (b'cf-cache-status', b'DYNAMIC'), (b'vary', b'accept-encoding'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'Set-Cookie', b'__cf_bm=FiaQyJTyN.qGWWyT.9h2uSYSi07eItkKFnKYJ4H8DR8-1761860641.621954-1.0.1.1-URivqJDbmH3iIxDlCMrWIebXarAiM_iVEzlQ6vJXJNKBmW3wGDUpnKnR7BxuNhnWO7pmD7AwOs77FGabTRDAVezWB95WzGJEBDuJv6ADSCcmuTBlM_NVQpWbJFptSRo.; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:14:02 GMT'), (b'CF-RAY', b'996e17722f654f3a-EWR')])
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.cborg.lbl.gov/chat/completions "200 OK" Headers({'date': 'Thu, 30 Oct 2025 21:44:02 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'content-encoding': 'gzip', 'llm_provider-apim-request-id': '08f5d481-1e52-45ec-9be9-6c2aa80231c3', 'llm_provider-azureml-model-session': 'd015-20251018173616', 'llm_provider-content-length': '1105', 'llm_provider-content-type': 'application/json', 'llm_provider-date': 'Thu, 30 Oct 2025 21:44:01 GMT', 'llm_provider-strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'llm_provider-x-accel-buffering': 'no', 'llm_provider-x-content-type-options': 'nosniff', 'llm_provider-x-ms-deployment-name': 'gpt-4o', 'llm_provider-x-ms-rai-invoked': 'true', 'llm_provider-x-ms-region': 'East US', 'llm_provider-x-ratelimit-limit-requests': '150', 'llm_provider-x-ratelimit-limit-tokens': '150000', 'llm_provider-x-ratelimit-remaining-requests': '143', 'llm_provider-x-ratelimit-remaining-tokens': '101632', 'llm_provider-x-request-id': 'ff417c92-ed7d-40f3-bcee-c51d5e1c1598', 'server': 'cloudflare', 'x-litellm-attempted-fallbacks': '0', 'x-litellm-attempted-retries': '0', 'x-litellm-call-id': 'ef6bcb7d-897a-419c-9cf9-fa02367fe380', 'x-litellm-key-spend': '32.762831900000066', 'x-litellm-model-api-base': 'https://science-it-openai.openai.azure.com/', 'x-litellm-model-group': 'gpt-4o', 'x-litellm-model-id': 'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38', 'x-litellm-overhead-duration-ms': '1.292', 'x-litellm-response-cost': '0.0005925', 'x-litellm-response-cost-discount-amount': '0.0', 'x-litellm-response-cost-original': '0.0005925', 'x-litellm-response-duration-ms': '381.60699999999997', 'x-litellm-version': '1.79.0', 'x-ratelimit-limit-requests': '150', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '143', 'x-ratelimit-remaining-tokens': '101632', 'cf-cache-status': 'DYNAMIC', 'vary': 'accept-encoding', 'strict-transport-security': 'max-age=31536000', 'set-cookie': '__cf_bm=FiaQyJTyN.qGWWyT.9h2uSYSi07eItkKFnKYJ4H8DR8-1761860641.621954-1.0.1.1-URivqJDbmH3iIxDlCMrWIebXarAiM_iVEzlQ6vJXJNKBmW3wGDUpnKnR7BxuNhnWO7pmD7AwOs77FGabTRDAVezWB95WzGJEBDuJv6ADSCcmuTBlM_NVQpWbJFptSRo.; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:14:02 GMT', 'cf-ray': '996e17722f654f3a-EWR'})
DEBUG:openai._base_client:request_id: None
DEBUG:LiteLLM:RAW RESPONSE:
{"id": "chatcmpl-CWUj3Gg2cnY695rvSsZfaGLH5jlhm", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "subject: H-2  \npredicate: has_gram_staining  \nobject: Gram-negative", "refusal": null, "role": "assistant", "annotations": [], "audio": null, "function_call": null, "tool_calls": null}, "provider_specific_fields": {"content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}}], "created": 1761860641, "model": "gpt-4o-2024-08-06", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_4a331a0222", "usage": {"completion_tokens": 19, "prompt_tokens": 161, "total_tokens": 180, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}


DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\nH-2 has_gram_staining Gram-negative\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): a18e44fc33eab64412cee240a8c1bb963c90a5843eb633dea64fea25f2fd3a61
DEBUG:LiteLLM:Final hashed key: a18e44fc33eab64412cee240a8c1bb963c90a5843eb633dea64fea25f2fd3a61
INFO:LiteLLM:Wrapper: Completed Call, calling success_handler
DEBUG:LiteLLM:response_cost: 0.0005925
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call: Cache_hit=None
INFO:root:PARSING LINE: subject: H-2
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:  FIELD: subject
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:root:SLOT: subject INL: False VALS: ['H-2']
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call streaming complete
INFO:root:PARSING LINE: predicate: has_gram_staining
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:root:  FIELD: predicate
DEBUG:root:SLOT: predicate INL: None VALS: ['has_gram_staining']
INFO:root:PARSING LINE: object: Gram-negative
DEBUG:root:  FIELD: object
DEBUG:root:SLOT: object INL: False VALS: ['Gram-negative']
INFO:ontogpt.clients.llm_client:Complete: engine=gpt-4o, prompt[400]=Split the following piece of text into fields in the following format:

subject: <the strain with th...
DEBUG:LiteLLM:

DEBUG:LiteLLM:[92mRequest to litellm:[0m
DEBUG:LiteLLM:[92mlitellm.completion(api_key='', api_base='https://api.cborg.lbl.gov', api_version=None, model='gpt-4o', messages=[{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\n172 has_gram_staining Gram-negative\n\n===\n\n', 'role': 'user'}], temperature=1.0, caching=True, custom_llm_provider='openai')[0m
DEBUG:LiteLLM:

DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:SYNC kwargs[caching]: True; litellm.cache: <litellm.caching.caching.Cache object at 0x105624f90>; kwargs.get('cache')['no-cache']: False
DEBUG:LiteLLM:INSIDE CHECKING SYNC CACHE
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\n172 has_gram_staining Gram-negative\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 9f06ca5da35e6e9d48d54ad94945d08320e8832ca96e98d00f5821c6a18a5ad6
DEBUG:LiteLLM:Final hashed key: 9f06ca5da35e6e9d48d54ad94945d08320e8832ca96e98d00f5821c6a18a5ad6
INFO:LiteLLM:
LiteLLM completion() model= gpt-4o; provider = openai
DEBUG:LiteLLM:
LiteLLM: Params passed to completion() {'model': 'gpt-4o', 'functions': None, 'function_call': None, 'temperature': 1.0, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\n172 has_gram_staining Gram-negative\n\n===\n\n', 'role': 'user'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
DEBUG:LiteLLM:
LiteLLM: Non-Default params passed to completion() {'temperature': 1.0}
DEBUG:LiteLLM:Final returned optional params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:self.optional_params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o', 'combined_model_name': 'openai/gpt-4o', 'stripped_model_name': 'gpt-4o', 'combined_stripped_model_name': 'openai/gpt-4o', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.cborg.lbl.gov \
-d '{'model': 'gpt-4o', 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\n172 has_gram_staining Gram-negative\n\n===\n\n', 'role': 'user'}], 'temperature': 1.0, 'extra_body': {}}'
[0m

DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-a4810813-a98c-4762-969a-8b524188b01d', 'json_data': {'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\n172 has_gram_staining Gram-negative\n\n===\n\n', 'role': 'user'}], 'model': 'gpt-4o', 'temperature': 1.0}, 'extra_json': {}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.cborg.lbl.gov/chat/completions
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 30 Oct 2025 21:44:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'llm_provider-apim-request-id', b'63e930a7-f811-4357-9963-50f6754114d9'), (b'llm_provider-azureml-model-session', b'd015-20251018173616'), (b'llm_provider-content-length', b'1107'), (b'llm_provider-content-type', b'application/json'), (b'llm_provider-date', b'Thu, 30 Oct 2025 21:44:01 GMT'), (b'llm_provider-strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'llm_provider-x-accel-buffering', b'no'), (b'llm_provider-x-content-type-options', b'nosniff'), (b'llm_provider-x-ms-deployment-name', b'gpt-4o'), (b'llm_provider-x-ms-rai-invoked', b'true'), (b'llm_provider-x-ms-region', b'East US'), (b'llm_provider-x-ratelimit-limit-requests', b'150'), (b'llm_provider-x-ratelimit-limit-tokens', b'150000'), (b'llm_provider-x-ratelimit-remaining-requests', b'142'), (b'llm_provider-x-ratelimit-remaining-tokens', b'101465'), (b'llm_provider-x-request-id', b'a69f1d17-e422-406f-b80d-7d47352bdeb6'), (b'Server', b'cloudflare'), (b'x-litellm-attempted-fallbacks', b'0'), (b'x-litellm-attempted-retries', b'0'), (b'x-litellm-call-id', b'0a79d93c-0e76-4e84-9222-3a008f565292'), (b'x-litellm-key-spend', b'32.76342440000007'), (b'x-litellm-model-api-base', b'https://science-it-openai.openai.azure.com/'), (b'x-litellm-model-group', b'gpt-4o'), (b'x-litellm-model-id', b'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38'), (b'x-litellm-overhead-duration-ms', b'1.226'), (b'x-litellm-response-cost', b'0.0005875'), (b'x-litellm-response-cost-discount-amount', b'0.0'), (b'x-litellm-response-cost-original', b'0.0005875'), (b'x-litellm-response-duration-ms', b'369.947'), (b'x-litellm-version', b'1.79.0'), (b'x-ratelimit-limit-requests', b'150'), (b'x-ratelimit-limit-tokens', b'150000'), (b'x-ratelimit-remaining-requests', b'142'), (b'x-ratelimit-remaining-tokens', b'101465'), (b'cf-cache-status', b'DYNAMIC'), (b'vary', b'accept-encoding'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'Set-Cookie', b'__cf_bm=pVm5P1gCVwvSUuij_IsTxerdrwZlGobzDCy1oUrRQso-1761860642.2252433-1.0.1.1-ltyfZXK38flYVm8HJ3ji8P9PRgcCysBX0etpHzv8j8PVVQTj7ZJ6deE9Tx6DY2ZIXPDGzj7a0mlF7yP1IMRBDmgxd4bJu6UVhCwqO886_oIUj.2uWQAvLtC8wu1qiVBK; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:14:02 GMT'), (b'CF-RAY', b'996e1775e8d04f3a-EWR')])
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.cborg.lbl.gov/chat/completions "200 OK" Headers({'date': 'Thu, 30 Oct 2025 21:44:02 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'content-encoding': 'gzip', 'llm_provider-apim-request-id': '63e930a7-f811-4357-9963-50f6754114d9', 'llm_provider-azureml-model-session': 'd015-20251018173616', 'llm_provider-content-length': '1107', 'llm_provider-content-type': 'application/json', 'llm_provider-date': 'Thu, 30 Oct 2025 21:44:01 GMT', 'llm_provider-strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'llm_provider-x-accel-buffering': 'no', 'llm_provider-x-content-type-options': 'nosniff', 'llm_provider-x-ms-deployment-name': 'gpt-4o', 'llm_provider-x-ms-rai-invoked': 'true', 'llm_provider-x-ms-region': 'East US', 'llm_provider-x-ratelimit-limit-requests': '150', 'llm_provider-x-ratelimit-limit-tokens': '150000', 'llm_provider-x-ratelimit-remaining-requests': '142', 'llm_provider-x-ratelimit-remaining-tokens': '101465', 'llm_provider-x-request-id': 'a69f1d17-e422-406f-b80d-7d47352bdeb6', 'server': 'cloudflare', 'x-litellm-attempted-fallbacks': '0', 'x-litellm-attempted-retries': '0', 'x-litellm-call-id': '0a79d93c-0e76-4e84-9222-3a008f565292', 'x-litellm-key-spend': '32.76342440000007', 'x-litellm-model-api-base': 'https://science-it-openai.openai.azure.com/', 'x-litellm-model-group': 'gpt-4o', 'x-litellm-model-id': 'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38', 'x-litellm-overhead-duration-ms': '1.226', 'x-litellm-response-cost': '0.0005875', 'x-litellm-response-cost-discount-amount': '0.0', 'x-litellm-response-cost-original': '0.0005875', 'x-litellm-response-duration-ms': '369.947', 'x-litellm-version': '1.79.0', 'x-ratelimit-limit-requests': '150', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '142', 'x-ratelimit-remaining-tokens': '101465', 'cf-cache-status': 'DYNAMIC', 'vary': 'accept-encoding', 'strict-transport-security': 'max-age=31536000', 'set-cookie': '__cf_bm=pVm5P1gCVwvSUuij_IsTxerdrwZlGobzDCy1oUrRQso-1761860642.2252433-1.0.1.1-ltyfZXK38flYVm8HJ3ji8P9PRgcCysBX0etpHzv8j8PVVQTj7ZJ6deE9Tx6DY2ZIXPDGzj7a0mlF7yP1IMRBDmgxd4bJu6UVhCwqO886_oIUj.2uWQAvLtC8wu1qiVBK; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:14:02 GMT', 'cf-ray': '996e1775e8d04f3a-EWR'})
DEBUG:openai._base_client:request_id: None
DEBUG:LiteLLM:RAW RESPONSE:
{"id": "chatcmpl-CWUj4vKiGoR59mzJPR3tCIP6bicif", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "subject: 172  \npredicate: has_gram_staining  \nobject: Gram-negative  ", "refusal": null, "role": "assistant", "annotations": [], "audio": null, "function_call": null, "tool_calls": null}, "provider_specific_fields": {"content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}}], "created": 1761860642, "model": "gpt-4o-2024-08-06", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_4a331a0222", "usage": {"completion_tokens": 19, "prompt_tokens": 159, "total_tokens": 178, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}


DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\n172 has_gram_staining Gram-negative\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 9f06ca5da35e6e9d48d54ad94945d08320e8832ca96e98d00f5821c6a18a5ad6
DEBUG:LiteLLM:Final hashed key: 9f06ca5da35e6e9d48d54ad94945d08320e8832ca96e98d00f5821c6a18a5ad6
INFO:LiteLLM:Wrapper: Completed Call, calling success_handler
DEBUG:LiteLLM:response_cost: 0.0005875
INFO:root:PARSING LINE: subject: 172
DEBUG:root:  FIELD: subject
DEBUG:root:SLOT: subject INL: False VALS: ['172']
INFO:root:PARSING LINE: predicate: has_gram_staining
DEBUG:root:  FIELD: predicate
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call: Cache_hit=None
DEBUG:root:SLOT: predicate INL: None VALS: ['has_gram_staining']
INFO:root:PARSING LINE: object: Gram-negative
DEBUG:root:  FIELD: object
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:SLOT: object INL: False VALS: ['Gram-negative']
INFO:ontogpt.clients.llm_client:Complete: engine=gpt-4o, prompt[403]=Split the following piece of text into fields in the following format:

subject: <the strain with th...
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:LiteLLM:

DEBUG:LiteLLM:Logging Details LiteLLM-Success Call streaming complete
DEBUG:LiteLLM:[92mRequest to litellm:[0m
DEBUG:LiteLLM:[92mlitellm.completion(api_key='', api_base='https://api.cborg.lbl.gov', api_version=None, model='gpt-4o', messages=[{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\nTACP-2 has_gram_staining Gram-negative\n\n===\n\n', 'role': 'user'}], temperature=1.0, caching=True, custom_llm_provider='openai')[0m
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:

DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:SYNC kwargs[caching]: True; litellm.cache: <litellm.caching.caching.Cache object at 0x105624f90>; kwargs.get('cache')['no-cache']: False
DEBUG:LiteLLM:INSIDE CHECKING SYNC CACHE
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\nTACP-2 has_gram_staining Gram-negative\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 7da60a0b1164d3fb77741f1382ce6c5344c3e25bf4376543b78eccfcd87c5204
DEBUG:LiteLLM:Final hashed key: 7da60a0b1164d3fb77741f1382ce6c5344c3e25bf4376543b78eccfcd87c5204
INFO:LiteLLM:
LiteLLM completion() model= gpt-4o; provider = openai
DEBUG:LiteLLM:
LiteLLM: Params passed to completion() {'model': 'gpt-4o', 'functions': None, 'function_call': None, 'temperature': 1.0, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\nTACP-2 has_gram_staining Gram-negative\n\n===\n\n', 'role': 'user'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
DEBUG:LiteLLM:
LiteLLM: Non-Default params passed to completion() {'temperature': 1.0}
DEBUG:LiteLLM:Final returned optional params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:self.optional_params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o', 'combined_model_name': 'openai/gpt-4o', 'stripped_model_name': 'gpt-4o', 'combined_stripped_model_name': 'openai/gpt-4o', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.cborg.lbl.gov \
-d '{'model': 'gpt-4o', 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\nTACP-2 has_gram_staining Gram-negative\n\n===\n\n', 'role': 'user'}], 'temperature': 1.0, 'extra_body': {}}'
[0m

DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-86475506-ad54-4c6a-b791-45407cd0a990', 'json_data': {'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\nTACP-2 has_gram_staining Gram-negative\n\n===\n\n', 'role': 'user'}], 'model': 'gpt-4o', 'temperature': 1.0}, 'extra_json': {}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.cborg.lbl.gov/chat/completions
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 30 Oct 2025 21:44:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'llm_provider-apim-request-id', b'4ae367e1-523f-4ae0-b8bf-2e2ea8d836fe'), (b'llm_provider-azureml-model-session', b'd015-20251018173616'), (b'llm_provider-content-length', b'1108'), (b'llm_provider-content-type', b'application/json'), (b'llm_provider-date', b'Thu, 30 Oct 2025 21:44:02 GMT'), (b'llm_provider-strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'llm_provider-x-accel-buffering', b'no'), (b'llm_provider-x-content-type-options', b'nosniff'), (b'llm_provider-x-ms-deployment-name', b'gpt-4o'), (b'llm_provider-x-ms-rai-invoked', b'true'), (b'llm_provider-x-ms-region', b'East US'), (b'llm_provider-x-ratelimit-limit-requests', b'150'), (b'llm_provider-x-ratelimit-limit-tokens', b'150000'), (b'llm_provider-x-ratelimit-remaining-requests', b'142'), (b'llm_provider-x-ratelimit-remaining-tokens', b'101298'), (b'llm_provider-x-request-id', b'e8b6a58c-1672-4926-883f-b30c79c4d884'), (b'Server', b'cloudflare'), (b'x-litellm-attempted-fallbacks', b'0'), (b'x-litellm-attempted-retries', b'0'), (b'x-litellm-call-id', b'0ac1e390-ed51-4a85-b1cb-4aa20c7cbcf9'), (b'x-litellm-key-spend', b'32.75791190000005'), (b'x-litellm-model-api-base', b'https://science-it-openai.openai.azure.com/'), (b'x-litellm-model-group', b'gpt-4o'), (b'x-litellm-model-id', b'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38'), (b'x-litellm-overhead-duration-ms', b'1.289'), (b'x-litellm-response-cost', b'0.0006050000000000001'), (b'x-litellm-response-cost-discount-amount', b'0.0'), (b'x-litellm-response-cost-original', b'0.0006050000000000001'), (b'x-litellm-response-duration-ms', b'637.953'), (b'x-litellm-version', b'1.79.0'), (b'x-ratelimit-limit-requests', b'150'), (b'x-ratelimit-limit-tokens', b'150000'), (b'x-ratelimit-remaining-requests', b'142'), (b'x-ratelimit-remaining-tokens', b'101298'), (b'cf-cache-status', b'DYNAMIC'), (b'vary', b'accept-encoding'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'Set-Cookie', b'__cf_bm=sI1eNi.l6cNj.NxwC99pO8qHKvS7Vti44xXEeJ.9saM-1761860642.7262857-1.0.1.1-nF3TAOGlfxEDZMncHWQAolWw0vCgZhsltu4Jtui6v6kaU.ybkEO3Kdekf19mwA7YZFcKRQebpxStceIsHZK3Ec9iPyp58nro_bxDuaRLjxq8rOThdN3xGwtPJerLlaTE; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:14:03 GMT'), (b'CF-RAY', b'996e177909044f3a-EWR')])
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.cborg.lbl.gov/chat/completions "200 OK" Headers({'date': 'Thu, 30 Oct 2025 21:44:03 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'content-encoding': 'gzip', 'llm_provider-apim-request-id': '4ae367e1-523f-4ae0-b8bf-2e2ea8d836fe', 'llm_provider-azureml-model-session': 'd015-20251018173616', 'llm_provider-content-length': '1108', 'llm_provider-content-type': 'application/json', 'llm_provider-date': 'Thu, 30 Oct 2025 21:44:02 GMT', 'llm_provider-strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'llm_provider-x-accel-buffering': 'no', 'llm_provider-x-content-type-options': 'nosniff', 'llm_provider-x-ms-deployment-name': 'gpt-4o', 'llm_provider-x-ms-rai-invoked': 'true', 'llm_provider-x-ms-region': 'East US', 'llm_provider-x-ratelimit-limit-requests': '150', 'llm_provider-x-ratelimit-limit-tokens': '150000', 'llm_provider-x-ratelimit-remaining-requests': '142', 'llm_provider-x-ratelimit-remaining-tokens': '101298', 'llm_provider-x-request-id': 'e8b6a58c-1672-4926-883f-b30c79c4d884', 'server': 'cloudflare', 'x-litellm-attempted-fallbacks': '0', 'x-litellm-attempted-retries': '0', 'x-litellm-call-id': '0ac1e390-ed51-4a85-b1cb-4aa20c7cbcf9', 'x-litellm-key-spend': '32.75791190000005', 'x-litellm-model-api-base': 'https://science-it-openai.openai.azure.com/', 'x-litellm-model-group': 'gpt-4o', 'x-litellm-model-id': 'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38', 'x-litellm-overhead-duration-ms': '1.289', 'x-litellm-response-cost': '0.0006050000000000001', 'x-litellm-response-cost-discount-amount': '0.0', 'x-litellm-response-cost-original': '0.0006050000000000001', 'x-litellm-response-duration-ms': '637.953', 'x-litellm-version': '1.79.0', 'x-ratelimit-limit-requests': '150', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '142', 'x-ratelimit-remaining-tokens': '101298', 'cf-cache-status': 'DYNAMIC', 'vary': 'accept-encoding', 'strict-transport-security': 'max-age=31536000', 'set-cookie': '__cf_bm=sI1eNi.l6cNj.NxwC99pO8qHKvS7Vti44xXEeJ.9saM-1761860642.7262857-1.0.1.1-nF3TAOGlfxEDZMncHWQAolWw0vCgZhsltu4Jtui6v6kaU.ybkEO3Kdekf19mwA7YZFcKRQebpxStceIsHZK3Ec9iPyp58nro_bxDuaRLjxq8rOThdN3xGwtPJerLlaTE; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:14:03 GMT', 'cf-ray': '996e177909044f3a-EWR'})
DEBUG:openai._base_client:request_id: None
DEBUG:LiteLLM:RAW RESPONSE:
{"id": "chatcmpl-CWUj5gIrNmGQxoK0Ttb7bLfdkSp4Q", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "subject: TACP-2  \npredicate: has_gram_staining  \nobject: Gram-negative", "refusal": null, "role": "assistant", "annotations": [], "audio": null, "function_call": null, "tool_calls": null}, "provider_specific_fields": {"content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}}], "created": 1761860643, "model": "gpt-4o-2024-08-06", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_4a331a0222", "usage": {"completion_tokens": 20, "prompt_tokens": 162, "total_tokens": 182, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}


DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\nTACP-2 has_gram_staining Gram-negative\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 7da60a0b1164d3fb77741f1382ce6c5344c3e25bf4376543b78eccfcd87c5204
DEBUG:LiteLLM:Final hashed key: 7da60a0b1164d3fb77741f1382ce6c5344c3e25bf4376543b78eccfcd87c5204
INFO:LiteLLM:Wrapper: Completed Call, calling success_handler
DEBUG:LiteLLM:response_cost: 0.0006050000000000001
INFO:root:PARSING LINE: subject: TACP-2
DEBUG:root:  FIELD: subject
DEBUG:root:SLOT: subject INL: False VALS: ['TACP-2']
INFO:root:PARSING LINE: predicate: has_gram_staining
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call: Cache_hit=None
DEBUG:root:  FIELD: predicate
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:SLOT: predicate INL: None VALS: ['has_gram_staining']
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
INFO:root:PARSING LINE: object: Gram-negative
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call streaming complete
DEBUG:root:  FIELD: object
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:SLOT: object INL: False VALS: ['Gram-negative']
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
INFO:ontogpt.clients.llm_client:Complete: engine=gpt-4o, prompt[403]=Split the following piece of text into fields in the following format:

subject: <the strain with th...
DEBUG:LiteLLM:

DEBUG:LiteLLM:[92mRequest to litellm:[0m
DEBUG:LiteLLM:[92mlitellm.completion(api_key='', api_base='https://api.cborg.lbl.gov', api_version=None, model='gpt-4o', messages=[{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\nTACP-5 has_gram_staining Gram-negative\n\n===\n\n', 'role': 'user'}], temperature=1.0, caching=True, custom_llm_provider='openai')[0m
DEBUG:LiteLLM:

DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:SYNC kwargs[caching]: True; litellm.cache: <litellm.caching.caching.Cache object at 0x105624f90>; kwargs.get('cache')['no-cache']: False
DEBUG:LiteLLM:INSIDE CHECKING SYNC CACHE
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\nTACP-5 has_gram_staining Gram-negative\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): c6a37608c1a44b85d324f7ab9bf8982775e2ee76d32a455900c8bc909de6c791
DEBUG:LiteLLM:Final hashed key: c6a37608c1a44b85d324f7ab9bf8982775e2ee76d32a455900c8bc909de6c791
INFO:LiteLLM:
LiteLLM completion() model= gpt-4o; provider = openai
DEBUG:LiteLLM:
LiteLLM: Params passed to completion() {'model': 'gpt-4o', 'functions': None, 'function_call': None, 'temperature': 1.0, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\nTACP-5 has_gram_staining Gram-negative\n\n===\n\n', 'role': 'user'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
DEBUG:LiteLLM:
LiteLLM: Non-Default params passed to completion() {'temperature': 1.0}
DEBUG:LiteLLM:Final returned optional params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:self.optional_params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o', 'combined_model_name': 'openai/gpt-4o', 'stripped_model_name': 'gpt-4o', 'combined_stripped_model_name': 'openai/gpt-4o', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.cborg.lbl.gov \
-d '{'model': 'gpt-4o', 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\nTACP-5 has_gram_staining Gram-negative\n\n===\n\n', 'role': 'user'}], 'temperature': 1.0, 'extra_body': {}}'
[0m

DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-5d421e26-c58e-4c8e-acb5-9b2683c15309', 'json_data': {'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\nTACP-5 has_gram_staining Gram-negative\n\n===\n\n', 'role': 'user'}], 'model': 'gpt-4o', 'temperature': 1.0}, 'extra_json': {}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.cborg.lbl.gov/chat/completions
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 30 Oct 2025 21:44:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'llm_provider-apim-request-id', b'47292294-d81e-48b7-897f-a6acbc725ad1'), (b'llm_provider-azureml-model-session', b'd015-20251018173616'), (b'llm_provider-content-length', b'1110'), (b'llm_provider-content-type', b'application/json'), (b'llm_provider-date', b'Thu, 30 Oct 2025 21:44:02 GMT'), (b'llm_provider-strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'llm_provider-x-accel-buffering', b'no'), (b'llm_provider-x-content-type-options', b'nosniff'), (b'llm_provider-x-ms-deployment-name', b'gpt-4o'), (b'llm_provider-x-ms-rai-invoked', b'true'), (b'llm_provider-x-ms-region', b'East US'), (b'llm_provider-x-ratelimit-limit-requests', b'150'), (b'llm_provider-x-ratelimit-limit-tokens', b'150000'), (b'llm_provider-x-ratelimit-remaining-requests', b'141'), (b'llm_provider-x-ratelimit-remaining-tokens', b'104784'), (b'llm_provider-x-request-id', b'89a2f8f7-e3f0-4692-81c8-d37598ca0f0f'), (b'Server', b'cloudflare'), (b'x-litellm-attempted-fallbacks', b'0'), (b'x-litellm-attempted-retries', b'0'), (b'x-litellm-call-id', b'd679a9ad-f2f7-4885-8e59-0b0300d9e02d'), (b'x-litellm-key-spend', b'32.76401190000007'), (b'x-litellm-model-api-base', b'https://science-it-openai.openai.azure.com/'), (b'x-litellm-model-group', b'gpt-4o'), (b'x-litellm-model-id', b'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38'), (b'x-litellm-overhead-duration-ms', b'1.252'), (b'x-litellm-response-cost', b'0.0006150000000000001'), (b'x-litellm-response-cost-discount-amount', b'0.0'), (b'x-litellm-response-cost-original', b'0.0006150000000000001'), (b'x-litellm-response-duration-ms', b'388.606'), (b'x-litellm-version', b'1.79.0'), (b'x-ratelimit-limit-requests', b'150'), (b'x-ratelimit-limit-tokens', b'150000'), (b'x-ratelimit-remaining-requests', b'141'), (b'x-ratelimit-remaining-tokens', b'104784'), (b'cf-cache-status', b'DYNAMIC'), (b'vary', b'accept-encoding'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'Set-Cookie', b'__cf_bm=sxAe3C4goeYbu.PlYahVP1.voUbUfbYD9.TPiPNLrtg-1761860643.5001547-1.0.1.1-u2bDx55yZLry1Mvw8_6iU_h6UfPXR3RW6wyvIhN7rYR3hkWaPLUZSSwwXFwkEtk86QEsAg2Cl_immqQu0FgBW2ndoSSVaeVxN9nPfIfs1Xo9sfkKyhZiH9mM4I7L4lUs; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:14:03 GMT'), (b'CF-RAY', b'996e177ddea34f3a-EWR')])
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.cborg.lbl.gov/chat/completions "200 OK" Headers({'date': 'Thu, 30 Oct 2025 21:44:03 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'content-encoding': 'gzip', 'llm_provider-apim-request-id': '47292294-d81e-48b7-897f-a6acbc725ad1', 'llm_provider-azureml-model-session': 'd015-20251018173616', 'llm_provider-content-length': '1110', 'llm_provider-content-type': 'application/json', 'llm_provider-date': 'Thu, 30 Oct 2025 21:44:02 GMT', 'llm_provider-strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'llm_provider-x-accel-buffering': 'no', 'llm_provider-x-content-type-options': 'nosniff', 'llm_provider-x-ms-deployment-name': 'gpt-4o', 'llm_provider-x-ms-rai-invoked': 'true', 'llm_provider-x-ms-region': 'East US', 'llm_provider-x-ratelimit-limit-requests': '150', 'llm_provider-x-ratelimit-limit-tokens': '150000', 'llm_provider-x-ratelimit-remaining-requests': '141', 'llm_provider-x-ratelimit-remaining-tokens': '104784', 'llm_provider-x-request-id': '89a2f8f7-e3f0-4692-81c8-d37598ca0f0f', 'server': 'cloudflare', 'x-litellm-attempted-fallbacks': '0', 'x-litellm-attempted-retries': '0', 'x-litellm-call-id': 'd679a9ad-f2f7-4885-8e59-0b0300d9e02d', 'x-litellm-key-spend': '32.76401190000007', 'x-litellm-model-api-base': 'https://science-it-openai.openai.azure.com/', 'x-litellm-model-group': 'gpt-4o', 'x-litellm-model-id': 'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38', 'x-litellm-overhead-duration-ms': '1.252', 'x-litellm-response-cost': '0.0006150000000000001', 'x-litellm-response-cost-discount-amount': '0.0', 'x-litellm-response-cost-original': '0.0006150000000000001', 'x-litellm-response-duration-ms': '388.606', 'x-litellm-version': '1.79.0', 'x-ratelimit-limit-requests': '150', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '141', 'x-ratelimit-remaining-tokens': '104784', 'cf-cache-status': 'DYNAMIC', 'vary': 'accept-encoding', 'strict-transport-security': 'max-age=31536000', 'set-cookie': '__cf_bm=sxAe3C4goeYbu.PlYahVP1.voUbUfbYD9.TPiPNLrtg-1761860643.5001547-1.0.1.1-u2bDx55yZLry1Mvw8_6iU_h6UfPXR3RW6wyvIhN7rYR3hkWaPLUZSSwwXFwkEtk86QEsAg2Cl_immqQu0FgBW2ndoSSVaeVxN9nPfIfs1Xo9sfkKyhZiH9mM4I7L4lUs; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:14:03 GMT', 'cf-ray': '996e177ddea34f3a-EWR'})
DEBUG:openai._base_client:request_id: None
DEBUG:LiteLLM:RAW RESPONSE:
{"id": "chatcmpl-CWUj5nttPMLq2uRcpTVlEQPvXoMNi", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "subject: TACP-5  \npredicate: has_gram_staining  \nobject: Gram-negative  ", "refusal": null, "role": "assistant", "annotations": [], "audio": null, "function_call": null, "tool_calls": null}, "provider_specific_fields": {"content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}}], "created": 1761860643, "model": "gpt-4o-2024-08-06", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_4a331a0222", "usage": {"completion_tokens": 21, "prompt_tokens": 162, "total_tokens": 183, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}


DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this staining result>\npredicate: <the type of staining relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific Gram staining result>\n\n\nText:\nTACP-5 has_gram_staining Gram-negative\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): c6a37608c1a44b85d324f7ab9bf8982775e2ee76d32a455900c8bc909de6c791
DEBUG:LiteLLM:Final hashed key: c6a37608c1a44b85d324f7ab9bf8982775e2ee76d32a455900c8bc909de6c791
INFO:LiteLLM:Wrapper: Completed Call, calling success_handler
DEBUG:LiteLLM:response_cost: 0.0006150000000000001
INFO:root:PARSING LINE: subject: TACP-5
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call: Cache_hit=None
DEBUG:root:  FIELD: subject
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:SLOT: subject INL: False VALS: ['TACP-5']
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
INFO:root:PARSING LINE: predicate: has_gram_staining
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call streaming complete
DEBUG:root:  FIELD: predicate
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:SLOT: predicate INL: None VALS: ['has_gram_staining']
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
INFO:root:PARSING LINE: object: Gram-negative
DEBUG:root:  FIELD: object
DEBUG:root:SLOT: object INL: False VALS: ['Gram-negative']
INFO:root:PARSING LINE: motility_relationships: H-2 has_motility non-motile;172 has_motility non-motile;TACP-2 has_motility non-motile;TACP-5 has_motility non-motile
DEBUG:root:  FIELD: motility_relationships
DEBUG:root:SLOT: motility_relationships INL: True VALS: ['H-2 has_motility non-motile', '172 has_motility non-motile', 'TACP-2 has_motility non-motile', 'TACP-5 has_motility non-motile']
DEBUG:root:  RECURSING ON SLOT: motility_relationships, range=MotilityRelationship
INFO:ontogpt.clients.llm_client:Complete: engine=gpt-4o, prompt[403]=Split the following piece of text into fields in the following format:

subject: <the strain with th...
DEBUG:LiteLLM:

DEBUG:LiteLLM:[92mRequest to litellm:[0m
DEBUG:LiteLLM:[92mlitellm.completion(api_key='', api_base='https://api.cborg.lbl.gov', api_version=None, model='gpt-4o', messages=[{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\nH-2 has_motility non-motile\n\n===\n\n', 'role': 'user'}], temperature=1.0, caching=True, custom_llm_provider='openai')[0m
DEBUG:LiteLLM:

DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:SYNC kwargs[caching]: True; litellm.cache: <litellm.caching.caching.Cache object at 0x105624f90>; kwargs.get('cache')['no-cache']: False
DEBUG:LiteLLM:INSIDE CHECKING SYNC CACHE
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\nH-2 has_motility non-motile\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): ab21dc5dc87a7ad4866b06fb15ed1e3a62c9db331e61bb19c6ae1ffccdd728ae
DEBUG:LiteLLM:Final hashed key: ab21dc5dc87a7ad4866b06fb15ed1e3a62c9db331e61bb19c6ae1ffccdd728ae
INFO:LiteLLM:
LiteLLM completion() model= gpt-4o; provider = openai
DEBUG:LiteLLM:
LiteLLM: Params passed to completion() {'model': 'gpt-4o', 'functions': None, 'function_call': None, 'temperature': 1.0, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\nH-2 has_motility non-motile\n\n===\n\n', 'role': 'user'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
DEBUG:LiteLLM:
LiteLLM: Non-Default params passed to completion() {'temperature': 1.0}
DEBUG:LiteLLM:Final returned optional params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:self.optional_params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o', 'combined_model_name': 'openai/gpt-4o', 'stripped_model_name': 'gpt-4o', 'combined_stripped_model_name': 'openai/gpt-4o', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.cborg.lbl.gov \
-d '{'model': 'gpt-4o', 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\nH-2 has_motility non-motile\n\n===\n\n', 'role': 'user'}], 'temperature': 1.0, 'extra_body': {}}'
[0m

DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-ae1d1fee-1b20-498c-b48a-76782a558124', 'json_data': {'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\nH-2 has_motility non-motile\n\n===\n\n', 'role': 'user'}], 'model': 'gpt-4o', 'temperature': 1.0}, 'extra_json': {}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.cborg.lbl.gov/chat/completions
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 30 Oct 2025 21:44:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'llm_provider-apim-request-id', b'687a041f-9d1f-4c87-b761-7af88356961c'), (b'llm_provider-azureml-model-session', b'd015-20251018173616'), (b'llm_provider-content-length', b'1099'), (b'llm_provider-content-type', b'application/json'), (b'llm_provider-date', b'Thu, 30 Oct 2025 21:44:03 GMT'), (b'llm_provider-strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'llm_provider-x-accel-buffering', b'no'), (b'llm_provider-x-content-type-options', b'nosniff'), (b'llm_provider-x-ms-deployment-name', b'gpt-4o'), (b'llm_provider-x-ms-rai-invoked', b'true'), (b'llm_provider-x-ms-region', b'East US'), (b'llm_provider-x-ratelimit-limit-requests', b'150'), (b'llm_provider-x-ratelimit-limit-tokens', b'150000'), (b'llm_provider-x-ratelimit-remaining-requests', b'140'), (b'llm_provider-x-ratelimit-remaining-tokens', b'104617'), (b'llm_provider-x-request-id', b'95fc8992-c00e-4e42-bba5-14da0d8c5cb4'), (b'Server', b'cloudflare'), (b'x-litellm-attempted-fallbacks', b'0'), (b'x-litellm-attempted-retries', b'0'), (b'x-litellm-call-id', b'd9e232cd-0449-4ae8-ab88-e8e738701f9d'), (b'x-litellm-key-spend', b'32.764626900000074'), (b'x-litellm-model-api-base', b'https://science-it-openai.openai.azure.com/'), (b'x-litellm-model-group', b'gpt-4o'), (b'x-litellm-model-id', b'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38'), (b'x-litellm-overhead-duration-ms', b'1.213'), (b'x-litellm-response-cost', b'0.0006200000000000001'), (b'x-litellm-response-cost-discount-amount', b'0.0'), (b'x-litellm-response-cost-original', b'0.0006200000000000001'), (b'x-litellm-response-duration-ms', b'389.083'), (b'x-litellm-version', b'1.79.0'), (b'x-ratelimit-limit-requests', b'150'), (b'x-ratelimit-limit-tokens', b'150000'), (b'x-ratelimit-remaining-requests', b'140'), (b'x-ratelimit-remaining-tokens', b'104617'), (b'cf-cache-status', b'DYNAMIC'), (b'vary', b'accept-encoding'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'Set-Cookie', b'__cf_bm=SyVBEB87Z2akyg9GKkL.FTcf0ZRFqOeSFnuJx270zB0-1761860644.052169-1.0.1.1-MH6E8R32yeltkGPphUicBs8uuDD5YIOa.iwyRKLr6_FDmCvBxVy3wA9EH4aEQwTlwt12I8InY2Hj4hQQD87.yElnFSTtXV054FktduyrKcugjZ9Wepr3ghjRZKRSVdrz; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:14:04 GMT'), (b'CF-RAY', b'996e17815fa24f3a-EWR')])
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.cborg.lbl.gov/chat/completions "200 OK" Headers({'date': 'Thu, 30 Oct 2025 21:44:04 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'content-encoding': 'gzip', 'llm_provider-apim-request-id': '687a041f-9d1f-4c87-b761-7af88356961c', 'llm_provider-azureml-model-session': 'd015-20251018173616', 'llm_provider-content-length': '1099', 'llm_provider-content-type': 'application/json', 'llm_provider-date': 'Thu, 30 Oct 2025 21:44:03 GMT', 'llm_provider-strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'llm_provider-x-accel-buffering': 'no', 'llm_provider-x-content-type-options': 'nosniff', 'llm_provider-x-ms-deployment-name': 'gpt-4o', 'llm_provider-x-ms-rai-invoked': 'true', 'llm_provider-x-ms-region': 'East US', 'llm_provider-x-ratelimit-limit-requests': '150', 'llm_provider-x-ratelimit-limit-tokens': '150000', 'llm_provider-x-ratelimit-remaining-requests': '140', 'llm_provider-x-ratelimit-remaining-tokens': '104617', 'llm_provider-x-request-id': '95fc8992-c00e-4e42-bba5-14da0d8c5cb4', 'server': 'cloudflare', 'x-litellm-attempted-fallbacks': '0', 'x-litellm-attempted-retries': '0', 'x-litellm-call-id': 'd9e232cd-0449-4ae8-ab88-e8e738701f9d', 'x-litellm-key-spend': '32.764626900000074', 'x-litellm-model-api-base': 'https://science-it-openai.openai.azure.com/', 'x-litellm-model-group': 'gpt-4o', 'x-litellm-model-id': 'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38', 'x-litellm-overhead-duration-ms': '1.213', 'x-litellm-response-cost': '0.0006200000000000001', 'x-litellm-response-cost-discount-amount': '0.0', 'x-litellm-response-cost-original': '0.0006200000000000001', 'x-litellm-response-duration-ms': '389.083', 'x-litellm-version': '1.79.0', 'x-ratelimit-limit-requests': '150', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '140', 'x-ratelimit-remaining-tokens': '104617', 'cf-cache-status': 'DYNAMIC', 'vary': 'accept-encoding', 'strict-transport-security': 'max-age=31536000', 'set-cookie': '__cf_bm=SyVBEB87Z2akyg9GKkL.FTcf0ZRFqOeSFnuJx270zB0-1761860644.052169-1.0.1.1-MH6E8R32yeltkGPphUicBs8uuDD5YIOa.iwyRKLr6_FDmCvBxVy3wA9EH4aEQwTlwt12I8InY2Hj4hQQD87.yElnFSTtXV054FktduyrKcugjZ9Wepr3ghjRZKRSVdrz; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:14:04 GMT', 'cf-ray': '996e17815fa24f3a-EWR'})
DEBUG:openai._base_client:request_id: None
DEBUG:LiteLLM:RAW RESPONSE:
{"id": "chatcmpl-CWUj6Q8eae2o7ZABzE60iyBgULykA", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "subject: H-2  \npredicate: has_motility  \nobject: non-motile  ", "refusal": null, "role": "assistant", "annotations": [], "audio": null, "function_call": null, "tool_calls": null}, "provider_specific_fields": {"content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}}], "created": 1761860644, "model": "gpt-4o-2024-08-06", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_4a331a0222", "usage": {"completion_tokens": 21, "prompt_tokens": 164, "total_tokens": 185, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}


DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\nH-2 has_motility non-motile\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): ab21dc5dc87a7ad4866b06fb15ed1e3a62c9db331e61bb19c6ae1ffccdd728ae
DEBUG:LiteLLM:Final hashed key: ab21dc5dc87a7ad4866b06fb15ed1e3a62c9db331e61bb19c6ae1ffccdd728ae
INFO:LiteLLM:Wrapper: Completed Call, calling success_handler
DEBUG:LiteLLM:response_cost: 0.0006200000000000001
INFO:root:PARSING LINE: subject: H-2
DEBUG:root:  FIELD: subject
DEBUG:root:SLOT: subject INL: False VALS: ['H-2']
INFO:root:PARSING LINE: predicate: has_motility
DEBUG:root:  FIELD: predicate
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call: Cache_hit=None
DEBUG:root:SLOT: predicate INL: None VALS: ['has_motility']
INFO:root:PARSING LINE: object: non-motile
DEBUG:root:  FIELD: object
DEBUG:root:SLOT: object INL: False VALS: ['non-motile']
INFO:ontogpt.clients.llm_client:Complete: engine=gpt-4o, prompt[403]=Split the following piece of text into fields in the following format:

subject: <the strain with th...
DEBUG:LiteLLM:

DEBUG:LiteLLM:[92mRequest to litellm:[0m
DEBUG:LiteLLM:[92mlitellm.completion(api_key='', api_base='https://api.cborg.lbl.gov', api_version=None, model='gpt-4o', messages=[{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\n172 has_motility non-motile\n\n===\n\n', 'role': 'user'}], temperature=1.0, caching=True, custom_llm_provider='openai')[0m
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:

DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call streaming complete
DEBUG:LiteLLM:SYNC kwargs[caching]: True; litellm.cache: <litellm.caching.caching.Cache object at 0x105624f90>; kwargs.get('cache')['no-cache']: False
DEBUG:LiteLLM:INSIDE CHECKING SYNC CACHE
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\n172 has_motility non-motile\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:LiteLLM:Hashed cache key (SHA-256): 0a9fdeaa6cc05c44489f77bd13a10689234c293cd36b49d7e11d0c80b4a9ce28
DEBUG:LiteLLM:Final hashed key: 0a9fdeaa6cc05c44489f77bd13a10689234c293cd36b49d7e11d0c80b4a9ce28
INFO:LiteLLM:
LiteLLM completion() model= gpt-4o; provider = openai
DEBUG:LiteLLM:
LiteLLM: Params passed to completion() {'model': 'gpt-4o', 'functions': None, 'function_call': None, 'temperature': 1.0, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\n172 has_motility non-motile\n\n===\n\n', 'role': 'user'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
DEBUG:LiteLLM:
LiteLLM: Non-Default params passed to completion() {'temperature': 1.0}
DEBUG:LiteLLM:Final returned optional params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:self.optional_params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o', 'combined_model_name': 'openai/gpt-4o', 'stripped_model_name': 'gpt-4o', 'combined_stripped_model_name': 'openai/gpt-4o', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.cborg.lbl.gov \
-d '{'model': 'gpt-4o', 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\n172 has_motility non-motile\n\n===\n\n', 'role': 'user'}], 'temperature': 1.0, 'extra_body': {}}'
[0m

DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-f8eb9a6e-ce42-451f-b3d9-8d276e37b7b3', 'json_data': {'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\n172 has_motility non-motile\n\n===\n\n', 'role': 'user'}], 'model': 'gpt-4o', 'temperature': 1.0}, 'extra_json': {}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.cborg.lbl.gov/chat/completions
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 30 Oct 2025 21:44:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'llm_provider-apim-request-id', b'684fc23a-4962-47e7-9bd0-e01d4350d813'), (b'llm_provider-azureml-model-session', b'd015-20251018173616'), (b'llm_provider-content-length', b'1099'), (b'llm_provider-content-type', b'application/json'), (b'llm_provider-date', b'Thu, 30 Oct 2025 21:44:04 GMT'), (b'llm_provider-strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'llm_provider-x-accel-buffering', b'no'), (b'llm_provider-x-content-type-options', b'nosniff'), (b'llm_provider-x-ms-deployment-name', b'gpt-4o'), (b'llm_provider-x-ms-rai-invoked', b'true'), (b'llm_provider-x-ms-region', b'East US'), (b'llm_provider-x-ratelimit-limit-requests', b'150'), (b'llm_provider-x-ratelimit-limit-tokens', b'150000'), (b'llm_provider-x-ratelimit-remaining-requests', b'139'), (b'llm_provider-x-ratelimit-remaining-tokens', b'104450'), (b'llm_provider-x-request-id', b'22d5e3b2-3fca-4d91-b155-a69a18c656a9'), (b'Server', b'cloudflare'), (b'x-litellm-attempted-fallbacks', b'0'), (b'x-litellm-attempted-retries', b'0'), (b'x-litellm-call-id', b'2a9331a0-6575-469c-a208-0dc73e873ff8'), (b'x-litellm-key-spend', b'32.76524690000007'), (b'x-litellm-model-api-base', b'https://science-it-openai.openai.azure.com/'), (b'x-litellm-model-group', b'gpt-4o'), (b'x-litellm-model-id', b'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38'), (b'x-litellm-overhead-duration-ms', b'1.233'), (b'x-litellm-response-cost', b'0.0006050000000000001'), (b'x-litellm-response-cost-discount-amount', b'0.0'), (b'x-litellm-response-cost-original', b'0.0006050000000000001'), (b'x-litellm-response-duration-ms', b'385.389'), (b'x-litellm-version', b'1.79.0'), (b'x-ratelimit-limit-requests', b'150'), (b'x-ratelimit-limit-tokens', b'150000'), (b'x-ratelimit-remaining-requests', b'139'), (b'x-ratelimit-remaining-tokens', b'104450'), (b'cf-cache-status', b'DYNAMIC'), (b'vary', b'accept-encoding'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'Set-Cookie', b'__cf_bm=WcvuSZIJ7T8rvS0yuGCXCM0Aq_zPWMMQmSBfJSWrS.4-1761860644.5723178-1.0.1.1-Aj3Xsf.uEQau1tzySUl59X1g8oIOf7GuSOtSpctn2xyo6JVjTcCqP20NsJTt28_HTecx6Ku2Sg5T3UWiklOmpVDcRcYrLJjD0PC_nraDSwFrDzWUddVdaJk6sbPVBwy4; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:14:05 GMT'), (b'CF-RAY', b'996e1784990e4f3a-EWR')])
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.cborg.lbl.gov/chat/completions "200 OK" Headers({'date': 'Thu, 30 Oct 2025 21:44:05 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'content-encoding': 'gzip', 'llm_provider-apim-request-id': '684fc23a-4962-47e7-9bd0-e01d4350d813', 'llm_provider-azureml-model-session': 'd015-20251018173616', 'llm_provider-content-length': '1099', 'llm_provider-content-type': 'application/json', 'llm_provider-date': 'Thu, 30 Oct 2025 21:44:04 GMT', 'llm_provider-strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'llm_provider-x-accel-buffering': 'no', 'llm_provider-x-content-type-options': 'nosniff', 'llm_provider-x-ms-deployment-name': 'gpt-4o', 'llm_provider-x-ms-rai-invoked': 'true', 'llm_provider-x-ms-region': 'East US', 'llm_provider-x-ratelimit-limit-requests': '150', 'llm_provider-x-ratelimit-limit-tokens': '150000', 'llm_provider-x-ratelimit-remaining-requests': '139', 'llm_provider-x-ratelimit-remaining-tokens': '104450', 'llm_provider-x-request-id': '22d5e3b2-3fca-4d91-b155-a69a18c656a9', 'server': 'cloudflare', 'x-litellm-attempted-fallbacks': '0', 'x-litellm-attempted-retries': '0', 'x-litellm-call-id': '2a9331a0-6575-469c-a208-0dc73e873ff8', 'x-litellm-key-spend': '32.76524690000007', 'x-litellm-model-api-base': 'https://science-it-openai.openai.azure.com/', 'x-litellm-model-group': 'gpt-4o', 'x-litellm-model-id': 'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38', 'x-litellm-overhead-duration-ms': '1.233', 'x-litellm-response-cost': '0.0006050000000000001', 'x-litellm-response-cost-discount-amount': '0.0', 'x-litellm-response-cost-original': '0.0006050000000000001', 'x-litellm-response-duration-ms': '385.389', 'x-litellm-version': '1.79.0', 'x-ratelimit-limit-requests': '150', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '139', 'x-ratelimit-remaining-tokens': '104450', 'cf-cache-status': 'DYNAMIC', 'vary': 'accept-encoding', 'strict-transport-security': 'max-age=31536000', 'set-cookie': '__cf_bm=WcvuSZIJ7T8rvS0yuGCXCM0Aq_zPWMMQmSBfJSWrS.4-1761860644.5723178-1.0.1.1-Aj3Xsf.uEQau1tzySUl59X1g8oIOf7GuSOtSpctn2xyo6JVjTcCqP20NsJTt28_HTecx6Ku2Sg5T3UWiklOmpVDcRcYrLJjD0PC_nraDSwFrDzWUddVdaJk6sbPVBwy4; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:14:05 GMT', 'cf-ray': '996e1784990e4f3a-EWR'})
DEBUG:openai._base_client:request_id: None
DEBUG:LiteLLM:RAW RESPONSE:
{"id": "chatcmpl-CWUj6jcxO3UOHa2q9BeWXa0sCF7aD", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "subject: 172  \npredicate: has_motility  \nobject: non-motile  ", "refusal": null, "role": "assistant", "annotations": [], "audio": null, "function_call": null, "tool_calls": null}, "provider_specific_fields": {"content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}}], "created": 1761860644, "model": "gpt-4o-2024-08-06", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_4a331a0222", "usage": {"completion_tokens": 20, "prompt_tokens": 162, "total_tokens": 182, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}


DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\n172 has_motility non-motile\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 0a9fdeaa6cc05c44489f77bd13a10689234c293cd36b49d7e11d0c80b4a9ce28
DEBUG:LiteLLM:Final hashed key: 0a9fdeaa6cc05c44489f77bd13a10689234c293cd36b49d7e11d0c80b4a9ce28
INFO:LiteLLM:Wrapper: Completed Call, calling success_handler
DEBUG:LiteLLM:response_cost: 0.0006050000000000001
INFO:root:PARSING LINE: subject: 172
DEBUG:root:  FIELD: subject
DEBUG:root:SLOT: subject INL: False VALS: ['172']
INFO:root:PARSING LINE: predicate: has_motility
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call: Cache_hit=None
DEBUG:root:  FIELD: predicate
DEBUG:root:SLOT: predicate INL: None VALS: ['has_motility']
INFO:root:PARSING LINE: object: non-motile
DEBUG:root:  FIELD: object
DEBUG:root:SLOT: object INL: False VALS: ['non-motile']
INFO:ontogpt.clients.llm_client:Complete: engine=gpt-4o, prompt[406]=Split the following piece of text into fields in the following format:

subject: <the strain with th...
DEBUG:LiteLLM:

DEBUG:LiteLLM:[92mRequest to litellm:[0m
DEBUG:LiteLLM:[92mlitellm.completion(api_key='', api_base='https://api.cborg.lbl.gov', api_version=None, model='gpt-4o', messages=[{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\nTACP-2 has_motility non-motile\n\n===\n\n', 'role': 'user'}], temperature=1.0, caching=True, custom_llm_provider='openai')[0m
DEBUG:LiteLLM:

DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:LiteLLM:SYNC kwargs[caching]: True; litellm.cache: <litellm.caching.caching.Cache object at 0x105624f90>; kwargs.get('cache')['no-cache']: False
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call streaming complete
DEBUG:LiteLLM:INSIDE CHECKING SYNC CACHE
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\nTACP-2 has_motility non-motile\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): bbb9b95ba34e3abea08800e090aaa56c96943558d1b347bbebf19f5bd28b1a40
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:LiteLLM:Final hashed key: bbb9b95ba34e3abea08800e090aaa56c96943558d1b347bbebf19f5bd28b1a40
INFO:LiteLLM:
LiteLLM completion() model= gpt-4o; provider = openai
DEBUG:LiteLLM:
LiteLLM: Params passed to completion() {'model': 'gpt-4o', 'functions': None, 'function_call': None, 'temperature': 1.0, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\nTACP-2 has_motility non-motile\n\n===\n\n', 'role': 'user'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
DEBUG:LiteLLM:
LiteLLM: Non-Default params passed to completion() {'temperature': 1.0}
DEBUG:LiteLLM:Final returned optional params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:self.optional_params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o', 'combined_model_name': 'openai/gpt-4o', 'stripped_model_name': 'gpt-4o', 'combined_stripped_model_name': 'openai/gpt-4o', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.cborg.lbl.gov \
-d '{'model': 'gpt-4o', 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\nTACP-2 has_motility non-motile\n\n===\n\n', 'role': 'user'}], 'temperature': 1.0, 'extra_body': {}}'
[0m

DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-2b0251ef-26d7-4237-b842-dfaa361072ff', 'json_data': {'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\nTACP-2 has_motility non-motile\n\n===\n\n', 'role': 'user'}], 'model': 'gpt-4o', 'temperature': 1.0}, 'extra_json': {}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.cborg.lbl.gov/chat/completions
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 30 Oct 2025 21:44:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'llm_provider-apim-request-id', b'7b149125-513e-40c1-b33b-95634a701240'), (b'llm_provider-azureml-model-session', b'd015-20251018173616'), (b'llm_provider-content-length', b'1096'), (b'llm_provider-content-type', b'application/json'), (b'llm_provider-date', b'Thu, 30 Oct 2025 21:44:04 GMT'), (b'llm_provider-strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'llm_provider-x-accel-buffering', b'no'), (b'llm_provider-x-content-type-options', b'nosniff'), (b'llm_provider-x-ms-deployment-name', b'gpt-4o'), (b'llm_provider-x-ms-rai-invoked', b'true'), (b'llm_provider-x-ms-region', b'East US'), (b'llm_provider-x-ratelimit-limit-requests', b'150'), (b'llm_provider-x-ratelimit-limit-tokens', b'150000'), (b'llm_provider-x-ratelimit-remaining-requests', b'137'), (b'llm_provider-x-ratelimit-remaining-tokens', b'102319'), (b'llm_provider-x-request-id', b'f0ba57b2-cc08-4be7-8846-292ee86882f6'), (b'Server', b'cloudflare'), (b'x-litellm-attempted-fallbacks', b'0'), (b'x-litellm-attempted-retries', b'0'), (b'x-litellm-call-id', b'2bf88d81-26b1-4ca8-b905-2ed22ca50d92'), (b'x-litellm-key-spend', b'32.76585190000007'), (b'x-litellm-model-api-base', b'https://science-it-openai.openai.azure.com/'), (b'x-litellm-model-group', b'gpt-4o'), (b'x-litellm-model-id', b'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38'), (b'x-litellm-overhead-duration-ms', b'1.312'), (b'x-litellm-response-cost', b'0.0006225'), (b'x-litellm-response-cost-discount-amount', b'0.0'), (b'x-litellm-response-cost-original', b'0.0006225'), (b'x-litellm-response-duration-ms', b'384.019'), (b'x-litellm-version', b'1.79.0'), (b'x-ratelimit-limit-requests', b'150'), (b'x-ratelimit-limit-tokens', b'150000'), (b'x-ratelimit-remaining-requests', b'137'), (b'x-ratelimit-remaining-tokens', b'102319'), (b'cf-cache-status', b'DYNAMIC'), (b'vary', b'accept-encoding'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'Set-Cookie', b'__cf_bm=RgQ.jUwDpThwZGTrwPDiTIF9d17ihsv3kHI8qXBOeOk-1761860645.0893514-1.0.1.1-a8aXlEEUsoXlLTdUO3Kc6nerNVKL2nH4ScvgXYuPxE_Skq45GAcII7rezH6cMMs3WuLyZyrAyhwZE6S8nI4__T4usO4kxm90owkyNdWqiOJYW.e11McLJqxCoJL7hYHp; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:14:05 GMT'), (b'CF-RAY', b'996e1787c9c04f3a-EWR')])
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.cborg.lbl.gov/chat/completions "200 OK" Headers({'date': 'Thu, 30 Oct 2025 21:44:05 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'content-encoding': 'gzip', 'llm_provider-apim-request-id': '7b149125-513e-40c1-b33b-95634a701240', 'llm_provider-azureml-model-session': 'd015-20251018173616', 'llm_provider-content-length': '1096', 'llm_provider-content-type': 'application/json', 'llm_provider-date': 'Thu, 30 Oct 2025 21:44:04 GMT', 'llm_provider-strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'llm_provider-x-accel-buffering': 'no', 'llm_provider-x-content-type-options': 'nosniff', 'llm_provider-x-ms-deployment-name': 'gpt-4o', 'llm_provider-x-ms-rai-invoked': 'true', 'llm_provider-x-ms-region': 'East US', 'llm_provider-x-ratelimit-limit-requests': '150', 'llm_provider-x-ratelimit-limit-tokens': '150000', 'llm_provider-x-ratelimit-remaining-requests': '137', 'llm_provider-x-ratelimit-remaining-tokens': '102319', 'llm_provider-x-request-id': 'f0ba57b2-cc08-4be7-8846-292ee86882f6', 'server': 'cloudflare', 'x-litellm-attempted-fallbacks': '0', 'x-litellm-attempted-retries': '0', 'x-litellm-call-id': '2bf88d81-26b1-4ca8-b905-2ed22ca50d92', 'x-litellm-key-spend': '32.76585190000007', 'x-litellm-model-api-base': 'https://science-it-openai.openai.azure.com/', 'x-litellm-model-group': 'gpt-4o', 'x-litellm-model-id': 'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38', 'x-litellm-overhead-duration-ms': '1.312', 'x-litellm-response-cost': '0.0006225', 'x-litellm-response-cost-discount-amount': '0.0', 'x-litellm-response-cost-original': '0.0006225', 'x-litellm-response-duration-ms': '384.019', 'x-litellm-version': '1.79.0', 'x-ratelimit-limit-requests': '150', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '137', 'x-ratelimit-remaining-tokens': '102319', 'cf-cache-status': 'DYNAMIC', 'vary': 'accept-encoding', 'strict-transport-security': 'max-age=31536000', 'set-cookie': '__cf_bm=RgQ.jUwDpThwZGTrwPDiTIF9d17ihsv3kHI8qXBOeOk-1761860645.0893514-1.0.1.1-a8aXlEEUsoXlLTdUO3Kc6nerNVKL2nH4ScvgXYuPxE_Skq45GAcII7rezH6cMMs3WuLyZyrAyhwZE6S8nI4__T4usO4kxm90owkyNdWqiOJYW.e11McLJqxCoJL7hYHp; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:14:05 GMT', 'cf-ray': '996e1787c9c04f3a-EWR'})
DEBUG:openai._base_client:request_id: None
DEBUG:LiteLLM:RAW RESPONSE:
{"id": "chatcmpl-CWUj7N6ZzLZIXaIlVYnLElhAGLy8f", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "subject: TACP-2\npredicate: has_motility\nobject: non-motile", "refusal": null, "role": "assistant", "annotations": [], "audio": null, "function_call": null, "tool_calls": null}, "provider_specific_fields": {"content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}}], "created": 1761860645, "model": "gpt-4o-2024-08-06", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_4a331a0222", "usage": {"completion_tokens": 21, "prompt_tokens": 165, "total_tokens": 186, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}


DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\nTACP-2 has_motility non-motile\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): bbb9b95ba34e3abea08800e090aaa56c96943558d1b347bbebf19f5bd28b1a40
DEBUG:LiteLLM:Final hashed key: bbb9b95ba34e3abea08800e090aaa56c96943558d1b347bbebf19f5bd28b1a40
INFO:LiteLLM:Wrapper: Completed Call, calling success_handler
DEBUG:LiteLLM:response_cost: 0.0006225
INFO:root:PARSING LINE: subject: TACP-2
DEBUG:root:  FIELD: subject
DEBUG:root:SLOT: subject INL: False VALS: ['TACP-2']
INFO:root:PARSING LINE: predicate: has_motility
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call: Cache_hit=None
DEBUG:root:  FIELD: predicate
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:SLOT: predicate INL: None VALS: ['has_motility']
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
INFO:root:PARSING LINE: object: non-motile
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call streaming complete
DEBUG:root:  FIELD: object
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:SLOT: object INL: False VALS: ['non-motile']
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
INFO:ontogpt.clients.llm_client:Complete: engine=gpt-4o, prompt[406]=Split the following piece of text into fields in the following format:

subject: <the strain with th...
DEBUG:LiteLLM:

DEBUG:LiteLLM:[92mRequest to litellm:[0m
DEBUG:LiteLLM:[92mlitellm.completion(api_key='', api_base='https://api.cborg.lbl.gov', api_version=None, model='gpt-4o', messages=[{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\nTACP-5 has_motility non-motile\n\n===\n\n', 'role': 'user'}], temperature=1.0, caching=True, custom_llm_provider='openai')[0m
DEBUG:LiteLLM:

DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:SYNC kwargs[caching]: True; litellm.cache: <litellm.caching.caching.Cache object at 0x105624f90>; kwargs.get('cache')['no-cache']: False
DEBUG:LiteLLM:INSIDE CHECKING SYNC CACHE
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\nTACP-5 has_motility non-motile\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 029f85d8f15936c4c3b2332af7be1eb63992459604385d4ff8f1c33ae9a76704
DEBUG:LiteLLM:Final hashed key: 029f85d8f15936c4c3b2332af7be1eb63992459604385d4ff8f1c33ae9a76704
INFO:LiteLLM:
LiteLLM completion() model= gpt-4o; provider = openai
DEBUG:LiteLLM:
LiteLLM: Params passed to completion() {'model': 'gpt-4o', 'functions': None, 'function_call': None, 'temperature': 1.0, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\nTACP-5 has_motility non-motile\n\n===\n\n', 'role': 'user'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
DEBUG:LiteLLM:
LiteLLM: Non-Default params passed to completion() {'temperature': 1.0}
DEBUG:LiteLLM:Final returned optional params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:self.optional_params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o', 'combined_model_name': 'openai/gpt-4o', 'stripped_model_name': 'gpt-4o', 'combined_stripped_model_name': 'openai/gpt-4o', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.cborg.lbl.gov \
-d '{'model': 'gpt-4o', 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\nTACP-5 has_motility non-motile\n\n===\n\n', 'role': 'user'}], 'temperature': 1.0, 'extra_body': {}}'
[0m

DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-8b5f2d0d-5199-458e-a1a0-95726b7af5c5', 'json_data': {'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\nTACP-5 has_motility non-motile\n\n===\n\n', 'role': 'user'}], 'model': 'gpt-4o', 'temperature': 1.0}, 'extra_json': {}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.cborg.lbl.gov/chat/completions
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 30 Oct 2025 21:44:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'llm_provider-apim-request-id', b'c389da3f-8781-4fa8-9f9b-5bd8f9856a47'), (b'llm_provider-azureml-model-session', b'd015-20251018173616'), (b'llm_provider-content-length', b'1102'), (b'llm_provider-content-type', b'application/json'), (b'llm_provider-date', b'Thu, 30 Oct 2025 21:44:05 GMT'), (b'llm_provider-strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'llm_provider-x-accel-buffering', b'no'), (b'llm_provider-x-content-type-options', b'nosniff'), (b'llm_provider-x-ms-deployment-name', b'gpt-4o'), (b'llm_provider-x-ms-rai-invoked', b'true'), (b'llm_provider-x-ms-region', b'East US'), (b'llm_provider-x-ratelimit-limit-requests', b'150'), (b'llm_provider-x-ratelimit-limit-tokens', b'150000'), (b'llm_provider-x-ratelimit-remaining-requests', b'136'), (b'llm_provider-x-ratelimit-remaining-tokens', b'100184'), (b'llm_provider-x-request-id', b'2f7dacd8-2ab6-46d9-8c1e-9b2aef7efefc'), (b'Server', b'cloudflare'), (b'x-litellm-attempted-fallbacks', b'0'), (b'x-litellm-attempted-retries', b'0'), (b'x-litellm-call-id', b'7a7b4362-a9c6-486d-bf94-84a6537f334e'), (b'x-litellm-key-spend', b'32.76647440000007'), (b'x-litellm-model-api-base', b'https://science-it-openai.openai.azure.com/'), (b'x-litellm-model-group', b'gpt-4o'), (b'x-litellm-model-id', b'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38'), (b'x-litellm-overhead-duration-ms', b'1.173'), (b'x-litellm-response-cost', b'0.0006325'), (b'x-litellm-response-cost-discount-amount', b'0.0'), (b'x-litellm-response-cost-original', b'0.0006325'), (b'x-litellm-response-duration-ms', b'445.837'), (b'x-litellm-version', b'1.79.0'), (b'x-ratelimit-limit-requests', b'150'), (b'x-ratelimit-limit-tokens', b'150000'), (b'x-ratelimit-remaining-requests', b'136'), (b'x-ratelimit-remaining-tokens', b'100184'), (b'cf-cache-status', b'DYNAMIC'), (b'vary', b'accept-encoding'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'Set-Cookie', b'__cf_bm=VMA_5bHr27jpCrGWfkurXPWJfnDW_0MEUhoUx9cj390-1761860645.6040204-1.0.1.1-MAPxEQs_8PzVXLLcNzsdi68zdqqT77MllNho4iy0wTZ.IN9cp8xuph0zJm0jQ.HUYQJX3.pp69KBmI0f12JtJXF8RAkkL5YyBDuwXnGltiW63MaCsOXGoOAmtjvWnSo9; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:14:06 GMT'), (b'CF-RAY', b'996e178b0b004f3a-EWR')])
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.cborg.lbl.gov/chat/completions "200 OK" Headers({'date': 'Thu, 30 Oct 2025 21:44:06 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'content-encoding': 'gzip', 'llm_provider-apim-request-id': 'c389da3f-8781-4fa8-9f9b-5bd8f9856a47', 'llm_provider-azureml-model-session': 'd015-20251018173616', 'llm_provider-content-length': '1102', 'llm_provider-content-type': 'application/json', 'llm_provider-date': 'Thu, 30 Oct 2025 21:44:05 GMT', 'llm_provider-strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'llm_provider-x-accel-buffering': 'no', 'llm_provider-x-content-type-options': 'nosniff', 'llm_provider-x-ms-deployment-name': 'gpt-4o', 'llm_provider-x-ms-rai-invoked': 'true', 'llm_provider-x-ms-region': 'East US', 'llm_provider-x-ratelimit-limit-requests': '150', 'llm_provider-x-ratelimit-limit-tokens': '150000', 'llm_provider-x-ratelimit-remaining-requests': '136', 'llm_provider-x-ratelimit-remaining-tokens': '100184', 'llm_provider-x-request-id': '2f7dacd8-2ab6-46d9-8c1e-9b2aef7efefc', 'server': 'cloudflare', 'x-litellm-attempted-fallbacks': '0', 'x-litellm-attempted-retries': '0', 'x-litellm-call-id': '7a7b4362-a9c6-486d-bf94-84a6537f334e', 'x-litellm-key-spend': '32.76647440000007', 'x-litellm-model-api-base': 'https://science-it-openai.openai.azure.com/', 'x-litellm-model-group': 'gpt-4o', 'x-litellm-model-id': 'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38', 'x-litellm-overhead-duration-ms': '1.173', 'x-litellm-response-cost': '0.0006325', 'x-litellm-response-cost-discount-amount': '0.0', 'x-litellm-response-cost-original': '0.0006325', 'x-litellm-response-duration-ms': '445.837', 'x-litellm-version': '1.79.0', 'x-ratelimit-limit-requests': '150', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '136', 'x-ratelimit-remaining-tokens': '100184', 'cf-cache-status': 'DYNAMIC', 'vary': 'accept-encoding', 'strict-transport-security': 'max-age=31536000', 'set-cookie': '__cf_bm=VMA_5bHr27jpCrGWfkurXPWJfnDW_0MEUhoUx9cj390-1761860645.6040204-1.0.1.1-MAPxEQs_8PzVXLLcNzsdi68zdqqT77MllNho4iy0wTZ.IN9cp8xuph0zJm0jQ.HUYQJX3.pp69KBmI0f12JtJXF8RAkkL5YyBDuwXnGltiW63MaCsOXGoOAmtjvWnSo9; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:14:06 GMT', 'cf-ray': '996e178b0b004f3a-EWR'})
DEBUG:openai._base_client:request_id: None
DEBUG:LiteLLM:RAW RESPONSE:
{"id": "chatcmpl-CWUj7vFaykmcwoFj3H8z8o8GQZsWE", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "subject: TACP-5  \npredicate: has_motility  \nobject: non-motile  ", "refusal": null, "role": "assistant", "annotations": [], "audio": null, "function_call": null, "tool_calls": null}, "provider_specific_fields": {"content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}}], "created": 1761860645, "model": "gpt-4o-2024-08-06", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_4a331a0222", "usage": {"completion_tokens": 22, "prompt_tokens": 165, "total_tokens": 187, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}


DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this motility characteristic>\npredicate: <the type of motility relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific motility characteristic>\n\n\nText:\nTACP-5 has_motility non-motile\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 029f85d8f15936c4c3b2332af7be1eb63992459604385d4ff8f1c33ae9a76704
DEBUG:LiteLLM:Final hashed key: 029f85d8f15936c4c3b2332af7be1eb63992459604385d4ff8f1c33ae9a76704
INFO:LiteLLM:Wrapper: Completed Call, calling success_handler
DEBUG:LiteLLM:response_cost: 0.0006325
INFO:root:PARSING LINE: subject: TACP-5
DEBUG:root:  FIELD: subject
DEBUG:root:SLOT: subject INL: False VALS: ['TACP-5']
INFO:root:PARSING LINE: predicate: has_motility
DEBUG:root:  FIELD: predicate
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call: Cache_hit=None
DEBUG:root:SLOT: predicate INL: None VALS: ['has_motility']
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
INFO:root:PARSING LINE: object: non-motile
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:root:  FIELD: object
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call streaming complete
DEBUG:root:SLOT: object INL: False VALS: ['non-motile']
INFO:root:PARSING LINE: spore_formation_relationships: none
DEBUG:root:  FIELD: spore_formation_relationships
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:SLOT: spore_formation_relationships INL: True VALS: ['none']
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:root:  RECURSING ON SLOT: spore_formation_relationships, range=SporeFormationRelationship
INFO:ontogpt.clients.llm_client:Complete: engine=gpt-4o, prompt[401]=Split the following piece of text into fields in the following format:

subject: <the strain with th...
DEBUG:LiteLLM:

DEBUG:LiteLLM:[92mRequest to litellm:[0m
DEBUG:LiteLLM:[92mlitellm.completion(api_key='', api_base='https://api.cborg.lbl.gov', api_version=None, model='gpt-4o', messages=[{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this spore formation characteristic>\npredicate: <the type of spore formation relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific spore formation characteristic>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], temperature=1.0, caching=True, custom_llm_provider='openai')[0m
DEBUG:LiteLLM:

DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:SYNC kwargs[caching]: True; litellm.cache: <litellm.caching.caching.Cache object at 0x105624f90>; kwargs.get('cache')['no-cache']: False
DEBUG:LiteLLM:INSIDE CHECKING SYNC CACHE
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this spore formation characteristic>\npredicate: <the type of spore formation relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific spore formation characteristic>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 6dbdeb3d8cd28326fa067aec9da0e62ef1c10d5ee4e193856246efb6c1d128eb
DEBUG:LiteLLM:Final hashed key: 6dbdeb3d8cd28326fa067aec9da0e62ef1c10d5ee4e193856246efb6c1d128eb
DEBUG:LiteLLM:selected model name for cost calculation: openai/gpt-4o-2024-08-06
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:LiteLLM:response_cost: 0.0005225000000000001
DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:Filtered callbacks: ['cache']
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this spore formation characteristic>\npredicate: <the type of spore formation relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific spore formation characteristic>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 6dbdeb3d8cd28326fa067aec9da0e62ef1c10d5ee4e193856246efb6c1d128eb
DEBUG:LiteLLM:Final hashed key: 6dbdeb3d8cd28326fa067aec9da0e62ef1c10d5ee4e193856246efb6c1d128eb
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call: Cache_hit=True
DEBUG:LiteLLM:Cache hit!
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
INFO:root:PARSING LINE: subject: none
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:root:  FIELD: subject
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call streaming complete
DEBUG:root:SLOT: subject INL: False VALS: ['none']
INFO:root:PARSING LINE: predicate: none
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:  FIELD: predicate
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:root:SLOT: predicate INL: None VALS: ['none']
INFO:root:PARSING LINE: object: none
DEBUG:root:  FIELD: object
DEBUG:root:SLOT: object INL: False VALS: ['none']
INFO:root:PARSING LINE: cell_wall_relationships: none
DEBUG:root:  FIELD: cell_wall_relationships
DEBUG:root:SLOT: cell_wall_relationships INL: True VALS: ['none']
DEBUG:root:  RECURSING ON SLOT: cell_wall_relationships, range=CellWallRelationship
INFO:ontogpt.clients.llm_client:Complete: engine=gpt-4o, prompt[383]=Split the following piece of text into fields in the following format:

subject: <the strain with th...
DEBUG:LiteLLM:

DEBUG:LiteLLM:[92mRequest to litellm:[0m
DEBUG:LiteLLM:[92mlitellm.completion(api_key='', api_base='https://api.cborg.lbl.gov', api_version=None, model='gpt-4o', messages=[{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cell wall characteristic>\npredicate: <the type of cell wall relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cell wall characteristic>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], temperature=1.0, caching=True, custom_llm_provider='openai')[0m
DEBUG:LiteLLM:

DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:SYNC kwargs[caching]: True; litellm.cache: <litellm.caching.caching.Cache object at 0x105624f90>; kwargs.get('cache')['no-cache']: False
DEBUG:LiteLLM:INSIDE CHECKING SYNC CACHE
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cell wall characteristic>\npredicate: <the type of cell wall relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cell wall characteristic>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 737e897e73b513c22e3e0e6ed36cdf0f10d4fb603eff7f31b351f35e7658a182
DEBUG:LiteLLM:Final hashed key: 737e897e73b513c22e3e0e6ed36cdf0f10d4fb603eff7f31b351f35e7658a182
DEBUG:LiteLLM:selected model name for cost calculation: openai/gpt-4o-2024-08-06
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:LiteLLM:response_cost: 0.000515
DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:Filtered callbacks: ['cache']
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cell wall characteristic>\npredicate: <the type of cell wall relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cell wall characteristic>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 737e897e73b513c22e3e0e6ed36cdf0f10d4fb603eff7f31b351f35e7658a182
DEBUG:LiteLLM:Final hashed key: 737e897e73b513c22e3e0e6ed36cdf0f10d4fb603eff7f31b351f35e7658a182
DEBUG:LiteLLM:Cache hit!
INFO:root:PARSING LINE: subject: none
DEBUG:root:  FIELD: subject
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call: Cache_hit=True
DEBUG:root:SLOT: subject INL: False VALS: ['none']
INFO:root:PARSING LINE: predicate: none
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:  FIELD: predicate
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:root:SLOT: predicate INL: None VALS: ['none']
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call streaming complete
INFO:root:PARSING LINE: object: none
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:  FIELD: object
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:root:SLOT: object INL: False VALS: ['none']
INFO:root:PARSING LINE: cellular_inclusion_relationships: none
DEBUG:root:  FIELD: cellular_inclusion_relationships
DEBUG:root:SLOT: cellular_inclusion_relationships INL: True VALS: ['none']
DEBUG:root:  RECURSING ON SLOT: cellular_inclusion_relationships, range=CellularInclusionRelationship
INFO:ontogpt.clients.llm_client:Complete: engine=gpt-4o, prompt[380]=Split the following piece of text into fields in the following format:

subject: <the strain with th...
DEBUG:LiteLLM:

DEBUG:LiteLLM:[92mRequest to litellm:[0m
DEBUG:LiteLLM:[92mlitellm.completion(api_key='', api_base='https://api.cborg.lbl.gov', api_version=None, model='gpt-4o', messages=[{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cellular inclusion>\npredicate: <the type of cellular inclusion relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cellular inclusion>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}], temperature=1.0, caching=True, custom_llm_provider='openai')[0m
DEBUG:LiteLLM:

DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:SYNC kwargs[caching]: True; litellm.cache: <litellm.caching.caching.Cache object at 0x105624f90>; kwargs.get('cache')['no-cache']: False
DEBUG:LiteLLM:INSIDE CHECKING SYNC CACHE
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cellular inclusion>\npredicate: <the type of cellular inclusion relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cellular inclusion>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 0b1c626018000ce59bbbd789e9d8cf681e8577779859bf415c3e7685b4dfbb3e
DEBUG:LiteLLM:Final hashed key: 0b1c626018000ce59bbbd789e9d8cf681e8577779859bf415c3e7685b4dfbb3e
DEBUG:LiteLLM:selected model name for cost calculation: openai/gpt-4o-2024-08-06
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:LiteLLM:response_cost: 0.0005
DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:Filtered callbacks: ['cache']
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the strain with this cellular inclusion>\npredicate: <the type of cellular inclusion relationshipMust be one of: has_cell_shape, has_arrangement, has_gram_staining, has_motility, has_spore_formation, has_cell_wall_feature, has_inclusion>\nobject: <the specific cellular inclusion>\n\n\nText:\nnone\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 0b1c626018000ce59bbbd789e9d8cf681e8577779859bf415c3e7685b4dfbb3e
DEBUG:LiteLLM:Final hashed key: 0b1c626018000ce59bbbd789e9d8cf681e8577779859bf415c3e7685b4dfbb3e
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call: Cache_hit=True
DEBUG:LiteLLM:Cache hit!
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
INFO:root:PARSING LINE: subject: none
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:root:  FIELD: subject
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call streaming complete
DEBUG:root:SLOT: subject INL: False VALS: ['none']
INFO:root:PARSING LINE: predicate: none
DEBUG:root:  FIELD: predicate
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:SLOT: predicate INL: None VALS: ['none']
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
INFO:root:PARSING LINE: object: none
DEBUG:root:  FIELD: object
DEBUG:root:SLOT: object INL: False VALS: ['none']
INFO:root:PARSING LINE: pigmentation: none
DEBUG:root:  FIELD: pigmentation
DEBUG:root:SLOT: pigmentation INL: False VALS: ['none']
INFO:root:PARSING LINE: strain_relationships: H-2 type_strain_of Geobacter hydrogenophilus;172 type_strain_of Geobacter chapellei;TACP-2 type_strain_of Geobacter grbiciae;TACP-5 strain_of Geobacter grbiciae
DEBUG:root:  FIELD: strain_relationships
DEBUG:root:SLOT: strain_relationships INL: True VALS: ['H-2 type_strain_of Geobacter hydrogenophilus', '172 type_strain_of Geobacter chapellei', 'TACP-2 type_strain_of Geobacter grbiciae', 'TACP-5 strain_of Geobacter grbiciae']
DEBUG:root:  RECURSING ON SLOT: strain_relationships, range=StrainRelationship
INFO:ontogpt.clients.llm_client:Complete: engine=gpt-4o, prompt[474]=Split the following piece of text into fields in the following format:

subject: <the specific strai...
DEBUG:LiteLLM:

DEBUG:LiteLLM:[92mRequest to litellm:[0m
DEBUG:LiteLLM:[92mlitellm.completion(api_key='', api_base='https://api.cborg.lbl.gov', api_version=None, model='gpt-4o', messages=[{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\nH-2 type_strain_of Geobacter hydrogenophilus\n\n===\n\n', 'role': 'user'}], temperature=1.0, caching=True, custom_llm_provider='openai')[0m
DEBUG:LiteLLM:

DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:SYNC kwargs[caching]: True; litellm.cache: <litellm.caching.caching.Cache object at 0x105624f90>; kwargs.get('cache')['no-cache']: False
DEBUG:LiteLLM:INSIDE CHECKING SYNC CACHE
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\nH-2 type_strain_of Geobacter hydrogenophilus\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 50966924dcbc3eca12b62e4a49f6de3cd93a5d0c3c27a74096e68f24491db546
DEBUG:LiteLLM:Final hashed key: 50966924dcbc3eca12b62e4a49f6de3cd93a5d0c3c27a74096e68f24491db546
INFO:LiteLLM:
LiteLLM completion() model= gpt-4o; provider = openai
DEBUG:LiteLLM:
LiteLLM: Params passed to completion() {'model': 'gpt-4o', 'functions': None, 'function_call': None, 'temperature': 1.0, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\nH-2 type_strain_of Geobacter hydrogenophilus\n\n===\n\n', 'role': 'user'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
DEBUG:LiteLLM:
LiteLLM: Non-Default params passed to completion() {'temperature': 1.0}
DEBUG:LiteLLM:Final returned optional params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:self.optional_params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o', 'combined_model_name': 'openai/gpt-4o', 'stripped_model_name': 'gpt-4o', 'combined_stripped_model_name': 'openai/gpt-4o', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.cborg.lbl.gov \
-d '{'model': 'gpt-4o', 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\nH-2 type_strain_of Geobacter hydrogenophilus\n\n===\n\n', 'role': 'user'}], 'temperature': 1.0, 'extra_body': {}}'
[0m

DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-b89b62c9-e705-4c11-8e33-4f29c10dcf13', 'json_data': {'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\nH-2 type_strain_of Geobacter hydrogenophilus\n\n===\n\n', 'role': 'user'}], 'model': 'gpt-4o', 'temperature': 1.0}, 'extra_json': {}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.cborg.lbl.gov/chat/completions
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 30 Oct 2025 21:44:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'llm_provider-apim-request-id', b'3a3eaa9a-4b05-42e8-970c-ed29e72ae46e'), (b'llm_provider-azureml-model-session', b'd015-20251018173616'), (b'llm_provider-content-length', b'1116'), (b'llm_provider-content-type', b'application/json'), (b'llm_provider-date', b'Thu, 30 Oct 2025 21:44:06 GMT'), (b'llm_provider-strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'llm_provider-x-accel-buffering', b'no'), (b'llm_provider-x-content-type-options', b'nosniff'), (b'llm_provider-x-ms-deployment-name', b'gpt-4o'), (b'llm_provider-x-ms-rai-invoked', b'true'), (b'llm_provider-x-ms-region', b'East US'), (b'llm_provider-x-ratelimit-limit-requests', b'150'), (b'llm_provider-x-ratelimit-limit-tokens', b'150000'), (b'llm_provider-x-ratelimit-remaining-requests', b'134'), (b'llm_provider-x-ratelimit-remaining-tokens', b'97944'), (b'llm_provider-x-request-id', b'133dc422-5f26-42cf-be73-e2eadb4ccfaa'), (b'Server', b'cloudflare'), (b'x-litellm-attempted-fallbacks', b'0'), (b'x-litellm-attempted-retries', b'0'), (b'x-litellm-call-id', b'6ea56875-5958-4ce8-afc3-f1e7a5828c89'), (b'x-litellm-key-spend', b'32.76710690000007'), (b'x-litellm-model-api-base', b'https://science-it-openai.openai.azure.com/'), (b'x-litellm-model-group', b'gpt-4o'), (b'x-litellm-model-id', b'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38'), (b'x-litellm-overhead-duration-ms', b'1.135'), (b'x-litellm-response-cost', b'0.0006625'), (b'x-litellm-response-cost-discount-amount', b'0.0'), (b'x-litellm-response-cost-original', b'0.0006625'), (b'x-litellm-response-duration-ms', b'423.516'), (b'x-litellm-version', b'1.79.0'), (b'x-ratelimit-limit-requests', b'150'), (b'x-ratelimit-limit-tokens', b'150000'), (b'x-ratelimit-remaining-requests', b'134'), (b'x-ratelimit-remaining-tokens', b'97944'), (b'cf-cache-status', b'DYNAMIC'), (b'vary', b'accept-encoding'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'Set-Cookie', b'__cf_bm=SWiUXq2E_8kQGuNdzvjOxzqhQyGEHaXR_ybzurMd1YY-1761860646.19944-1.0.1.1-E7TXDOVudpbq4jtxxmDbgZeiBcUJDICQPzeHBi3oiF674YgZ1toja9nxhjkkz2mwU.Zyxe87yzi5AQEscUlau.51.mJCezsyMXxOxfuJrZKXp2o1E.439QVrsGFJ9fmP; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:14:06 GMT'), (b'CF-RAY', b'996e178ebd3b4f3a-EWR')])
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.cborg.lbl.gov/chat/completions "200 OK" Headers({'date': 'Thu, 30 Oct 2025 21:44:06 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'content-encoding': 'gzip', 'llm_provider-apim-request-id': '3a3eaa9a-4b05-42e8-970c-ed29e72ae46e', 'llm_provider-azureml-model-session': 'd015-20251018173616', 'llm_provider-content-length': '1116', 'llm_provider-content-type': 'application/json', 'llm_provider-date': 'Thu, 30 Oct 2025 21:44:06 GMT', 'llm_provider-strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'llm_provider-x-accel-buffering': 'no', 'llm_provider-x-content-type-options': 'nosniff', 'llm_provider-x-ms-deployment-name': 'gpt-4o', 'llm_provider-x-ms-rai-invoked': 'true', 'llm_provider-x-ms-region': 'East US', 'llm_provider-x-ratelimit-limit-requests': '150', 'llm_provider-x-ratelimit-limit-tokens': '150000', 'llm_provider-x-ratelimit-remaining-requests': '134', 'llm_provider-x-ratelimit-remaining-tokens': '97944', 'llm_provider-x-request-id': '133dc422-5f26-42cf-be73-e2eadb4ccfaa', 'server': 'cloudflare', 'x-litellm-attempted-fallbacks': '0', 'x-litellm-attempted-retries': '0', 'x-litellm-call-id': '6ea56875-5958-4ce8-afc3-f1e7a5828c89', 'x-litellm-key-spend': '32.76710690000007', 'x-litellm-model-api-base': 'https://science-it-openai.openai.azure.com/', 'x-litellm-model-group': 'gpt-4o', 'x-litellm-model-id': 'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38', 'x-litellm-overhead-duration-ms': '1.135', 'x-litellm-response-cost': '0.0006625', 'x-litellm-response-cost-discount-amount': '0.0', 'x-litellm-response-cost-original': '0.0006625', 'x-litellm-response-duration-ms': '423.516', 'x-litellm-version': '1.79.0', 'x-ratelimit-limit-requests': '150', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '134', 'x-ratelimit-remaining-tokens': '97944', 'cf-cache-status': 'DYNAMIC', 'vary': 'accept-encoding', 'strict-transport-security': 'max-age=31536000', 'set-cookie': '__cf_bm=SWiUXq2E_8kQGuNdzvjOxzqhQyGEHaXR_ybzurMd1YY-1761860646.19944-1.0.1.1-E7TXDOVudpbq4jtxxmDbgZeiBcUJDICQPzeHBi3oiF674YgZ1toja9nxhjkkz2mwU.Zyxe87yzi5AQEscUlau.51.mJCezsyMXxOxfuJrZKXp2o1E.439QVrsGFJ9fmP; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:14:06 GMT', 'cf-ray': '996e178ebd3b4f3a-EWR'})
DEBUG:openai._base_client:request_id: None
DEBUG:LiteLLM:RAW RESPONSE:
{"id": "chatcmpl-CWUj8B6kThaUOpeAug2rd8iUnNDZE", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "subject: H-2  \npredicate: type_strain_of  \nobject: Geobacter hydrogenophilus  ", "refusal": null, "role": "assistant", "annotations": [], "audio": null, "function_call": null, "tool_calls": null}, "provider_specific_fields": {"content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}}], "created": 1761860646, "model": "gpt-4o-2024-08-06", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_4a331a0222", "usage": {"completion_tokens": 22, "prompt_tokens": 177, "total_tokens": 199, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}


DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\nH-2 type_strain_of Geobacter hydrogenophilus\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 50966924dcbc3eca12b62e4a49f6de3cd93a5d0c3c27a74096e68f24491db546
DEBUG:LiteLLM:Final hashed key: 50966924dcbc3eca12b62e4a49f6de3cd93a5d0c3c27a74096e68f24491db546
INFO:LiteLLM:Wrapper: Completed Call, calling success_handler
DEBUG:LiteLLM:response_cost: 0.0006625
INFO:root:PARSING LINE: subject: H-2
DEBUG:root:  FIELD: subject
DEBUG:root:SLOT: subject INL: False VALS: ['H-2']
INFO:root:PARSING LINE: predicate: type_strain_of
DEBUG:root:  FIELD: predicate
DEBUG:root:SLOT: predicate INL: None VALS: ['type_strain_of']
INFO:root:PARSING LINE: object: Geobacter hydrogenophilus
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call: Cache_hit=None
DEBUG:root:  FIELD: object
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:SLOT: object INL: False VALS: ['Geobacter hydrogenophilus']
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
INFO:ontogpt.clients.llm_client:Complete: engine=gpt-4o, prompt[468]=Split the following piece of text into fields in the following format:

subject: <the specific strai...
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call streaming complete
DEBUG:LiteLLM:

DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:[92mRequest to litellm:[0m
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:LiteLLM:[92mlitellm.completion(api_key='', api_base='https://api.cborg.lbl.gov', api_version=None, model='gpt-4o', messages=[{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\n172 type_strain_of Geobacter chapellei\n\n===\n\n', 'role': 'user'}], temperature=1.0, caching=True, custom_llm_provider='openai')[0m
DEBUG:LiteLLM:

DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:SYNC kwargs[caching]: True; litellm.cache: <litellm.caching.caching.Cache object at 0x105624f90>; kwargs.get('cache')['no-cache']: False
DEBUG:LiteLLM:INSIDE CHECKING SYNC CACHE
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\n172 type_strain_of Geobacter chapellei\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 4779c4dd9c685917b9f1c2e1fd99b29a2f0744ca5e1831253c8251fdc3caa637
DEBUG:LiteLLM:Final hashed key: 4779c4dd9c685917b9f1c2e1fd99b29a2f0744ca5e1831253c8251fdc3caa637
INFO:LiteLLM:
LiteLLM completion() model= gpt-4o; provider = openai
DEBUG:LiteLLM:
LiteLLM: Params passed to completion() {'model': 'gpt-4o', 'functions': None, 'function_call': None, 'temperature': 1.0, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\n172 type_strain_of Geobacter chapellei\n\n===\n\n', 'role': 'user'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
DEBUG:LiteLLM:
LiteLLM: Non-Default params passed to completion() {'temperature': 1.0}
DEBUG:LiteLLM:Final returned optional params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:self.optional_params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o', 'combined_model_name': 'openai/gpt-4o', 'stripped_model_name': 'gpt-4o', 'combined_stripped_model_name': 'openai/gpt-4o', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.cborg.lbl.gov \
-d '{'model': 'gpt-4o', 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\n172 type_strain_of Geobacter chapellei\n\n===\n\n', 'role': 'user'}], 'temperature': 1.0, 'extra_body': {}}'
[0m

DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-ad6dfefd-902b-4f2e-ad51-3cc69e711038', 'json_data': {'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\n172 type_strain_of Geobacter chapellei\n\n===\n\n', 'role': 'user'}], 'model': 'gpt-4o', 'temperature': 1.0}, 'extra_json': {}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.cborg.lbl.gov/chat/completions
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 30 Oct 2025 21:44:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'llm_provider-apim-request-id', b'e189a4df-bb1a-4729-a807-6348e463c408'), (b'llm_provider-azureml-model-session', b'd015-20251018173616'), (b'llm_provider-content-length', b'1110'), (b'llm_provider-content-type', b'application/json'), (b'llm_provider-date', b'Thu, 30 Oct 2025 21:44:06 GMT'), (b'llm_provider-strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'llm_provider-x-accel-buffering', b'no'), (b'llm_provider-x-content-type-options', b'nosniff'), (b'llm_provider-x-ms-deployment-name', b'gpt-4o'), (b'llm_provider-x-ms-rai-invoked', b'true'), (b'llm_provider-x-ms-region', b'East US'), (b'llm_provider-x-ratelimit-limit-requests', b'150'), (b'llm_provider-x-ratelimit-limit-tokens', b'150000'), (b'llm_provider-x-ratelimit-remaining-requests', b'132'), (b'llm_provider-x-ratelimit-remaining-tokens', b'95772'), (b'llm_provider-x-request-id', b'44ce32dc-4d12-47f9-a76c-b9aaae4922b6'), (b'Server', b'cloudflare'), (b'x-litellm-attempted-fallbacks', b'0'), (b'x-litellm-attempted-retries', b'0'), (b'x-litellm-call-id', b'f94777b4-23c1-4545-9384-0b1f5d2b171c'), (b'x-litellm-key-spend', b'32.76776940000007'), (b'x-litellm-model-api-base', b'https://science-it-openai.openai.azure.com/'), (b'x-litellm-model-group', b'gpt-4o'), (b'x-litellm-model-id', b'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38'), (b'x-litellm-overhead-duration-ms', b'1.231'), (b'x-litellm-response-cost', b'0.0006475000000000001'), (b'x-litellm-response-cost-discount-amount', b'0.0'), (b'x-litellm-response-cost-original', b'0.0006475000000000001'), (b'x-litellm-response-duration-ms', b'408.074'), (b'x-litellm-version', b'1.79.0'), (b'x-ratelimit-limit-requests', b'150'), (b'x-ratelimit-limit-tokens', b'150000'), (b'x-ratelimit-remaining-requests', b'132'), (b'x-ratelimit-remaining-tokens', b'95772'), (b'cf-cache-status', b'DYNAMIC'), (b'vary', b'accept-encoding'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'Set-Cookie', b'__cf_bm=EvJg0a6G0Nihjiix4TEvrEnd57X7FMvpH_oV1v2OFq0-1761860646.7547958-1.0.1.1-Lh4FLeleaY5ASxvKy0.Sz2ke5stDB9M0BLueiyNR7Zpi8_LHfB1wlRBalnLs3wglqjSKpdrrDABzpPNLmc8gyesaCJgQORjlpsKOrcJj9cyZ9CN7RXPksUxpEGTcXbky; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:14:07 GMT'), (b'CF-RAY', b'996e17923eb64f3a-EWR')])
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.cborg.lbl.gov/chat/completions "200 OK" Headers({'date': 'Thu, 30 Oct 2025 21:44:07 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'content-encoding': 'gzip', 'llm_provider-apim-request-id': 'e189a4df-bb1a-4729-a807-6348e463c408', 'llm_provider-azureml-model-session': 'd015-20251018173616', 'llm_provider-content-length': '1110', 'llm_provider-content-type': 'application/json', 'llm_provider-date': 'Thu, 30 Oct 2025 21:44:06 GMT', 'llm_provider-strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'llm_provider-x-accel-buffering': 'no', 'llm_provider-x-content-type-options': 'nosniff', 'llm_provider-x-ms-deployment-name': 'gpt-4o', 'llm_provider-x-ms-rai-invoked': 'true', 'llm_provider-x-ms-region': 'East US', 'llm_provider-x-ratelimit-limit-requests': '150', 'llm_provider-x-ratelimit-limit-tokens': '150000', 'llm_provider-x-ratelimit-remaining-requests': '132', 'llm_provider-x-ratelimit-remaining-tokens': '95772', 'llm_provider-x-request-id': '44ce32dc-4d12-47f9-a76c-b9aaae4922b6', 'server': 'cloudflare', 'x-litellm-attempted-fallbacks': '0', 'x-litellm-attempted-retries': '0', 'x-litellm-call-id': 'f94777b4-23c1-4545-9384-0b1f5d2b171c', 'x-litellm-key-spend': '32.76776940000007', 'x-litellm-model-api-base': 'https://science-it-openai.openai.azure.com/', 'x-litellm-model-group': 'gpt-4o', 'x-litellm-model-id': 'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38', 'x-litellm-overhead-duration-ms': '1.231', 'x-litellm-response-cost': '0.0006475000000000001', 'x-litellm-response-cost-discount-amount': '0.0', 'x-litellm-response-cost-original': '0.0006475000000000001', 'x-litellm-response-duration-ms': '408.074', 'x-litellm-version': '1.79.0', 'x-ratelimit-limit-requests': '150', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '132', 'x-ratelimit-remaining-tokens': '95772', 'cf-cache-status': 'DYNAMIC', 'vary': 'accept-encoding', 'strict-transport-security': 'max-age=31536000', 'set-cookie': '__cf_bm=EvJg0a6G0Nihjiix4TEvrEnd57X7FMvpH_oV1v2OFq0-1761860646.7547958-1.0.1.1-Lh4FLeleaY5ASxvKy0.Sz2ke5stDB9M0BLueiyNR7Zpi8_LHfB1wlRBalnLs3wglqjSKpdrrDABzpPNLmc8gyesaCJgQORjlpsKOrcJj9cyZ9CN7RXPksUxpEGTcXbky; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:14:07 GMT', 'cf-ray': '996e17923eb64f3a-EWR'})
DEBUG:openai._base_client:request_id: None
DEBUG:LiteLLM:RAW RESPONSE:
{"id": "chatcmpl-CWUj8ROcdL884iGNsWLLXzH0effR7", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "subject: 172  \npredicate: type_strain_of  \nobject: Geobacter chapellei  ", "refusal": null, "role": "assistant", "annotations": [], "audio": null, "function_call": null, "tool_calls": null}, "provider_specific_fields": {"content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}}], "created": 1761860646, "model": "gpt-4o-2024-08-06", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_4a331a0222", "usage": {"completion_tokens": 21, "prompt_tokens": 175, "total_tokens": 196, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}


DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\n172 type_strain_of Geobacter chapellei\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): 4779c4dd9c685917b9f1c2e1fd99b29a2f0744ca5e1831253c8251fdc3caa637
DEBUG:LiteLLM:Final hashed key: 4779c4dd9c685917b9f1c2e1fd99b29a2f0744ca5e1831253c8251fdc3caa637
INFO:LiteLLM:Wrapper: Completed Call, calling success_handler
DEBUG:LiteLLM:response_cost: 0.0006475000000000001
INFO:root:PARSING LINE: subject: 172
DEBUG:root:  FIELD: subject
DEBUG:root:SLOT: subject INL: False VALS: ['172']
INFO:root:PARSING LINE: predicate: type_strain_of
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call: Cache_hit=None
DEBUG:root:  FIELD: predicate
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:SLOT: predicate INL: None VALS: ['type_strain_of']
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
INFO:root:PARSING LINE: object: Geobacter chapellei
DEBUG:root:  FIELD: object
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call streaming complete
DEBUG:root:SLOT: object INL: False VALS: ['Geobacter chapellei']
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
INFO:ontogpt.clients.llm_client:Complete: engine=gpt-4o, prompt[470]=Split the following piece of text into fields in the following format:

subject: <the specific strai...
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:LiteLLM:

DEBUG:LiteLLM:[92mRequest to litellm:[0m
DEBUG:LiteLLM:[92mlitellm.completion(api_key='', api_base='https://api.cborg.lbl.gov', api_version=None, model='gpt-4o', messages=[{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\nTACP-2 type_strain_of Geobacter grbiciae\n\n===\n\n', 'role': 'user'}], temperature=1.0, caching=True, custom_llm_provider='openai')[0m
DEBUG:LiteLLM:

DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:SYNC kwargs[caching]: True; litellm.cache: <litellm.caching.caching.Cache object at 0x105624f90>; kwargs.get('cache')['no-cache']: False
DEBUG:LiteLLM:INSIDE CHECKING SYNC CACHE
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\nTACP-2 type_strain_of Geobacter grbiciae\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): ec042bccccfdaf18874195be6776e4f86ecd7ec410b59235ddc6e0a2e64a93e1
DEBUG:LiteLLM:Final hashed key: ec042bccccfdaf18874195be6776e4f86ecd7ec410b59235ddc6e0a2e64a93e1
INFO:LiteLLM:
LiteLLM completion() model= gpt-4o; provider = openai
DEBUG:LiteLLM:
LiteLLM: Params passed to completion() {'model': 'gpt-4o', 'functions': None, 'function_call': None, 'temperature': 1.0, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\nTACP-2 type_strain_of Geobacter grbiciae\n\n===\n\n', 'role': 'user'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
DEBUG:LiteLLM:
LiteLLM: Non-Default params passed to completion() {'temperature': 1.0}
DEBUG:LiteLLM:Final returned optional params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:self.optional_params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o', 'combined_model_name': 'openai/gpt-4o', 'stripped_model_name': 'gpt-4o', 'combined_stripped_model_name': 'openai/gpt-4o', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.cborg.lbl.gov \
-d '{'model': 'gpt-4o', 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\nTACP-2 type_strain_of Geobacter grbiciae\n\n===\n\n', 'role': 'user'}], 'temperature': 1.0, 'extra_body': {}}'
[0m

DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-b1fafa76-c638-4309-bd34-b2f318949f6c', 'json_data': {'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\nTACP-2 type_strain_of Geobacter grbiciae\n\n===\n\n', 'role': 'user'}], 'model': 'gpt-4o', 'temperature': 1.0}, 'extra_json': {}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.cborg.lbl.gov/chat/completions
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 30 Oct 2025 21:44:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'llm_provider-apim-request-id', b'fabb4b84-1a2f-4759-b326-d246fb3a368f'), (b'llm_provider-azureml-model-session', b'd015-20251018173616'), (b'llm_provider-content-length', b'1110'), (b'llm_provider-content-type', b'application/json'), (b'llm_provider-date', b'Thu, 30 Oct 2025 21:44:07 GMT'), (b'llm_provider-strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'llm_provider-x-accel-buffering', b'no'), (b'llm_provider-x-content-type-options', b'nosniff'), (b'llm_provider-x-ms-deployment-name', b'gpt-4o'), (b'llm_provider-x-ms-rai-invoked', b'true'), (b'llm_provider-x-ms-region', b'East US'), (b'llm_provider-x-ratelimit-limit-requests', b'150'), (b'llm_provider-x-ratelimit-limit-tokens', b'150000'), (b'llm_provider-x-ratelimit-remaining-requests', b'131'), (b'llm_provider-x-ratelimit-remaining-tokens', b'95588'), (b'llm_provider-x-request-id', b'5f91c7cf-ca9a-464f-9dea-7aa22351789c'), (b'Server', b'cloudflare'), (b'x-litellm-attempted-fallbacks', b'0'), (b'x-litellm-attempted-retries', b'0'), (b'x-litellm-call-id', b'8292e365-a837-44ba-a172-71bb668a8753'), (b'x-litellm-key-spend', b'32.76841690000007'), (b'x-litellm-model-api-base', b'https://science-it-openai.openai.azure.com/'), (b'x-litellm-model-group', b'gpt-4o'), (b'x-litellm-model-id', b'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38'), (b'x-litellm-overhead-duration-ms', b'1.189'), (b'x-litellm-response-cost', b'0.0006775'), (b'x-litellm-response-cost-discount-amount', b'0.0'), (b'x-litellm-response-cost-original', b'0.0006775'), (b'x-litellm-response-duration-ms', b'430.541'), (b'x-litellm-version', b'1.79.0'), (b'x-ratelimit-limit-requests', b'150'), (b'x-ratelimit-limit-tokens', b'150000'), (b'x-ratelimit-remaining-requests', b'131'), (b'x-ratelimit-remaining-tokens', b'95588'), (b'cf-cache-status', b'DYNAMIC'), (b'vary', b'accept-encoding'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'Set-Cookie', b'__cf_bm=yCjURP35gPaLUXIDkXR3aqJc7kzCWr.MdKTuCyBEbJw-1761860647.2946732-1.0.1.1-z1ZNP8U_zOcGtOfp8m5i_aMfi0GuC.2YIojH5CbbcnhlxbKUVASopBiIxl20kxadWPPfERViQKsAAYTuMQnjOh.zUKWzx_Jv_Zmdb9q3BWQQQpFIqwu1j.9dAuYbCX9Y; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:14:07 GMT'), (b'CF-RAY', b'996e17959fea4f3a-EWR')])
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.cborg.lbl.gov/chat/completions "200 OK" Headers({'date': 'Thu, 30 Oct 2025 21:44:07 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'content-encoding': 'gzip', 'llm_provider-apim-request-id': 'fabb4b84-1a2f-4759-b326-d246fb3a368f', 'llm_provider-azureml-model-session': 'd015-20251018173616', 'llm_provider-content-length': '1110', 'llm_provider-content-type': 'application/json', 'llm_provider-date': 'Thu, 30 Oct 2025 21:44:07 GMT', 'llm_provider-strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'llm_provider-x-accel-buffering': 'no', 'llm_provider-x-content-type-options': 'nosniff', 'llm_provider-x-ms-deployment-name': 'gpt-4o', 'llm_provider-x-ms-rai-invoked': 'true', 'llm_provider-x-ms-region': 'East US', 'llm_provider-x-ratelimit-limit-requests': '150', 'llm_provider-x-ratelimit-limit-tokens': '150000', 'llm_provider-x-ratelimit-remaining-requests': '131', 'llm_provider-x-ratelimit-remaining-tokens': '95588', 'llm_provider-x-request-id': '5f91c7cf-ca9a-464f-9dea-7aa22351789c', 'server': 'cloudflare', 'x-litellm-attempted-fallbacks': '0', 'x-litellm-attempted-retries': '0', 'x-litellm-call-id': '8292e365-a837-44ba-a172-71bb668a8753', 'x-litellm-key-spend': '32.76841690000007', 'x-litellm-model-api-base': 'https://science-it-openai.openai.azure.com/', 'x-litellm-model-group': 'gpt-4o', 'x-litellm-model-id': 'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38', 'x-litellm-overhead-duration-ms': '1.189', 'x-litellm-response-cost': '0.0006775', 'x-litellm-response-cost-discount-amount': '0.0', 'x-litellm-response-cost-original': '0.0006775', 'x-litellm-response-duration-ms': '430.541', 'x-litellm-version': '1.79.0', 'x-ratelimit-limit-requests': '150', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '131', 'x-ratelimit-remaining-tokens': '95588', 'cf-cache-status': 'DYNAMIC', 'vary': 'accept-encoding', 'strict-transport-security': 'max-age=31536000', 'set-cookie': '__cf_bm=yCjURP35gPaLUXIDkXR3aqJc7kzCWr.MdKTuCyBEbJw-1761860647.2946732-1.0.1.1-z1ZNP8U_zOcGtOfp8m5i_aMfi0GuC.2YIojH5CbbcnhlxbKUVASopBiIxl20kxadWPPfERViQKsAAYTuMQnjOh.zUKWzx_Jv_Zmdb9q3BWQQQpFIqwu1j.9dAuYbCX9Y; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:14:07 GMT', 'cf-ray': '996e17959fea4f3a-EWR'})
DEBUG:openai._base_client:request_id: None
DEBUG:LiteLLM:RAW RESPONSE:
{"id": "chatcmpl-CWUj9WMueycyxPYZXBcYeO9SDYNlS", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "subject: TACP-2  \npredicate: type_strain_of  \nobject: Geobacter grbiciae", "refusal": null, "role": "assistant", "annotations": [], "audio": null, "function_call": null, "tool_calls": null}, "provider_specific_fields": {"content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}}], "created": 1761860647, "model": "gpt-4o-2024-08-06", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_4a331a0222", "usage": {"completion_tokens": 23, "prompt_tokens": 179, "total_tokens": 202, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}


DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\nTACP-2 type_strain_of Geobacter grbiciae\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): ec042bccccfdaf18874195be6776e4f86ecd7ec410b59235ddc6e0a2e64a93e1
DEBUG:LiteLLM:Final hashed key: ec042bccccfdaf18874195be6776e4f86ecd7ec410b59235ddc6e0a2e64a93e1
INFO:LiteLLM:Wrapper: Completed Call, calling success_handler
DEBUG:LiteLLM:response_cost: 0.0006775
INFO:root:PARSING LINE: subject: TACP-2
DEBUG:root:  FIELD: subject
DEBUG:root:SLOT: subject INL: False VALS: ['TACP-2']
INFO:root:PARSING LINE: predicate: type_strain_of
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call: Cache_hit=None
DEBUG:root:  FIELD: predicate
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:SLOT: predicate INL: None VALS: ['type_strain_of']
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
INFO:root:PARSING LINE: object: Geobacter grbiciae
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call streaming complete
DEBUG:root:  FIELD: object
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:SLOT: object INL: False VALS: ['Geobacter grbiciae']
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
INFO:ontogpt.clients.llm_client:Complete: engine=gpt-4o, prompt[465]=Split the following piece of text into fields in the following format:

subject: <the specific strai...
DEBUG:LiteLLM:

DEBUG:LiteLLM:[92mRequest to litellm:[0m
DEBUG:LiteLLM:[92mlitellm.completion(api_key='', api_base='https://api.cborg.lbl.gov', api_version=None, model='gpt-4o', messages=[{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\nTACP-5 strain_of Geobacter grbiciae\n\n===\n\n', 'role': 'user'}], temperature=1.0, caching=True, custom_llm_provider='openai')[0m
DEBUG:LiteLLM:

DEBUG:LiteLLM:self.optional_params: {}
DEBUG:LiteLLM:SYNC kwargs[caching]: True; litellm.cache: <litellm.caching.caching.Cache object at 0x105624f90>; kwargs.get('cache')['no-cache']: False
DEBUG:LiteLLM:INSIDE CHECKING SYNC CACHE
DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\nTACP-5 strain_of Geobacter grbiciae\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): fcd407cbb91484d09087b4e216b9153396ce46ead8737a760cf4c639773c7013
DEBUG:LiteLLM:Final hashed key: fcd407cbb91484d09087b4e216b9153396ce46ead8737a760cf4c639773c7013
INFO:LiteLLM:
LiteLLM completion() model= gpt-4o; provider = openai
DEBUG:LiteLLM:
LiteLLM: Params passed to completion() {'model': 'gpt-4o', 'functions': None, 'function_call': None, 'temperature': 1.0, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\nTACP-5 strain_of Geobacter grbiciae\n\n===\n\n', 'role': 'user'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
DEBUG:LiteLLM:
LiteLLM: Non-Default params passed to completion() {'temperature': 1.0}
DEBUG:LiteLLM:Final returned optional params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:self.optional_params: {'temperature': 1.0, 'extra_body': {}}
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o', 'combined_model_name': 'openai/gpt-4o', 'stripped_model_name': 'gpt-4o', 'combined_stripped_model_name': 'openai/gpt-4o', 'custom_llm_provider': 'openai'}
DEBUG:LiteLLM:[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.cborg.lbl.gov \
-d '{'model': 'gpt-4o', 'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\nTACP-5 strain_of Geobacter grbiciae\n\n===\n\n', 'role': 'user'}], 'temperature': 1.0, 'extra_body': {}}'
[0m

DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-513f071a-7ed3-4fdd-9375-4ecc17f9e609', 'json_data': {'messages': [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\nTACP-5 strain_of Geobacter grbiciae\n\n===\n\n', 'role': 'user'}], 'model': 'gpt-4o', 'temperature': 1.0}, 'extra_json': {}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.cborg.lbl.gov/chat/completions
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 30 Oct 2025 21:44:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'llm_provider-apim-request-id', b'e5edf810-55e0-4f75-905d-238489cbf46d'), (b'llm_provider-azureml-model-session', b'd015-20251018173616'), (b'llm_provider-content-length', b'1107'), (b'llm_provider-content-type', b'application/json'), (b'llm_provider-date', b'Thu, 30 Oct 2025 21:44:07 GMT'), (b'llm_provider-strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'llm_provider-x-accel-buffering', b'no'), (b'llm_provider-x-content-type-options', b'nosniff'), (b'llm_provider-x-ms-deployment-name', b'gpt-4o'), (b'llm_provider-x-ms-rai-invoked', b'true'), (b'llm_provider-x-ms-region', b'East US'), (b'llm_provider-x-ratelimit-limit-requests', b'150'), (b'llm_provider-x-ratelimit-limit-tokens', b'150000'), (b'llm_provider-x-ratelimit-remaining-requests', b'130'), (b'llm_provider-x-ratelimit-remaining-tokens', b'95405'), (b'llm_provider-x-request-id', b'3abd058e-21f8-44c7-85ed-394450c4ecab'), (b'Server', b'cloudflare'), (b'x-litellm-attempted-fallbacks', b'0'), (b'x-litellm-attempted-retries', b'0'), (b'x-litellm-call-id', b'20497a73-dae2-4e5f-88a3-f7b52fc4da2d'), (b'x-litellm-key-spend', b'32.76909440000007'), (b'x-litellm-model-api-base', b'https://science-it-openai.openai.azure.com/'), (b'x-litellm-model-group', b'gpt-4o'), (b'x-litellm-model-id', b'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38'), (b'x-litellm-overhead-duration-ms', b'1.215'), (b'x-litellm-response-cost', b'0.0006625'), (b'x-litellm-response-cost-discount-amount', b'0.0'), (b'x-litellm-response-cost-original', b'0.0006625'), (b'x-litellm-response-duration-ms', b'438.49100000000004'), (b'x-litellm-version', b'1.79.0'), (b'x-ratelimit-limit-requests', b'150'), (b'x-ratelimit-limit-tokens', b'150000'), (b'x-ratelimit-remaining-requests', b'130'), (b'x-ratelimit-remaining-tokens', b'95405'), (b'cf-cache-status', b'DYNAMIC'), (b'vary', b'accept-encoding'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'Set-Cookie', b'__cf_bm=9BIUXhl3Yr3pqrWBdTkPNZo9W1439XcMRCs4MqA.bso-1761860647.8553672-1.0.1.1-7fPBW16heRlwmfATVJ0_kVYqiZwYQbVlxbjAmEwvE9UHbSOngiTHssaWMvERVtSaNAxgELbL9.Ud4vGELR_FgcghadZU4Z.c6ZnX.xzTGPEMIGk0hED8K_uL4.n9MNHQ; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:14:08 GMT'), (b'CF-RAY', b'996e17991a304f3a-EWR')])
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.cborg.lbl.gov/chat/completions "200 OK" Headers({'date': 'Thu, 30 Oct 2025 21:44:08 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'content-encoding': 'gzip', 'llm_provider-apim-request-id': 'e5edf810-55e0-4f75-905d-238489cbf46d', 'llm_provider-azureml-model-session': 'd015-20251018173616', 'llm_provider-content-length': '1107', 'llm_provider-content-type': 'application/json', 'llm_provider-date': 'Thu, 30 Oct 2025 21:44:07 GMT', 'llm_provider-strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'llm_provider-x-accel-buffering': 'no', 'llm_provider-x-content-type-options': 'nosniff', 'llm_provider-x-ms-deployment-name': 'gpt-4o', 'llm_provider-x-ms-rai-invoked': 'true', 'llm_provider-x-ms-region': 'East US', 'llm_provider-x-ratelimit-limit-requests': '150', 'llm_provider-x-ratelimit-limit-tokens': '150000', 'llm_provider-x-ratelimit-remaining-requests': '130', 'llm_provider-x-ratelimit-remaining-tokens': '95405', 'llm_provider-x-request-id': '3abd058e-21f8-44c7-85ed-394450c4ecab', 'server': 'cloudflare', 'x-litellm-attempted-fallbacks': '0', 'x-litellm-attempted-retries': '0', 'x-litellm-call-id': '20497a73-dae2-4e5f-88a3-f7b52fc4da2d', 'x-litellm-key-spend': '32.76909440000007', 'x-litellm-model-api-base': 'https://science-it-openai.openai.azure.com/', 'x-litellm-model-group': 'gpt-4o', 'x-litellm-model-id': 'ff67af5fcffadebb5f3be2c280edfc0814a9462d42e607ae16e9a310e599ca38', 'x-litellm-overhead-duration-ms': '1.215', 'x-litellm-response-cost': '0.0006625', 'x-litellm-response-cost-discount-amount': '0.0', 'x-litellm-response-cost-original': '0.0006625', 'x-litellm-response-duration-ms': '438.49100000000004', 'x-litellm-version': '1.79.0', 'x-ratelimit-limit-requests': '150', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '130', 'x-ratelimit-remaining-tokens': '95405', 'cf-cache-status': 'DYNAMIC', 'vary': 'accept-encoding', 'strict-transport-security': 'max-age=31536000', 'set-cookie': '__cf_bm=9BIUXhl3Yr3pqrWBdTkPNZo9W1439XcMRCs4MqA.bso-1761860647.8553672-1.0.1.1-7fPBW16heRlwmfATVJ0_kVYqiZwYQbVlxbjAmEwvE9UHbSOngiTHssaWMvERVtSaNAxgELbL9.Ud4vGELR_FgcghadZU4Z.c6ZnX.xzTGPEMIGk0hED8K_uL4.n9MNHQ; HttpOnly; Secure; Path=/; Domain=lbl.gov; Expires=Thu, 30 Oct 2025 22:14:08 GMT', 'cf-ray': '996e17991a304f3a-EWR'})
DEBUG:openai._base_client:request_id: None
DEBUG:LiteLLM:RAW RESPONSE:
{"id": "chatcmpl-CWUj9u8YzDCFSXytUelC5LW7YsWpp", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "subject: TACP-5  \npredicate: strain_of  \nobject: Geobacter grbiciae  ", "refusal": null, "role": "assistant", "annotations": [], "audio": null, "function_call": null, "tool_calls": null}, "provider_specific_fields": {"content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}}], "created": 1761860647, "model": "gpt-4o-2024-08-06", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_4a331a0222", "usage": {"completion_tokens": 22, "prompt_tokens": 177, "total_tokens": 199, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}


DEBUG:LiteLLM:
Created cache key: model: gpt-4omessages: [{'content': "You are a precise data extraction system. Output ONLY the requested fields in the exact format specified. Do not add explanations, preambles, notes, or any other text. If a field has no value, write 'none' after the colon. Never leave a field completely empty.", 'role': 'system'}, {'content': 'Split the following piece of text into fields in the following format:\n\nsubject: <the specific strain designation or identifier>\npredicate: <the type of strain-taxon relationship (strain_of, type_strain_of, isolate_of, etc.)Must be one of: strain_of, type_strain_of, reference_strain_of, isolate_of, variant_of, derived_from, identical_to, deposited_as>\nobject: <the parent species or genus this strain belongs to>\n\n\nText:\nTACP-5 strain_of Geobacter grbiciae\n\n===\n\n', 'role': 'user'}]temperature: 1.0
DEBUG:LiteLLM:Hashed cache key (SHA-256): fcd407cbb91484d09087b4e216b9153396ce46ead8737a760cf4c639773c7013
DEBUG:LiteLLM:Final hashed key: fcd407cbb91484d09087b4e216b9153396ce46ead8737a760cf4c639773c7013
INFO:LiteLLM:Wrapper: Completed Call, calling success_handler
DEBUG:LiteLLM:response_cost: 0.0006625
INFO:root:PARSING LINE: subject: TACP-5
DEBUG:root:  FIELD: subject
DEBUG:root:SLOT: subject INL: False VALS: ['TACP-5']
INFO:root:PARSING LINE: predicate: strain_of
DEBUG:root:  FIELD: predicate
DEBUG:root:SLOT: predicate INL: None VALS: ['strain_of']
INFO:root:PARSING LINE: object: Geobacter grbiciae
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call: Cache_hit=None
DEBUG:root:  FIELD: object
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:SLOT: object INL: False VALS: ['Geobacter grbiciae']
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
INFO:root:PARSING LINE: article_type: novel_species
DEBUG:LiteLLM:Logging Details LiteLLM-Success Call streaming complete
DEBUG:root:  FIELD: article_type
DEBUG:LiteLLM:checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-08-06', 'combined_model_name': 'openai/gpt-4o-2024-08-06', 'stripped_model_name': 'gpt-4o-2024-08-06', 'combined_stripped_model_name': 'openai/gpt-4o-2024-08-06', 'custom_llm_provider': 'openai'}
DEBUG:root:SLOT: article_type INL: None VALS: ['novel_species']
DEBUG:LiteLLM:model_info: {'key': 'gpt-4o-2024-08-06', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_token_flex': None, 'input_cost_per_token_priority': None, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 1.25e-06, 'cache_read_input_token_cost_flex': None, 'cache_read_input_token_cost_priority': None, 'cache_creation_input_token_cost_above_1hr': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 1.25e-06, 'output_cost_per_token_batches': 5e-06, 'output_cost_per_token': 1e-05, 'output_cost_per_token_flex': None, 'output_cost_per_token_priority': None, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_video_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'tiered_pricing': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None, 'ocr_cost_per_page': None, 'annotation_cost_per_page': None}
DEBUG:root:RAW: {'pmid': '11321104', 'study_taxa': ['Geobacter hydrogenophilus', 'Geobacter chapellei', 'Geobacter grbiciae'], 'strains': ['H-2', '172', 'TACP-2', 'TACP-5'], 'cell_shape': ['none'], 'cell_arrangements': ['none'], 'gram_staining': ['Gram-negative'], 'motility': ['non-motile'], 'spore_formation': ['none'], 'cell_wall_characteristics': ['none'], 'cellular_inclusions': ['none'], 'cell_shape_relationships': [{'subject': 'none', 'predicate': 'none', 'object': 'none'}], 'cell_arrangement_relationships': [{'subject': 'none', 'predicate': 'none', 'object': 'none'}], 'gram_staining_relationships': [{'subject': 'H-2', 'predicate': 'has_gram_staining', 'object': 'Gram-negative'}, {'subject': '172', 'predicate': 'has_gram_staining', 'object': 'Gram-negative'}, {'subject': 'TACP-2', 'predicate': 'has_gram_staining', 'object': 'Gram-negative'}, {'subject': 'TACP-5', 'predicate': 'has_gram_staining', 'object': 'Gram-negative'}], 'motility_relationships': [{'subject': 'H-2', 'predicate': 'has_motility', 'object': 'non-motile'}, {'subject': '172', 'predicate': 'has_motility', 'object': 'non-motile'}, {'subject': 'TACP-2', 'predicate': 'has_motility', 'object': 'non-motile'}, {'subject': 'TACP-5', 'predicate': 'has_motility', 'object': 'non-motile'}], 'spore_formation_relationships': [{'subject': 'none', 'predicate': 'none', 'object': 'none'}], 'cell_wall_relationships': [{'subject': 'none', 'predicate': 'none', 'object': 'none'}], 'cellular_inclusion_relationships': [{'subject': 'none', 'predicate': 'none', 'object': 'none'}], 'pigmentation': ['none'], 'strain_relationships': [{'subject': 'H-2', 'predicate': 'type_strain_of', 'object': 'Geobacter hydrogenophilus'}, {'subject': '172', 'predicate': 'type_strain_of', 'object': 'Geobacter chapellei'}, {'subject': 'TACP-2', 'predicate': 'type_strain_of', 'object': 'Geobacter grbiciae'}, {'subject': 'TACP-5', 'predicate': 'strain_of', 'object': 'Geobacter grbiciae'}], 'article_type': 'novel_species'}
DEBUG:root:Grounding annotation object {'pmid': '11321104', 'study_taxa': ['Geobacter hydrogenophilus', 'Geobacter chapellei', 'Geobacter grbiciae'], 'strains': ['H-2', '172', 'TACP-2', 'TACP-5'], 'cell_shape': ['none'], 'cell_arrangements': ['none'], 'gram_staining': ['Gram-negative'], 'motility': ['non-motile'], 'spore_formation': ['none'], 'cell_wall_characteristics': ['none'], 'cellular_inclusions': ['none'], 'cell_shape_relationships': [{'subject': 'none', 'predicate': 'none', 'object': 'none'}], 'cell_arrangement_relationships': [{'subject': 'none', 'predicate': 'none', 'object': 'none'}], 'gram_staining_relationships': [{'subject': 'H-2', 'predicate': 'has_gram_staining', 'object': 'Gram-negative'}, {'subject': '172', 'predicate': 'has_gram_staining', 'object': 'Gram-negative'}, {'subject': 'TACP-2', 'predicate': 'has_gram_staining', 'object': 'Gram-negative'}, {'subject': 'TACP-5', 'predicate': 'has_gram_staining', 'object': 'Gram-negative'}], 'motility_relationships': [{'subject': 'H-2', 'predicate': 'has_motility', 'object': 'non-motile'}, {'subject': '172', 'predicate': 'has_motility', 'object': 'non-motile'}, {'subject': 'TACP-2', 'predicate': 'has_motility', 'object': 'non-motile'}, {'subject': 'TACP-5', 'predicate': 'has_motility', 'object': 'non-motile'}], 'spore_formation_relationships': [{'subject': 'none', 'predicate': 'none', 'object': 'none'}], 'cell_wall_relationships': [{'subject': 'none', 'predicate': 'none', 'object': 'none'}], 'cellular_inclusion_relationships': [{'subject': 'none', 'predicate': 'none', 'object': 'none'}], 'pigmentation': ['none'], 'strain_relationships': [{'subject': 'H-2', 'predicate': 'type_strain_of', 'object': 'Geobacter hydrogenophilus'}, {'subject': '172', 'predicate': 'type_strain_of', 'object': 'Geobacter chapellei'}, {'subject': 'TACP-2', 'predicate': 'type_strain_of', 'object': 'Geobacter grbiciae'}, {'subject': 'TACP-5', 'predicate': 'strain_of', 'object': 'Geobacter grbiciae'}], 'article_type': 'novel_species'}
DEBUG:root:FIELD: pmid SLOT: pmid
DEBUG:root:   VAL: 11321104
DEBUG:root:FIELD: study_taxa SLOT: study_taxa
DEBUG:root:   VAL: Geobacter hydrogenophilus
INFO:ontogpt.engines.knowledge_engine:GROUNDING Geobacter hydrogenophilus using Taxon
INFO:ontogpt.engines.knowledge_engine:Singularized Geobacter hydrogenophilus to geobacter hydrogenophilu
INFO:ontogpt.engines.knowledge_engine:GROUNDING geobacter hydrogenophilu using Taxon
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 47.13s ago] ('rdfs:label', 'geobacter hydrogenophilu')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 49.08s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'geobacter hydrogenophilu')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 51.82s ago] ('rdfs:label', 'Geobacter hydrogenophilus')
INFO:sqlalchemy.engine.Engine:SELECT rdfs_label_statement.value AS rdfs_label_statement_value 
FROM rdfs_label_statement 
WHERE rdfs_label_statement.subject = ?
INFO:sqlalchemy.engine.Engine:[cached since 31.82s ago] ('NCBITaxon:40983',)
INFO:ontogpt.engines.knowledge_engine:Grounding Geobacter hydrogenophilus to NCBITaxon:40983; next step is to normalize
INFO:ontogpt.engines.knowledge_engine:Normalized Geobacter hydrogenophilus with NCBITaxon:40983 to NCBITaxon:40983
DEBUG:root:   VAL: Geobacter chapellei
INFO:ontogpt.engines.knowledge_engine:GROUNDING Geobacter chapellei using Taxon
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 53.8s ago] ('rdfs:label', 'Geobacter chapellei')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 55.8s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'Geobacter chapellei')
INFO:sqlalchemy.engine.Engine:SELECT rdfs_label_statement.value AS rdfs_label_statement_value 
FROM rdfs_label_statement 
WHERE rdfs_label_statement.subject = ?
INFO:sqlalchemy.engine.Engine:[cached since 36.49s ago] ('NCBITaxon:44671',)
INFO:ontogpt.engines.knowledge_engine:Grounding Geobacter chapellei to NCBITaxon:44671; next step is to normalize
INFO:ontogpt.engines.knowledge_engine:Normalized Geobacter chapellei with NCBITaxon:44671 to NCBITaxon:44671
DEBUG:root:   VAL: Geobacter grbiciae
INFO:ontogpt.engines.knowledge_engine:GROUNDING Geobacter grbiciae using Taxon
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 58.48s ago] ('rdfs:label', 'Geobacter grbiciae')
INFO:sqlalchemy.engine.Engine:SELECT rdfs_label_statement.value AS rdfs_label_statement_value 
FROM rdfs_label_statement 
WHERE rdfs_label_statement.subject = ?
INFO:sqlalchemy.engine.Engine:[cached since 38.48s ago] ('NCBITaxon:155042',)
INFO:ontogpt.engines.knowledge_engine:Grounding Geobacter grbiciae to NCBITaxon:155042; next step is to normalize
INFO:ontogpt.engines.knowledge_engine:Normalized Geobacter grbiciae with NCBITaxon:155042 to NCBITaxon:155042
DEBUG:root:FIELD: strains SLOT: strains
DEBUG:root:   VAL: H-2
INFO:ontogpt.engines.knowledge_engine:GROUNDING H-2 using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize H-2 to Strain
DEBUG:root:   VAL: 172
INFO:ontogpt.engines.knowledge_engine:GROUNDING 172 using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize 172 to Strain
DEBUG:root:   VAL: TACP-2
INFO:ontogpt.engines.knowledge_engine:GROUNDING TACP-2 using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize TACP-2 to Strain
DEBUG:root:   VAL: TACP-5
INFO:ontogpt.engines.knowledge_engine:GROUNDING TACP-5 using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize TACP-5 to Strain
DEBUG:root:FIELD: cell_shape SLOT: cell_shape
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using CellShape
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 27.97s ago] ('rdfs:label', 'none')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 27.97s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'none')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to CellShape
DEBUG:root:FIELD: cell_arrangements SLOT: cell_arrangements
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using CellArrangement
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 27.97s ago] ('rdfs:label', 'none')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 27.97s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'none')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to CellArrangement
DEBUG:root:FIELD: gram_staining SLOT: gram_staining
DEBUG:root:   VAL: Gram-negative
INFO:ontogpt.engines.knowledge_engine:GROUNDING Gram-negative using GramStaining
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 27.97s ago] ('rdfs:label', 'Gram-negative')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 27.97s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'Gram-negative')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize Gram-negative to GramStaining
DEBUG:root:FIELD: motility SLOT: motility
DEBUG:root:   VAL: non-motile
INFO:ontogpt.engines.knowledge_engine:GROUNDING non-motile using Motility
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 27.97s ago] ('rdfs:label', 'non-motile')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 27.97s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'non-motile')
INFO:sqlalchemy.engine.Engine:SELECT rdfs_label_statement.value AS rdfs_label_statement_value 
FROM rdfs_label_statement 
WHERE rdfs_label_statement.subject = ?
INFO:sqlalchemy.engine.Engine:[generated in 0.00011s] ('<https://w3id.org/metpo/1000703>',)
INFO:ontogpt.engines.knowledge_engine:Grounding non-motile to <https://w3id.org/metpo/1000703>; next step is to normalize
INFO:ontogpt.engines.knowledge_engine:Normalized non-motile with <https://w3id.org/metpo/1000703> to <https://w3id.org/metpo/1000703>
DEBUG:root:FIELD: spore_formation SLOT: spore_formation
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using SporeFormation
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 27.98s ago] ('rdfs:label', 'none')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 27.98s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'none')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to SporeFormation
DEBUG:root:FIELD: cell_wall_characteristics SLOT: cell_wall_characteristics
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using CellWallCharacteristic
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 27.98s ago] ('rdfs:label', 'none')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 27.98s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'none')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to CellWallCharacteristic
DEBUG:root:FIELD: cellular_inclusions SLOT: cellular_inclusions
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using CellularInclusion
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 27.98s ago] ('rdfs:label', 'none')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 27.98s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'none')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to CellularInclusion
DEBUG:root:FIELD: cell_shape_relationships SLOT: cell_shape_relationships
DEBUG:root:   VAL: {'subject': 'none', 'predicate': 'none', 'object': 'none'}
DEBUG:root:Grounding annotation object {'subject': 'none', 'predicate': 'none', 'object': 'none'}
DEBUG:root:FIELD: subject SLOT: subject
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to Strain
DEBUG:root:FIELD: predicate SLOT: predicate
DEBUG:root:   VAL: none
INFO:root:Looking for none in MorphologyType
INFO:root:Cannot find enum value for none in MorphologyType
DEBUG:root:FIELD: object SLOT: object
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using CellShape
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 27.98s ago] ('rdfs:label', 'none')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 27.98s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'none')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to CellShape
DEBUG:root:Creating object from dict {'subject': 'AUTO:none', 'predicate': None, 'object': 'AUTO:none'}
INFO:root:{'subject': 'AUTO:none', 'predicate': None, 'object': 'AUTO:none'}
DEBUG:root:FIELD: cell_arrangement_relationships SLOT: cell_arrangement_relationships
DEBUG:root:   VAL: {'subject': 'none', 'predicate': 'none', 'object': 'none'}
DEBUG:root:Grounding annotation object {'subject': 'none', 'predicate': 'none', 'object': 'none'}
DEBUG:root:FIELD: subject SLOT: subject
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to Strain
DEBUG:root:FIELD: predicate SLOT: predicate
DEBUG:root:   VAL: none
INFO:root:Looking for none in MorphologyType
INFO:root:Cannot find enum value for none in MorphologyType
DEBUG:root:FIELD: object SLOT: object
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using CellArrangement
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 27.99s ago] ('rdfs:label', 'none')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 27.99s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'none')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to CellArrangement
DEBUG:root:Creating object from dict {'subject': 'AUTO:none', 'predicate': None, 'object': 'AUTO:none'}
INFO:root:{'subject': 'AUTO:none', 'predicate': None, 'object': 'AUTO:none'}
DEBUG:root:FIELD: gram_staining_relationships SLOT: gram_staining_relationships
DEBUG:root:   VAL: {'subject': 'H-2', 'predicate': 'has_gram_staining', 'object': 'Gram-negative'}
DEBUG:root:Grounding annotation object {'subject': 'H-2', 'predicate': 'has_gram_staining', 'object': 'Gram-negative'}
DEBUG:root:FIELD: subject SLOT: subject
DEBUG:root:   VAL: H-2
INFO:ontogpt.engines.knowledge_engine:GROUNDING H-2 using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize H-2 to Strain
DEBUG:root:FIELD: predicate SLOT: predicate
DEBUG:root:   VAL: has_gram_staining
INFO:root:Looking for has_gram_staining in MorphologyType
DEBUG:root:FIELD: object SLOT: object
DEBUG:root:   VAL: Gram-negative
INFO:ontogpt.engines.knowledge_engine:GROUNDING Gram-negative using GramStaining
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 27.99s ago] ('rdfs:label', 'Gram-negative')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 27.99s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'Gram-negative')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize Gram-negative to GramStaining
DEBUG:root:Creating object from dict {'subject': 'AUTO:H-2', 'predicate': 'has_gram_staining', 'object': 'AUTO:Gram-negative'}
INFO:root:{'subject': 'AUTO:H-2', 'predicate': 'has_gram_staining', 'object': 'AUTO:Gram-negative'}
DEBUG:root:   VAL: {'subject': '172', 'predicate': 'has_gram_staining', 'object': 'Gram-negative'}
DEBUG:root:Grounding annotation object {'subject': '172', 'predicate': 'has_gram_staining', 'object': 'Gram-negative'}
DEBUG:root:FIELD: subject SLOT: subject
DEBUG:root:   VAL: 172
INFO:ontogpt.engines.knowledge_engine:GROUNDING 172 using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize 172 to Strain
DEBUG:root:FIELD: predicate SLOT: predicate
DEBUG:root:   VAL: has_gram_staining
INFO:root:Looking for has_gram_staining in MorphologyType
DEBUG:root:FIELD: object SLOT: object
DEBUG:root:   VAL: Gram-negative
INFO:ontogpt.engines.knowledge_engine:GROUNDING Gram-negative using GramStaining
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 27.99s ago] ('rdfs:label', 'Gram-negative')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 27.99s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'Gram-negative')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize Gram-negative to GramStaining
DEBUG:root:Creating object from dict {'subject': 'AUTO:172', 'predicate': 'has_gram_staining', 'object': 'AUTO:Gram-negative'}
INFO:root:{'subject': 'AUTO:172', 'predicate': 'has_gram_staining', 'object': 'AUTO:Gram-negative'}
DEBUG:root:   VAL: {'subject': 'TACP-2', 'predicate': 'has_gram_staining', 'object': 'Gram-negative'}
DEBUG:root:Grounding annotation object {'subject': 'TACP-2', 'predicate': 'has_gram_staining', 'object': 'Gram-negative'}
DEBUG:root:FIELD: subject SLOT: subject
DEBUG:root:   VAL: TACP-2
INFO:ontogpt.engines.knowledge_engine:GROUNDING TACP-2 using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize TACP-2 to Strain
DEBUG:root:FIELD: predicate SLOT: predicate
DEBUG:root:   VAL: has_gram_staining
INFO:root:Looking for has_gram_staining in MorphologyType
DEBUG:root:FIELD: object SLOT: object
DEBUG:root:   VAL: Gram-negative
INFO:ontogpt.engines.knowledge_engine:GROUNDING Gram-negative using GramStaining
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 27.99s ago] ('rdfs:label', 'Gram-negative')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 27.99s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'Gram-negative')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize Gram-negative to GramStaining
DEBUG:root:Creating object from dict {'subject': 'AUTO:TACP-2', 'predicate': 'has_gram_staining', 'object': 'AUTO:Gram-negative'}
INFO:root:{'subject': 'AUTO:TACP-2', 'predicate': 'has_gram_staining', 'object': 'AUTO:Gram-negative'}
DEBUG:root:   VAL: {'subject': 'TACP-5', 'predicate': 'has_gram_staining', 'object': 'Gram-negative'}
DEBUG:root:Grounding annotation object {'subject': 'TACP-5', 'predicate': 'has_gram_staining', 'object': 'Gram-negative'}
DEBUG:root:FIELD: subject SLOT: subject
DEBUG:root:   VAL: TACP-5
INFO:ontogpt.engines.knowledge_engine:GROUNDING TACP-5 using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize TACP-5 to Strain
DEBUG:root:FIELD: predicate SLOT: predicate
DEBUG:root:   VAL: has_gram_staining
INFO:root:Looking for has_gram_staining in MorphologyType
DEBUG:root:FIELD: object SLOT: object
DEBUG:root:   VAL: Gram-negative
INFO:ontogpt.engines.knowledge_engine:GROUNDING Gram-negative using GramStaining
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 28s ago] ('rdfs:label', 'Gram-negative')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 28s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'Gram-negative')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize Gram-negative to GramStaining
DEBUG:root:Creating object from dict {'subject': 'AUTO:TACP-5', 'predicate': 'has_gram_staining', 'object': 'AUTO:Gram-negative'}
INFO:root:{'subject': 'AUTO:TACP-5', 'predicate': 'has_gram_staining', 'object': 'AUTO:Gram-negative'}
DEBUG:root:FIELD: motility_relationships SLOT: motility_relationships
DEBUG:root:   VAL: {'subject': 'H-2', 'predicate': 'has_motility', 'object': 'non-motile'}
DEBUG:root:Grounding annotation object {'subject': 'H-2', 'predicate': 'has_motility', 'object': 'non-motile'}
DEBUG:root:FIELD: subject SLOT: subject
DEBUG:root:   VAL: H-2
INFO:ontogpt.engines.knowledge_engine:GROUNDING H-2 using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize H-2 to Strain
DEBUG:root:FIELD: predicate SLOT: predicate
DEBUG:root:   VAL: has_motility
INFO:root:Looking for has_motility in MorphologyType
DEBUG:root:FIELD: object SLOT: object
DEBUG:root:   VAL: non-motile
INFO:ontogpt.engines.knowledge_engine:GROUNDING non-motile using Motility
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 28s ago] ('rdfs:label', 'non-motile')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 28s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'non-motile')
INFO:sqlalchemy.engine.Engine:SELECT rdfs_label_statement.value AS rdfs_label_statement_value 
FROM rdfs_label_statement 
WHERE rdfs_label_statement.subject = ?
INFO:sqlalchemy.engine.Engine:[cached since 0.02595s ago] ('<https://w3id.org/metpo/1000703>',)
INFO:ontogpt.engines.knowledge_engine:Grounding non-motile to <https://w3id.org/metpo/1000703>; next step is to normalize
INFO:ontogpt.engines.knowledge_engine:Normalized non-motile with <https://w3id.org/metpo/1000703> to <https://w3id.org/metpo/1000703>
DEBUG:root:Creating object from dict {'subject': 'AUTO:H-2', 'predicate': 'has_motility', 'object': '<https://w3id.org/metpo/1000703>'}
INFO:root:{'subject': 'AUTO:H-2', 'predicate': 'has_motility', 'object': '<https://w3id.org/metpo/1000703>'}
DEBUG:root:   VAL: {'subject': '172', 'predicate': 'has_motility', 'object': 'non-motile'}
DEBUG:root:Grounding annotation object {'subject': '172', 'predicate': 'has_motility', 'object': 'non-motile'}
DEBUG:root:FIELD: subject SLOT: subject
DEBUG:root:   VAL: 172
INFO:ontogpt.engines.knowledge_engine:GROUNDING 172 using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize 172 to Strain
DEBUG:root:FIELD: predicate SLOT: predicate
DEBUG:root:   VAL: has_motility
INFO:root:Looking for has_motility in MorphologyType
DEBUG:root:FIELD: object SLOT: object
DEBUG:root:   VAL: non-motile
INFO:ontogpt.engines.knowledge_engine:GROUNDING non-motile using Motility
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 28s ago] ('rdfs:label', 'non-motile')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 28s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'non-motile')
INFO:sqlalchemy.engine.Engine:SELECT rdfs_label_statement.value AS rdfs_label_statement_value 
FROM rdfs_label_statement 
WHERE rdfs_label_statement.subject = ?
INFO:sqlalchemy.engine.Engine:[cached since 0.02865s ago] ('<https://w3id.org/metpo/1000703>',)
INFO:ontogpt.engines.knowledge_engine:Grounding non-motile to <https://w3id.org/metpo/1000703>; next step is to normalize
INFO:ontogpt.engines.knowledge_engine:Normalized non-motile with <https://w3id.org/metpo/1000703> to <https://w3id.org/metpo/1000703>
DEBUG:root:Creating object from dict {'subject': 'AUTO:172', 'predicate': 'has_motility', 'object': '<https://w3id.org/metpo/1000703>'}
INFO:root:{'subject': 'AUTO:172', 'predicate': 'has_motility', 'object': '<https://w3id.org/metpo/1000703>'}
DEBUG:root:   VAL: {'subject': 'TACP-2', 'predicate': 'has_motility', 'object': 'non-motile'}
DEBUG:root:Grounding annotation object {'subject': 'TACP-2', 'predicate': 'has_motility', 'object': 'non-motile'}
DEBUG:root:FIELD: subject SLOT: subject
DEBUG:root:   VAL: TACP-2
INFO:ontogpt.engines.knowledge_engine:GROUNDING TACP-2 using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize TACP-2 to Strain
DEBUG:root:FIELD: predicate SLOT: predicate
DEBUG:root:   VAL: has_motility
INFO:root:Looking for has_motility in MorphologyType
DEBUG:root:FIELD: object SLOT: object
DEBUG:root:   VAL: non-motile
INFO:ontogpt.engines.knowledge_engine:GROUNDING non-motile using Motility
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 28s ago] ('rdfs:label', 'non-motile')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 28s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'non-motile')
INFO:sqlalchemy.engine.Engine:SELECT rdfs_label_statement.value AS rdfs_label_statement_value 
FROM rdfs_label_statement 
WHERE rdfs_label_statement.subject = ?
INFO:sqlalchemy.engine.Engine:[cached since 0.03149s ago] ('<https://w3id.org/metpo/1000703>',)
INFO:ontogpt.engines.knowledge_engine:Grounding non-motile to <https://w3id.org/metpo/1000703>; next step is to normalize
INFO:ontogpt.engines.knowledge_engine:Normalized non-motile with <https://w3id.org/metpo/1000703> to <https://w3id.org/metpo/1000703>
DEBUG:root:Creating object from dict {'subject': 'AUTO:TACP-2', 'predicate': 'has_motility', 'object': '<https://w3id.org/metpo/1000703>'}
INFO:root:{'subject': 'AUTO:TACP-2', 'predicate': 'has_motility', 'object': '<https://w3id.org/metpo/1000703>'}
DEBUG:root:   VAL: {'subject': 'TACP-5', 'predicate': 'has_motility', 'object': 'non-motile'}
DEBUG:root:Grounding annotation object {'subject': 'TACP-5', 'predicate': 'has_motility', 'object': 'non-motile'}
DEBUG:root:FIELD: subject SLOT: subject
DEBUG:root:   VAL: TACP-5
INFO:ontogpt.engines.knowledge_engine:GROUNDING TACP-5 using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize TACP-5 to Strain
DEBUG:root:FIELD: predicate SLOT: predicate
DEBUG:root:   VAL: has_motility
INFO:root:Looking for has_motility in MorphologyType
DEBUG:root:FIELD: object SLOT: object
DEBUG:root:   VAL: non-motile
INFO:ontogpt.engines.knowledge_engine:GROUNDING non-motile using Motility
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 28.01s ago] ('rdfs:label', 'non-motile')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 28.01s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'non-motile')
INFO:sqlalchemy.engine.Engine:SELECT rdfs_label_statement.value AS rdfs_label_statement_value 
FROM rdfs_label_statement 
WHERE rdfs_label_statement.subject = ?
INFO:sqlalchemy.engine.Engine:[cached since 0.03442s ago] ('<https://w3id.org/metpo/1000703>',)
INFO:ontogpt.engines.knowledge_engine:Grounding non-motile to <https://w3id.org/metpo/1000703>; next step is to normalize
INFO:ontogpt.engines.knowledge_engine:Normalized non-motile with <https://w3id.org/metpo/1000703> to <https://w3id.org/metpo/1000703>
DEBUG:root:Creating object from dict {'subject': 'AUTO:TACP-5', 'predicate': 'has_motility', 'object': '<https://w3id.org/metpo/1000703>'}
INFO:root:{'subject': 'AUTO:TACP-5', 'predicate': 'has_motility', 'object': '<https://w3id.org/metpo/1000703>'}
DEBUG:root:FIELD: spore_formation_relationships SLOT: spore_formation_relationships
DEBUG:root:   VAL: {'subject': 'none', 'predicate': 'none', 'object': 'none'}
DEBUG:root:Grounding annotation object {'subject': 'none', 'predicate': 'none', 'object': 'none'}
DEBUG:root:FIELD: subject SLOT: subject
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to Strain
DEBUG:root:FIELD: predicate SLOT: predicate
DEBUG:root:   VAL: none
INFO:root:Looking for none in MorphologyType
INFO:root:Cannot find enum value for none in MorphologyType
DEBUG:root:FIELD: object SLOT: object
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using SporeFormation
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 28.01s ago] ('rdfs:label', 'none')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 28.01s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'none')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to SporeFormation
DEBUG:root:Creating object from dict {'subject': 'AUTO:none', 'predicate': None, 'object': 'AUTO:none'}
INFO:root:{'subject': 'AUTO:none', 'predicate': None, 'object': 'AUTO:none'}
DEBUG:root:FIELD: cell_wall_relationships SLOT: cell_wall_relationships
DEBUG:root:   VAL: {'subject': 'none', 'predicate': 'none', 'object': 'none'}
DEBUG:root:Grounding annotation object {'subject': 'none', 'predicate': 'none', 'object': 'none'}
DEBUG:root:FIELD: subject SLOT: subject
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to Strain
DEBUG:root:FIELD: predicate SLOT: predicate
DEBUG:root:   VAL: none
INFO:root:Looking for none in MorphologyType
INFO:root:Cannot find enum value for none in MorphologyType
DEBUG:root:FIELD: object SLOT: object
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using CellWallCharacteristic
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 28.01s ago] ('rdfs:label', 'none')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 28.01s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'none')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to CellWallCharacteristic
DEBUG:root:Creating object from dict {'subject': 'AUTO:none', 'predicate': None, 'object': 'AUTO:none'}
INFO:root:{'subject': 'AUTO:none', 'predicate': None, 'object': 'AUTO:none'}
DEBUG:root:FIELD: cellular_inclusion_relationships SLOT: cellular_inclusion_relationships
DEBUG:root:   VAL: {'subject': 'none', 'predicate': 'none', 'object': 'none'}
DEBUG:root:Grounding annotation object {'subject': 'none', 'predicate': 'none', 'object': 'none'}
DEBUG:root:FIELD: subject SLOT: subject
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to Strain
DEBUG:root:FIELD: predicate SLOT: predicate
DEBUG:root:   VAL: none
INFO:root:Looking for none in MorphologyType
INFO:root:Cannot find enum value for none in MorphologyType
DEBUG:root:FIELD: object SLOT: object
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using CellularInclusion
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 28.01s ago] ('rdfs:label', 'none')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 28.02s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'none')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to CellularInclusion
DEBUG:root:Creating object from dict {'subject': 'AUTO:none', 'predicate': None, 'object': 'AUTO:none'}
INFO:root:{'subject': 'AUTO:none', 'predicate': None, 'object': 'AUTO:none'}
DEBUG:root:FIELD: pigmentation SLOT: pigmentation
DEBUG:root:   VAL: none
INFO:ontogpt.engines.knowledge_engine:GROUNDING none using Pigmentation
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 28.02s ago] ('rdfs:label', 'none')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 28.02s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'none')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize none to Pigmentation
DEBUG:root:FIELD: strain_relationships SLOT: strain_relationships
DEBUG:root:   VAL: {'subject': 'H-2', 'predicate': 'type_strain_of', 'object': 'Geobacter hydrogenophilus'}
DEBUG:root:Grounding annotation object {'subject': 'H-2', 'predicate': 'type_strain_of', 'object': 'Geobacter hydrogenophilus'}
DEBUG:root:FIELD: subject SLOT: subject
DEBUG:root:   VAL: H-2
INFO:ontogpt.engines.knowledge_engine:GROUNDING H-2 using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize H-2 to Strain
DEBUG:root:FIELD: predicate SLOT: predicate
DEBUG:root:   VAL: type_strain_of
INFO:root:Looking for type_strain_of in StrainRelationshipType
DEBUG:root:FIELD: object SLOT: object
DEBUG:root:   VAL: Geobacter hydrogenophilus
INFO:ontogpt.engines.knowledge_engine:GROUNDING Geobacter hydrogenophilus using Taxon
INFO:ontogpt.engines.knowledge_engine:Singularized Geobacter hydrogenophilus to geobacter hydrogenophilu
INFO:ontogpt.engines.knowledge_engine:GROUNDING geobacter hydrogenophilu using Taxon
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 60.52s ago] ('rdfs:label', 'geobacter hydrogenophilu')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 62.51s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'geobacter hydrogenophilu')
INFO:ontogpt.engines.knowledge_engine:Skipping <class 'oaklib.implementations.sqldb.sql_implementation.SqlImplementation'> as it does not support partial matches
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 65.16s ago] ('rdfs:label', 'Geobacter hydrogenophilus')
INFO:sqlalchemy.engine.Engine:SELECT rdfs_label_statement.value AS rdfs_label_statement_value 
FROM rdfs_label_statement 
WHERE rdfs_label_statement.subject = ?
INFO:sqlalchemy.engine.Engine:[cached since 45.28s ago] ('NCBITaxon:40983',)
INFO:ontogpt.engines.knowledge_engine:Grounding Geobacter hydrogenophilus to NCBITaxon:40983; next step is to normalize
INFO:ontogpt.engines.knowledge_engine:Normalized Geobacter hydrogenophilus with NCBITaxon:40983 to NCBITaxon:40983
DEBUG:root:Creating object from dict {'subject': 'AUTO:H-2', 'predicate': 'type_strain_of', 'object': 'NCBITaxon:40983'}
INFO:root:{'subject': 'AUTO:H-2', 'predicate': 'type_strain_of', 'object': 'NCBITaxon:40983'}
DEBUG:root:   VAL: {'subject': '172', 'predicate': 'type_strain_of', 'object': 'Geobacter chapellei'}
DEBUG:root:Grounding annotation object {'subject': '172', 'predicate': 'type_strain_of', 'object': 'Geobacter chapellei'}
DEBUG:root:FIELD: subject SLOT: subject
DEBUG:root:   VAL: 172
INFO:ontogpt.engines.knowledge_engine:GROUNDING 172 using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize 172 to Strain
DEBUG:root:FIELD: predicate SLOT: predicate
DEBUG:root:   VAL: type_strain_of
INFO:root:Looking for type_strain_of in StrainRelationshipType
DEBUG:root:FIELD: object SLOT: object
DEBUG:root:   VAL: Geobacter chapellei
INFO:ontogpt.engines.knowledge_engine:GROUNDING Geobacter chapellei using Taxon
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 67.27s ago] ('rdfs:label', 'Geobacter chapellei')
DEBUG:root:Config, including synonyms: SearchConfiguration(search_terms=[], syntax=SearchTermSyntax(text='SQL', description='The search term is SQL LIKE syntax, with percent symbols acting as wildcards'), properties=[SearchProperty(text='ALIAS', description='An alias or synonym of the entity', meaning='http://www.w3.org/2004/02/skos/core#altLabel')], limit=None, cursor=None, is_partial=None, is_complete=None, include_obsoletes_in_results=None, is_fuzzy=None, categories=[], force_case_insensitive=True)
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?, ?, ?, ?, ?, ?, ?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 69.17s ago] ('rdfs:label', 'oio:hasRelatedSynonym', 'oio:hasNarrowSynonym', 'oio:hasExactSynonym', 'oio:hasBroadSynonym', 'skos:altLabel', 'IAO:0000118', 'Geobacter chapellei')
INFO:sqlalchemy.engine.Engine:SELECT rdfs_label_statement.value AS rdfs_label_statement_value 
FROM rdfs_label_statement 
WHERE rdfs_label_statement.subject = ?
INFO:sqlalchemy.engine.Engine:[cached since 49.85s ago] ('NCBITaxon:44671',)
INFO:ontogpt.engines.knowledge_engine:Grounding Geobacter chapellei to NCBITaxon:44671; next step is to normalize
INFO:ontogpt.engines.knowledge_engine:Normalized Geobacter chapellei with NCBITaxon:44671 to NCBITaxon:44671
DEBUG:root:Creating object from dict {'subject': 'AUTO:172', 'predicate': 'type_strain_of', 'object': 'NCBITaxon:44671'}
INFO:root:{'subject': 'AUTO:172', 'predicate': 'type_strain_of', 'object': 'NCBITaxon:44671'}
DEBUG:root:   VAL: {'subject': 'TACP-2', 'predicate': 'type_strain_of', 'object': 'Geobacter grbiciae'}
DEBUG:root:Grounding annotation object {'subject': 'TACP-2', 'predicate': 'type_strain_of', 'object': 'Geobacter grbiciae'}
DEBUG:root:FIELD: subject SLOT: subject
DEBUG:root:   VAL: TACP-2
INFO:ontogpt.engines.knowledge_engine:GROUNDING TACP-2 using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize TACP-2 to Strain
DEBUG:root:FIELD: predicate SLOT: predicate
DEBUG:root:   VAL: type_strain_of
INFO:root:Looking for type_strain_of in StrainRelationshipType
DEBUG:root:FIELD: object SLOT: object
DEBUG:root:   VAL: Geobacter grbiciae
INFO:ontogpt.engines.knowledge_engine:GROUNDING Geobacter grbiciae using Taxon
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 71.84s ago] ('rdfs:label', 'Geobacter grbiciae')
INFO:sqlalchemy.engine.Engine:SELECT rdfs_label_statement.value AS rdfs_label_statement_value 
FROM rdfs_label_statement 
WHERE rdfs_label_statement.subject = ?
INFO:sqlalchemy.engine.Engine:[cached since 51.81s ago] ('NCBITaxon:155042',)
INFO:ontogpt.engines.knowledge_engine:Grounding Geobacter grbiciae to NCBITaxon:155042; next step is to normalize
INFO:ontogpt.engines.knowledge_engine:Normalized Geobacter grbiciae with NCBITaxon:155042 to NCBITaxon:155042
DEBUG:root:Creating object from dict {'subject': 'AUTO:TACP-2', 'predicate': 'type_strain_of', 'object': 'NCBITaxon:155042'}
INFO:root:{'subject': 'AUTO:TACP-2', 'predicate': 'type_strain_of', 'object': 'NCBITaxon:155042'}
DEBUG:root:   VAL: {'subject': 'TACP-5', 'predicate': 'strain_of', 'object': 'Geobacter grbiciae'}
DEBUG:root:Grounding annotation object {'subject': 'TACP-5', 'predicate': 'strain_of', 'object': 'Geobacter grbiciae'}
DEBUG:root:FIELD: subject SLOT: subject
DEBUG:root:   VAL: TACP-5
INFO:ontogpt.engines.knowledge_engine:GROUNDING TACP-5 using Strain
INFO:ontogpt.engines.knowledge_engine:Could not ground and normalize TACP-5 to Strain
DEBUG:root:FIELD: predicate SLOT: predicate
DEBUG:root:   VAL: strain_of
INFO:root:Looking for strain_of in StrainRelationshipType
DEBUG:root:FIELD: object SLOT: object
DEBUG:root:   VAL: Geobacter grbiciae
INFO:ontogpt.engines.knowledge_engine:GROUNDING Geobacter grbiciae using Taxon
INFO:root:No token exclusion list provided. Proceeding ...
INFO:sqlalchemy.engine.Engine:SELECT DISTINCT statements.subject AS statements_subject 
FROM statements 
WHERE statements.predicate IN (?) AND statements.value LIKE ?
INFO:sqlalchemy.engine.Engine:[cached since 73.79s ago] ('rdfs:label', 'Geobacter grbiciae')
INFO:sqlalchemy.engine.Engine:SELECT rdfs_label_statement.value AS rdfs_label_statement_value 
FROM rdfs_label_statement 
WHERE rdfs_label_statement.subject = ?
INFO:sqlalchemy.engine.Engine:[cached since 53.74s ago] ('NCBITaxon:155042',)
INFO:ontogpt.engines.knowledge_engine:Grounding Geobacter grbiciae to NCBITaxon:155042; next step is to normalize
INFO:ontogpt.engines.knowledge_engine:Normalized Geobacter grbiciae with NCBITaxon:155042 to NCBITaxon:155042
DEBUG:root:Creating object from dict {'subject': 'AUTO:TACP-5', 'predicate': 'strain_of', 'object': 'NCBITaxon:155042'}
INFO:root:{'subject': 'AUTO:TACP-5', 'predicate': 'strain_of', 'object': 'NCBITaxon:155042'}
DEBUG:root:FIELD: article_type SLOT: article_type
DEBUG:root:   VAL: novel_species
INFO:root:Looking for novel_species in ArticleType
DEBUG:root:Creating object from dict {'pmid': '11321104', 'study_taxa': ['NCBITaxon:40983', 'NCBITaxon:44671', 'NCBITaxon:155042'], 'strains': ['AUTO:H-2', 'AUTO:172', 'AUTO:TACP-2', 'AUTO:TACP-5'], 'cell_shape': ['AUTO:none'], 'cell_arrangements': ['AUTO:none'], 'gram_staining': ['AUTO:Gram-negative'], 'motility': ['<https://w3id.org/metpo/1000703>'], 'spore_formation': ['AUTO:none'], 'cell_wall_characteristics': ['AUTO:none'], 'cellular_inclusions': ['AUTO:none'], 'cell_shape_relationships': [CellShapeRelationship(subject='AUTO:none', predicate=None, object='AUTO:none')], 'cell_arrangement_relationships': [CellArrangementRelationship(subject='AUTO:none', predicate=None, object='AUTO:none')], 'gram_staining_relationships': [GramStainingRelationship(subject='AUTO:H-2', predicate='has_gram_staining', object='AUTO:Gram-negative'), GramStainingRelationship(subject='AUTO:172', predicate='has_gram_staining', object='AUTO:Gram-negative'), GramStainingRelationship(subject='AUTO:TACP-2', predicate='has_gram_staining', object='AUTO:Gram-negative'), GramStainingRelationship(subject='AUTO:TACP-5', predicate='has_gram_staining', object='AUTO:Gram-negative')], 'motility_relationships': [MotilityRelationship(subject='AUTO:H-2', predicate='has_motility', object='<https://w3id.org/metpo/1000703>'), MotilityRelationship(subject='AUTO:172', predicate='has_motility', object='<https://w3id.org/metpo/1000703>'), MotilityRelationship(subject='AUTO:TACP-2', predicate='has_motility', object='<https://w3id.org/metpo/1000703>'), MotilityRelationship(subject='AUTO:TACP-5', predicate='has_motility', object='<https://w3id.org/metpo/1000703>')], 'spore_formation_relationships': [SporeFormationRelationship(subject='AUTO:none', predicate=None, object='AUTO:none')], 'cell_wall_relationships': [CellWallRelationship(subject='AUTO:none', predicate=None, object='AUTO:none')], 'cellular_inclusion_relationships': [CellularInclusionRelationship(subject='AUTO:none', predicate=None, object='AUTO:none')], 'pigmentation': ['AUTO:none'], 'strain_relationships': [StrainRelationship(subject='AUTO:H-2', predicate='type_strain_of', object='NCBITaxon:40983'), StrainRelationship(subject='AUTO:172', predicate='type_strain_of', object='NCBITaxon:44671'), StrainRelationship(subject='AUTO:TACP-2', predicate='type_strain_of', object='NCBITaxon:155042'), StrainRelationship(subject='AUTO:TACP-5', predicate='strain_of', object='NCBITaxon:155042')], 'article_type': 'novel_species'}
INFO:root:{'pmid': '11321104', 'study_taxa': ['NCBITaxon:40983', 'NCBITaxon:44671', 'NCBITaxon:155042'], 'strains': ['AUTO:H-2', 'AUTO:172', 'AUTO:TACP-2', 'AUTO:TACP-5'], 'cell_shape': ['AUTO:none'], 'cell_arrangements': ['AUTO:none'], 'gram_staining': ['AUTO:Gram-negative'], 'motility': ['<https://w3id.org/metpo/1000703>'], 'spore_formation': ['AUTO:none'], 'cell_wall_characteristics': ['AUTO:none'], 'cellular_inclusions': ['AUTO:none'], 'cell_shape_relationships': [CellShapeRelationship(subject='AUTO:none', predicate=None, object='AUTO:none')], 'cell_arrangement_relationships': [CellArrangementRelationship(subject='AUTO:none', predicate=None, object='AUTO:none')], 'gram_staining_relationships': [GramStainingRelationship(subject='AUTO:H-2', predicate='has_gram_staining', object='AUTO:Gram-negative'), GramStainingRelationship(subject='AUTO:172', predicate='has_gram_staining', object='AUTO:Gram-negative'), GramStainingRelationship(subject='AUTO:TACP-2', predicate='has_gram_staining', object='AUTO:Gram-negative'), GramStainingRelationship(subject='AUTO:TACP-5', predicate='has_gram_staining', object='AUTO:Gram-negative')], 'motility_relationships': [MotilityRelationship(subject='AUTO:H-2', predicate='has_motility', object='<https://w3id.org/metpo/1000703>'), MotilityRelationship(subject='AUTO:172', predicate='has_motility', object='<https://w3id.org/metpo/1000703>'), MotilityRelationship(subject='AUTO:TACP-2', predicate='has_motility', object='<https://w3id.org/metpo/1000703>'), MotilityRelationship(subject='AUTO:TACP-5', predicate='has_motility', object='<https://w3id.org/metpo/1000703>')], 'spore_formation_relationships': [SporeFormationRelationship(subject='AUTO:none', predicate=None, object='AUTO:none')], 'cell_wall_relationships': [CellWallRelationship(subject='AUTO:none', predicate=None, object='AUTO:none')], 'cellular_inclusion_relationships': [CellularInclusionRelationship(subject='AUTO:none', predicate=None, object='AUTO:none')], 'pigmentation': ['AUTO:none'], 'strain_relationships': [StrainRelationship(subject='AUTO:H-2', predicate='type_strain_of', object='NCBITaxon:40983'), StrainRelationship(subject='AUTO:172', predicate='type_strain_of', object='NCBITaxon:44671'), StrainRelationship(subject='AUTO:TACP-2', predicate='type_strain_of', object='NCBITaxon:155042'), StrainRelationship(subject='AUTO:TACP-5', predicate='strain_of', object='NCBITaxon:155042')], 'article_type': 'novel_species'}
INFO:root:Output format: yaml
