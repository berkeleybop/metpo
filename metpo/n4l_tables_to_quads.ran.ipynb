{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T23:21:55.446575Z",
     "start_time": "2025-05-20T23:21:55.056890Z"
    },
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-21T01:35:23.136863Z",
     "iopub.status.busy": "2025-05-21T01:35:23.136641Z",
     "iopub.status.idle": "2025-05-21T01:35:23.466155Z",
     "shell.execute_reply": "2025-05-21T01:35:23.465472Z"
    },
    "papermill": {
     "duration": 0.345977,
     "end_time": "2025-05-21T01:35:23.467285",
     "exception": false,
     "start_time": "2025-05-21T01:35:23.121308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from urllib.parse import quote\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import pandas as pd\n",
    "from rdflib import Dataset, URIRef, Literal\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46335522b31a73a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T23:21:55.647792Z",
     "start_time": "2025-05-20T23:21:55.644095Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-21T01:35:23.482046Z",
     "iopub.status.busy": "2025-05-21T01:35:23.481698Z",
     "iopub.status.idle": "2025-05-21T01:35:23.485360Z",
     "shell.execute_reply": "2025-05-21T01:35:23.484892Z"
    },
    "papermill": {
     "duration": 0.01406,
     "end_time": "2025-05-21T01:35:23.486366",
     "exception": false,
     "start_time": "2025-05-21T01:35:23.472306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Handle both interactive and CLI (e.g., papermill) execution\n",
    "notebook_path = Path(__file__).parent if \"__file__\" in globals() else Path.cwd()\n",
    "\n",
    "# Project root is the parent of `metpo/`, even though the notebook lives in `metpo/`\n",
    "project_root = notebook_path if (notebook_path / \"assets\").is_dir() else notebook_path.parent\n",
    "assets_dir = project_root / \"assets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "971174b17f8caa04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T23:22:00.227711Z",
     "start_time": "2025-05-20T23:22:00.224848Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-21T01:35:23.496605Z",
     "iopub.status.busy": "2025-05-21T01:35:23.496412Z",
     "iopub.status.idle": "2025-05-21T01:35:23.499269Z",
     "shell.execute_reply": "2025-05-21T01:35:23.498806Z"
    },
    "papermill": {
     "duration": 0.009018,
     "end_time": "2025-05-21T01:35:23.500183",
     "exception": false,
     "start_time": "2025-05-21T01:35:23.491165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n4l_data_directory = assets_dir / \"N4L_phenotypic_ontology_2016\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4571d839c55f032",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T23:22:00.899458Z",
     "start_time": "2025-05-20T23:22:00.896876Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-21T01:35:23.510299Z",
     "iopub.status.busy": "2025-05-21T01:35:23.510114Z",
     "iopub.status.idle": "2025-05-21T01:35:23.513015Z",
     "shell.execute_reply": "2025-05-21T01:35:23.512551Z"
    },
    "papermill": {
     "duration": 0.009021,
     "end_time": "2025-05-21T01:35:23.513914",
     "exception": false,
     "start_time": "2025-05-21T01:35:23.504893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xlsx_config_path = assets_dir / \"n4l-xlsx-parsing-config.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "518a6ce01ab0ad23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T23:22:01.520161Z",
     "start_time": "2025-05-20T23:22:01.515386Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-21T01:35:23.524217Z",
     "iopub.status.busy": "2025-05-21T01:35:23.523898Z",
     "iopub.status.idle": "2025-05-21T01:35:23.526550Z",
     "shell.execute_reply": "2025-05-21T01:35:23.526098Z"
    },
    "papermill": {
     "duration": 0.008867,
     "end_time": "2025-05-21T01:35:23.527451",
     "exception": false,
     "start_time": "2025-05-21T01:35:23.518584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicate_mapping_normalization_file = assets_dir / \"n4l_predicate_mapping_normalization.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b27fad2dadbd61ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T23:22:02.208368Z",
     "start_time": "2025-05-20T23:22:02.205649Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-21T01:35:23.537576Z",
     "iopub.status.busy": "2025-05-21T01:35:23.537239Z",
     "iopub.status.idle": "2025-05-21T01:35:23.539884Z",
     "shell.execute_reply": "2025-05-21T01:35:23.539431Z"
    },
    "papermill": {
     "duration": 0.008725,
     "end_time": "2025-05-21T01:35:23.540771",
     "exception": false,
     "start_time": "2025-05-21T01:35:23.532046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nq_out = project_root / \"local\" / \"n4l-tables.nq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "356a4cbece26f1fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T23:22:02.972559Z",
     "start_time": "2025-05-20T23:22:02.969596Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-21T01:35:23.550837Z",
     "iopub.status.busy": "2025-05-21T01:35:23.550519Z",
     "iopub.status.idle": "2025-05-21T01:35:23.553023Z",
     "shell.execute_reply": "2025-05-21T01:35:23.552574Z"
    },
    "papermill": {
     "duration": 0.00852,
     "end_time": "2025-05-21T01:35:23.553913",
     "exception": false,
     "start_time": "2025-05-21T01:35:23.545393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n4l_prefix = \"http://example.com/n4l/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a8854b6e8ad1816",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T23:22:03.597565Z",
     "start_time": "2025-05-20T23:22:03.591848Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-21T01:35:23.563853Z",
     "iopub.status.busy": "2025-05-21T01:35:23.563498Z",
     "iopub.status.idle": "2025-05-21T01:35:23.568689Z",
     "shell.execute_reply": "2025-05-21T01:35:23.568239Z"
    },
    "papermill": {
     "duration": 0.011136,
     "end_time": "2025-05-21T01:35:23.569596",
     "exception": false,
     "start_time": "2025-05-21T01:35:23.558460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapping_df = pd.read_csv(predicate_mapping_normalization_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0f2a9001fff07e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T23:22:04.948385Z",
     "start_time": "2025-05-20T23:22:04.944792Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-21T01:35:23.580368Z",
     "iopub.status.busy": "2025-05-21T01:35:23.580032Z",
     "iopub.status.idle": "2025-05-21T01:35:23.583787Z",
     "shell.execute_reply": "2025-05-21T01:35:23.583134Z"
    },
    "papermill": {
     "duration": 0.010113,
     "end_time": "2025-05-21T01:35:23.584681",
     "exception": false,
     "start_time": "2025-05-21T01:35:23.574568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "delimited_text_configs = [\n",
    "    {\n",
    "        \"filename\": \"N4L_Taxonomy_20220802.tsv\",\n",
    "        \"path\": f\"{n4l_data_directory}/N4L_Taxonomy_20220802.tsv\",\n",
    "        \"id_column\": \"N4LID\",\n",
    "        \"delimiter\": \"\\t\"\n",
    "    },\n",
    "    {\n",
    "        \"filename\": \"N4L_Taxonomy_20220802_pruned.tsv\",\n",
    "        \"path\": f\"{n4l_data_directory}/N4L_Taxonomy_20220802_pruned.tsv\",\n",
    "        \"id_column\": \"N4LID\",\n",
    "        \"delimiter\": \"\\t\"\n",
    "    },\n",
    "    {\n",
    "        \"filename\": \"reference_id_mapping.csv\",\n",
    "        \"path\": f\"{n4l_data_directory}/reference_id_mapping.csv\",\n",
    "        \"id_column\": \"refid\",\n",
    "        \"delimiter\": \",\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6fd9cfd0d514063",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T23:22:05.670851Z",
     "start_time": "2025-05-20T23:22:05.666894Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-21T01:35:23.595551Z",
     "iopub.status.busy": "2025-05-21T01:35:23.595187Z",
     "iopub.status.idle": "2025-05-21T01:35:23.598497Z",
     "shell.execute_reply": "2025-05-21T01:35:23.597990Z"
    },
    "papermill": {
     "duration": 0.009666,
     "end_time": "2025-05-21T01:35:23.599399",
     "exception": false,
     "start_time": "2025-05-21T01:35:23.589733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def safe_iri_component(value: str) -> str:\n",
    "    # Replace all whitespace characters and colons with underscores\n",
    "    cleaned = re.sub(r'[\\s:]+', '_', value.strip())\n",
    "    # Percent-encode everything else, but preserve underscores\n",
    "    return quote(cleaned, safe='_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ce9d78bfb627f3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T23:22:06.237695Z",
     "start_time": "2025-05-20T23:22:06.234214Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-21T01:35:23.609893Z",
     "iopub.status.busy": "2025-05-21T01:35:23.609701Z",
     "iopub.status.idle": "2025-05-21T01:35:23.613072Z",
     "shell.execute_reply": "2025-05-21T01:35:23.612616Z"
    },
    "papermill": {
     "duration": 0.009683,
     "end_time": "2025-05-21T01:35:23.613934",
     "exception": false,
     "start_time": "2025-05-21T01:35:23.604251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def str_to_bool(val):\n",
    "    \"\"\"Convert common string values to boolean.\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return False\n",
    "    return str(val).strip().lower() in {\"1\", \"true\", \"yes\", \"y\", \"t\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40edf4e1b52584a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T23:22:06.637198Z",
     "start_time": "2025-05-20T23:22:06.633383Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-21T01:35:23.624658Z",
     "iopub.status.busy": "2025-05-21T01:35:23.624256Z",
     "iopub.status.idle": "2025-05-21T01:35:23.628092Z",
     "shell.execute_reply": "2025-05-21T01:35:23.627635Z"
    },
    "papermill": {
     "duration": 0.010098,
     "end_time": "2025-05-21T01:35:23.628958",
     "exception": false,
     "start_time": "2025-05-21T01:35:23.618860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_transposed_sheet(df, id_column):\n",
    "    df = df.transpose()\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df[1:].reset_index(drop=True)\n",
    "\n",
    "    if id_column not in df.columns:\n",
    "        raise ValueError(f\"'{id_column}' not found in transposed headers\")\n",
    "\n",
    "    df = df.dropna(subset=[id_column])\n",
    "    melted = df.melt(id_vars=[id_column], var_name=\"predicate\", value_name=\"object_value\")\n",
    "    return melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3eaaedd9e7a9ea4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T23:22:07.145823Z",
     "start_time": "2025-05-20T23:22:07.140103Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-21T01:35:23.639505Z",
     "iopub.status.busy": "2025-05-21T01:35:23.639327Z",
     "iopub.status.idle": "2025-05-21T01:35:23.642715Z",
     "shell.execute_reply": "2025-05-21T01:35:23.642253Z"
    },
    "papermill": {
     "duration": 0.009672,
     "end_time": "2025-05-21T01:35:23.643629",
     "exception": false,
     "start_time": "2025-05-21T01:35:23.633957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_standard_sheet(df, id_column):\n",
    "    if id_column not in df.columns:\n",
    "        raise ValueError(f\"'{id_column}' not found in standard headers\")\n",
    "\n",
    "    df = df.dropna(subset=[id_column])\n",
    "    melted = df.melt(id_vars=[id_column], var_name=\"predicate\", value_name=\"object_value\")\n",
    "    return melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d4467bea3f0495c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T23:22:07.612825Z",
     "start_time": "2025-05-20T23:22:07.608711Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-21T01:35:23.676903Z",
     "iopub.status.busy": "2025-05-21T01:35:23.676658Z",
     "iopub.status.idle": "2025-05-21T01:35:23.680669Z",
     "shell.execute_reply": "2025-05-21T01:35:23.680187Z"
    },
    "papermill": {
     "duration": 0.033267,
     "end_time": "2025-05-21T01:35:23.681653",
     "exception": false,
     "start_time": "2025-05-21T01:35:23.648386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def safe_object_term(val):\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    val = str(val).strip()\n",
    "    parsed = urlparse(val)\n",
    "    if parsed.scheme in (\"http\", \"https\") and parsed.netloc and \" \" not in val:\n",
    "        try:\n",
    "            return URIRef(val)  # Only if it's really URI-safe\n",
    "        except:\n",
    "            pass\n",
    "    return Literal(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb598e967da0c2da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T23:22:08.228832Z",
     "start_time": "2025-05-20T23:22:08.226219Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-21T01:35:23.693317Z",
     "iopub.status.busy": "2025-05-21T01:35:23.692729Z",
     "iopub.status.idle": "2025-05-21T01:35:23.695713Z",
     "shell.execute_reply": "2025-05-21T01:35:23.695245Z"
    },
    "papermill": {
     "duration": 0.009606,
     "end_time": "2025-05-21T01:35:23.696630",
     "exception": false,
     "start_time": "2025-05-21T01:35:23.687024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "melted_frames = []\n",
    "melted_dropped_frames = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b210da3d5046b4b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T23:22:19.821942Z",
     "start_time": "2025-05-20T23:22:09.058820Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-21T01:35:23.708577Z",
     "iopub.status.busy": "2025-05-21T01:35:23.708257Z",
     "iopub.status.idle": "2025-05-21T01:35:33.538109Z",
     "shell.execute_reply": "2025-05-21T01:35:33.537574Z"
    },
    "papermill": {
     "duration": 9.836886,
     "end_time": "2025-05-21T01:35:33.539017",
     "exception": false,
     "start_time": "2025-05-21T01:35:23.702131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DUPLICATES] N4L_Taxonomy_20220802.tsv - No duplicates in 'N4LID'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] N4L_Taxonomy_20220802.tsv → 1273296 melted rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DUPLICATES] N4L_Taxonomy_20220802_pruned.tsv - No duplicates in 'N4LID'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] N4L_Taxonomy_20220802_pruned.tsv → 957331 melted rows\n",
      "[DUPLICATES] reference_id_mapping.csv - No duplicates in 'refid'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] reference_id_mapping.csv → 64272 melted rows\n"
     ]
    }
   ],
   "source": [
    "for config in delimited_text_configs:\n",
    "    try:\n",
    "        df = pd.read_csv(config[\"path\"], sep=config[\"delimiter\"], low_memory=False)\n",
    "\n",
    "        graph_iri = f\"{n4l_prefix}{safe_iri_component(config['filename'].strip())}\"\n",
    "\n",
    "        # Remove exact duplicates before anything else\n",
    "        before = df.shape[0]\n",
    "        df = df.drop_duplicates()\n",
    "        after = df.shape[0]\n",
    "        if after < before:\n",
    "            print(f\"[QC] {config['filename']} - Removed {before - after} fully duplicated rows\")\n",
    "\n",
    "        id_column = config[\"id_column\"]\n",
    "        if id_column not in df.columns:\n",
    "            print(\n",
    "                f\"[ERROR] {config['filename']} - ID column '{id_column}' not found. Available columns: {df.columns.tolist()}\")\n",
    "            continue\n",
    "\n",
    "        # Drop and log missing ID rows\n",
    "        missing_id_rows = df[df[id_column].isna()]\n",
    "        if not missing_id_rows.empty:\n",
    "            print(f\"[QC] {config['filename']} - Dropped {len(missing_id_rows)} rows missing '{id_column}'\")\n",
    "            melted_missing = missing_id_rows.melt(var_name=\"predicate\", value_name=\"object_value\")\n",
    "            melted_missing[\"subject\"] = None\n",
    "            melted_missing[\"source_file\"] = config[\"filename\"]\n",
    "            melted_missing[\"drop_reason\"] = \"missing_id\"\n",
    "            melted_missing[\"graph\"] = graph_iri\n",
    "            melted_dropped_frames.append(melted_missing)\n",
    "\n",
    "        df = df.dropna(subset=[id_column])\n",
    "\n",
    "        # Drop and log duplicated IDs\n",
    "        duplicated_mask = df[id_column].duplicated(keep=False)\n",
    "        if duplicated_mask.any():\n",
    "            duplicated_ids = df.loc[duplicated_mask, id_column].unique()\n",
    "            print(\n",
    "                f\"[DUPLICATES] {config['filename']} - {duplicated_mask.sum()} duplicate rows on '{id_column}' → {duplicated_ids.tolist()}\")\n",
    "            melted_dupes = df.loc[duplicated_mask].melt(var_name=\"predicate\", value_name=\"object_value\")\n",
    "            melted_dupes[\"subject\"] = df.loc[duplicated_mask, id_column].values.repeat(len(df.columns) - 1)\n",
    "            melted_dupes[\"source_file\"] = config[\"filename\"]\n",
    "            melted_dupes[\"drop_reason\"] = \"duplicate_id\"\n",
    "            melted_dupes[\"graph\"] = graph_iri\n",
    "            melted_dropped_frames.append(melted_dupes)\n",
    "            df = df[~duplicated_mask]\n",
    "        else:\n",
    "            print(f\"[DUPLICATES] {config['filename']} - No duplicates in '{id_column}'\")\n",
    "\n",
    "        # Melt and append\n",
    "        melted = df.melt(id_vars=[id_column], var_name=\"predicate\", value_name=\"object_value\")\n",
    "        melted = melted.rename(columns={id_column: \"subject\"})\n",
    "        melted = melted.dropna(subset=[\"subject\", \"predicate\", \"object_value\"])\n",
    "        melted[\"subject\"] = melted[\"subject\"].astype(str).apply(\n",
    "            lambda x: f\"{n4l_prefix}{safe_iri_component(x.strip())}\")\n",
    "        melted[\"predicate\"] = melted[\"predicate\"].astype(str).apply(\n",
    "            lambda x: f\"{n4l_prefix}{safe_iri_component(x.strip())}\")\n",
    "        melted[\"source_file\"] = config[\"filename\"]\n",
    "        melted[\"graph\"] = graph_iri\n",
    "        melted_frames.append(melted)\n",
    "        print(f\"[INFO] {config['filename']} → {melted.shape[0]} melted rows\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed processing {config['filename']} - {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "195a6f6efc35977a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T01:35:33.553818Z",
     "iopub.status.busy": "2025-05-21T01:35:33.553588Z",
     "iopub.status.idle": "2025-05-21T01:35:33.557955Z",
     "shell.execute_reply": "2025-05-21T01:35:33.557523Z"
    },
    "papermill": {
     "duration": 0.014771,
     "end_time": "2025-05-21T01:35:33.558819",
     "exception": false,
     "start_time": "2025-05-21T01:35:33.544048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xlsx_sheet_configs = pd.read_csv(xlsx_config_path, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab05691a8eca9c70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T01:35:33.569682Z",
     "iopub.status.busy": "2025-05-21T01:35:33.569363Z",
     "iopub.status.idle": "2025-05-21T01:35:33.583195Z",
     "shell.execute_reply": "2025-05-21T01:35:33.582673Z"
    },
    "papermill": {
     "duration": 0.020264,
     "end_time": "2025-05-21T01:35:33.584033",
     "exception": false,
     "start_time": "2025-05-21T01:35:33.563769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>sheet_name</th>\n",
       "      <th>id_column</th>\n",
       "      <th>skip</th>\n",
       "      <th>requires_transposition</th>\n",
       "      <th>spo_already</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>article_download_status_20161222.xlsx</td>\n",
       "      <td>all_protologs</td>\n",
       "      <td>UID</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UID style: rid.10014_nm.6832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>article_download_status_20161222.xlsx</td>\n",
       "      <td>parsed_protologs</td>\n",
       "      <td>UID</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>complete.term.book_07.18.2013_CTP.xlsx</td>\n",
       "      <td>Sheet1</td>\n",
       "      <td>Term|class</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>complete.term.book_07.18.2013_CTP.xlsx</td>\n",
       "      <td>Sheet2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>blank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>complete.term.book_07.18.2013_CTP.xlsx</td>\n",
       "      <td>Sheet3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>blank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>media_normalized_20130916.xlsx</td>\n",
       "      <td>chemical_exemplar</td>\n",
       "      <td>chemical_exemplar.id</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>media_normalized_20130916.xlsx</td>\n",
       "      <td>chemical_name</td>\n",
       "      <td>chemical_name.id</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>media_normalized_20130916.xlsx</td>\n",
       "      <td>chemical_taxon</td>\n",
       "      <td>chemical_taxon.id</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>media_normalized_20130916.xlsx</td>\n",
       "      <td>chemical_taxon_exemplar</td>\n",
       "      <td>chemical_taxon.id</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>media_normalized_20130916.xlsx</td>\n",
       "      <td>ingredient</td>\n",
       "      <td>substance_id</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(inconsistent) Excel formulae in substance_nam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>media_normalized_20130916.xlsx</td>\n",
       "      <td>medium</td>\n",
       "      <td>substance_exemplar.id</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>media_normalized_20130916.xlsx</td>\n",
       "      <td>medium_features</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>media_normalized_20130916.xlsx</td>\n",
       "      <td>medium_name</td>\n",
       "      <td>substance_name.id</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>media_normalized_20130916.xlsx</td>\n",
       "      <td>medium_taxon</td>\n",
       "      <td>substance_taxon.id</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>media_normalized_20130916.xlsx</td>\n",
       "      <td>medium_taxon_exemplar</td>\n",
       "      <td>taxon_id</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>media_normalized_20130916.xlsx</td>\n",
       "      <td>medium_taxonomy</td>\n",
       "      <td>substance_taxonomy.parent_taxon_id|substance_t...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>media_normalized_20130916.xlsx</td>\n",
       "      <td>medium_taxonomy_full</td>\n",
       "      <td>substance_name.id</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>media_normalized_20130916.xlsx</td>\n",
       "      <td>mixture_exemplar</td>\n",
       "      <td>exemplar_id</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>media_normalized_20130916.xlsx</td>\n",
       "      <td>mixture_ingredient</td>\n",
       "      <td>ingredient.list_id|sort_order</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>media_normalized_20130916.xlsx</td>\n",
       "      <td>mixture_name</td>\n",
       "      <td>substance_name.id</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>media_normalized_20130916.xlsx</td>\n",
       "      <td>mixture_taxon</td>\n",
       "      <td>substance_taxon.id</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>media_normalized_20130916.xlsx</td>\n",
       "      <td>mixture_taxon_exemplar</td>\n",
       "      <td>taxon_id</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>media_normalized_20130916.xlsx</td>\n",
       "      <td>mixture_taxonomy</td>\n",
       "      <td>substance_taxonomy.parent|substance_taxonomy.c...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>media_normalized_20130916.xlsx</td>\n",
       "      <td>product</td>\n",
       "      <td>substance_name.id|vendor|productId</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>media_normalized_20130916.xlsx</td>\n",
       "      <td>substance_exemplar</td>\n",
       "      <td>substance_exemplar.id</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>media_normalized_20130916.xlsx</td>\n",
       "      <td>substance_exemplar_feature</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>blank except for headers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>media_normalized_20130916.xlsx</td>\n",
       "      <td>substance_exemplar_type</td>\n",
       "      <td>substance_exemplar_feature_type.type</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>media_normalized_20130916.xlsx</td>\n",
       "      <td>unit</td>\n",
       "      <td>id</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>media_normalized_20130916.xlsx</td>\n",
       "      <td>vendor</td>\n",
       "      <td>abbrev</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>N4L_ID_to_NCBI_mappings.xlsx</td>\n",
       "      <td>N4L_NM.ID_to_EX.ID</td>\n",
       "      <td>Name N4LID</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>N4L_ID_to_NCBI_mappings.xlsx</td>\n",
       "      <td>N4L_NM.ID_to_NCBI_TaxID</td>\n",
       "      <td>Name N4LID</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>N4L_ID_to_NCBI_mappings.xlsx</td>\n",
       "      <td>N4L_REF.ID_to_DOCID</td>\n",
       "      <td>refid</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>N4L_Taxonomy_20220802_pruned.xlsx</td>\n",
       "      <td>N4L_Taxonomy_20220802_pruned</td>\n",
       "      <td>N4LID</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>N4L_Taxonomy_20220802.xlsx</td>\n",
       "      <td>N4L_Taxonomy_20220802_complete</td>\n",
       "      <td>N4LID</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>N4L_Taxonomy_20220802.xlsx</td>\n",
       "      <td>N4L_Taxonomy_20220802_pruned</td>\n",
       "      <td>N4LID</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>protolog_normalization_categories_with_1000_DB...</td>\n",
       "      <td>1000_proto_proj</td>\n",
       "      <td>rid (effective)|name.id</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>protolog_normalization_categories_with_1000_DB...</td>\n",
       "      <td>Sheet1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two-level class hierarchy of traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>protolog_normalization_categories_with_1000_DB...</td>\n",
       "      <td>Sheet2</td>\n",
       "      <td>rid|name.id</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>protolog_normalization_categories_with_1000_DB...</td>\n",
       "      <td>Sheet3</td>\n",
       "      <td>rid|name.id</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>protolog_normalization_categories_with_1000_KM...</td>\n",
       "      <td>1000_proto_proj</td>\n",
       "      <td>rid (effective/emendation)|name.id</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>protolog_normalization_categories_with_1000_KM...</td>\n",
       "      <td>All(Sheet1,2,3)</td>\n",
       "      <td>rid|name.id</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>protolog_normalization_categories_with_1000_KM...</td>\n",
       "      <td>EffectRIDProtos(rid.2300 up)</td>\n",
       "      <td>rid|name.id</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>protolog_normalization_categories_with_1000_KM...</td>\n",
       "      <td>Notes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>skip notes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>protolog_normalization_categories_with_1000_KM...</td>\n",
       "      <td>Sheet2</td>\n",
       "      <td>rid|name.id</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             filename  \\\n",
       "0               article_download_status_20161222.xlsx   \n",
       "1               article_download_status_20161222.xlsx   \n",
       "2              complete.term.book_07.18.2013_CTP.xlsx   \n",
       "3              complete.term.book_07.18.2013_CTP.xlsx   \n",
       "4              complete.term.book_07.18.2013_CTP.xlsx   \n",
       "5                      media_normalized_20130916.xlsx   \n",
       "6                      media_normalized_20130916.xlsx   \n",
       "7                      media_normalized_20130916.xlsx   \n",
       "8                      media_normalized_20130916.xlsx   \n",
       "9                      media_normalized_20130916.xlsx   \n",
       "10                     media_normalized_20130916.xlsx   \n",
       "11                     media_normalized_20130916.xlsx   \n",
       "12                     media_normalized_20130916.xlsx   \n",
       "13                     media_normalized_20130916.xlsx   \n",
       "14                     media_normalized_20130916.xlsx   \n",
       "15                     media_normalized_20130916.xlsx   \n",
       "16                     media_normalized_20130916.xlsx   \n",
       "17                     media_normalized_20130916.xlsx   \n",
       "18                     media_normalized_20130916.xlsx   \n",
       "19                     media_normalized_20130916.xlsx   \n",
       "20                     media_normalized_20130916.xlsx   \n",
       "21                     media_normalized_20130916.xlsx   \n",
       "22                     media_normalized_20130916.xlsx   \n",
       "23                     media_normalized_20130916.xlsx   \n",
       "24                     media_normalized_20130916.xlsx   \n",
       "25                     media_normalized_20130916.xlsx   \n",
       "26                     media_normalized_20130916.xlsx   \n",
       "27                     media_normalized_20130916.xlsx   \n",
       "28                     media_normalized_20130916.xlsx   \n",
       "29                       N4L_ID_to_NCBI_mappings.xlsx   \n",
       "30                       N4L_ID_to_NCBI_mappings.xlsx   \n",
       "31                       N4L_ID_to_NCBI_mappings.xlsx   \n",
       "32                  N4L_Taxonomy_20220802_pruned.xlsx   \n",
       "33                         N4L_Taxonomy_20220802.xlsx   \n",
       "34                         N4L_Taxonomy_20220802.xlsx   \n",
       "35  protolog_normalization_categories_with_1000_DB...   \n",
       "36  protolog_normalization_categories_with_1000_DB...   \n",
       "37  protolog_normalization_categories_with_1000_DB...   \n",
       "38  protolog_normalization_categories_with_1000_DB...   \n",
       "39  protolog_normalization_categories_with_1000_KM...   \n",
       "40  protolog_normalization_categories_with_1000_KM...   \n",
       "41  protolog_normalization_categories_with_1000_KM...   \n",
       "42  protolog_normalization_categories_with_1000_KM...   \n",
       "43  protolog_normalization_categories_with_1000_KM...   \n",
       "\n",
       "                        sheet_name  \\\n",
       "0                    all_protologs   \n",
       "1                 parsed_protologs   \n",
       "2                           Sheet1   \n",
       "3                           Sheet2   \n",
       "4                           Sheet3   \n",
       "5                chemical_exemplar   \n",
       "6                    chemical_name   \n",
       "7                   chemical_taxon   \n",
       "8          chemical_taxon_exemplar   \n",
       "9                       ingredient   \n",
       "10                          medium   \n",
       "11                 medium_features   \n",
       "12                     medium_name   \n",
       "13                    medium_taxon   \n",
       "14           medium_taxon_exemplar   \n",
       "15                 medium_taxonomy   \n",
       "16            medium_taxonomy_full   \n",
       "17                mixture_exemplar   \n",
       "18              mixture_ingredient   \n",
       "19                    mixture_name   \n",
       "20                   mixture_taxon   \n",
       "21          mixture_taxon_exemplar   \n",
       "22                mixture_taxonomy   \n",
       "23                         product   \n",
       "24              substance_exemplar   \n",
       "25      substance_exemplar_feature   \n",
       "26         substance_exemplar_type   \n",
       "27                            unit   \n",
       "28                          vendor   \n",
       "29              N4L_NM.ID_to_EX.ID   \n",
       "30         N4L_NM.ID_to_NCBI_TaxID   \n",
       "31             N4L_REF.ID_to_DOCID   \n",
       "32    N4L_Taxonomy_20220802_pruned   \n",
       "33  N4L_Taxonomy_20220802_complete   \n",
       "34    N4L_Taxonomy_20220802_pruned   \n",
       "35                 1000_proto_proj   \n",
       "36                          Sheet1   \n",
       "37                          Sheet2   \n",
       "38                          Sheet3   \n",
       "39                 1000_proto_proj   \n",
       "40                 All(Sheet1,2,3)   \n",
       "41    EffectRIDProtos(rid.2300 up)   \n",
       "42                           Notes   \n",
       "43                          Sheet2   \n",
       "\n",
       "                                            id_column   skip  \\\n",
       "0                                                 UID  False   \n",
       "1                                                 UID  False   \n",
       "2                                          Term|class  False   \n",
       "3                                                 NaN   True   \n",
       "4                                                 NaN   True   \n",
       "5                                chemical_exemplar.id  False   \n",
       "6                                    chemical_name.id  False   \n",
       "7                                   chemical_taxon.id  False   \n",
       "8                                   chemical_taxon.id  False   \n",
       "9                                        substance_id  False   \n",
       "10                              substance_exemplar.id  False   \n",
       "11                                                NaN  False   \n",
       "12                                  substance_name.id  False   \n",
       "13                                 substance_taxon.id  False   \n",
       "14                                           taxon_id  False   \n",
       "15  substance_taxonomy.parent_taxon_id|substance_t...  False   \n",
       "16                                  substance_name.id  False   \n",
       "17                                        exemplar_id  False   \n",
       "18                      ingredient.list_id|sort_order  False   \n",
       "19                                  substance_name.id  False   \n",
       "20                                 substance_taxon.id  False   \n",
       "21                                           taxon_id  False   \n",
       "22  substance_taxonomy.parent|substance_taxonomy.c...  False   \n",
       "23                 substance_name.id|vendor|productId  False   \n",
       "24                              substance_exemplar.id  False   \n",
       "25                                                NaN   True   \n",
       "26               substance_exemplar_feature_type.type  False   \n",
       "27                                                 id  False   \n",
       "28                                             abbrev  False   \n",
       "29                                         Name N4LID  False   \n",
       "30                                         Name N4LID  False   \n",
       "31                                              refid  False   \n",
       "32                                              N4LID  False   \n",
       "33                                              N4LID  False   \n",
       "34                                              N4LID  False   \n",
       "35                            rid (effective)|name.id  False   \n",
       "36                                                NaN   True   \n",
       "37                                        rid|name.id  False   \n",
       "38                                        rid|name.id  False   \n",
       "39                 rid (effective/emendation)|name.id  False   \n",
       "40                                        rid|name.id  False   \n",
       "41                                        rid|name.id  False   \n",
       "42                                                NaN   True   \n",
       "43                                        rid|name.id  False   \n",
       "\n",
       "    requires_transposition spo_already  \\\n",
       "0                    False         NaN   \n",
       "1                    False         NaN   \n",
       "2                    False         NaN   \n",
       "3                    False         NaN   \n",
       "4                    False         NaN   \n",
       "5                    False         NaN   \n",
       "6                    False         NaN   \n",
       "7                    False         NaN   \n",
       "8                    False         NaN   \n",
       "9                    False         NaN   \n",
       "10                   False         NaN   \n",
       "11                   False        True   \n",
       "12                   False         NaN   \n",
       "13                   False         NaN   \n",
       "14                   False         NaN   \n",
       "15                   False         NaN   \n",
       "16                   False         NaN   \n",
       "17                   False         NaN   \n",
       "18                   False         NaN   \n",
       "19                   False         NaN   \n",
       "20                   False         NaN   \n",
       "21                   False         NaN   \n",
       "22                   False         NaN   \n",
       "23                   False         NaN   \n",
       "24                   False         NaN   \n",
       "25                   False         NaN   \n",
       "26                   False         NaN   \n",
       "27                   False         NaN   \n",
       "28                   False         NaN   \n",
       "29                   False         NaN   \n",
       "30                   False         NaN   \n",
       "31                   False         NaN   \n",
       "32                   False         NaN   \n",
       "33                   False         NaN   \n",
       "34                   False         NaN   \n",
       "35                    True         NaN   \n",
       "36                   False         NaN   \n",
       "37                    True         NaN   \n",
       "38                    True         NaN   \n",
       "39                    True         NaN   \n",
       "40                    True         NaN   \n",
       "41                    True         NaN   \n",
       "42                   False         NaN   \n",
       "43                    True         NaN   \n",
       "\n",
       "                                                 note  \n",
       "0                        UID style: rid.10014_nm.6832  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3                                               blank  \n",
       "4                                               blank  \n",
       "5                                                 NaN  \n",
       "6                                                 NaN  \n",
       "7                                                 NaN  \n",
       "8                                                 NaN  \n",
       "9   (inconsistent) Excel formulae in substance_nam...  \n",
       "10                                                NaN  \n",
       "11                                                NaN  \n",
       "12                                                NaN  \n",
       "13                                                NaN  \n",
       "14                                                NaN  \n",
       "15                                                NaN  \n",
       "16                                                NaN  \n",
       "17                                                NaN  \n",
       "18                                                NaN  \n",
       "19                                                NaN  \n",
       "20                                                NaN  \n",
       "21                                                NaN  \n",
       "22                                                NaN  \n",
       "23                                                NaN  \n",
       "24                                                NaN  \n",
       "25                           blank except for headers  \n",
       "26                                                NaN  \n",
       "27                                                NaN  \n",
       "28                                                NaN  \n",
       "29                                                NaN  \n",
       "30                                                NaN  \n",
       "31                                                NaN  \n",
       "32                                                NaN  \n",
       "33                                                NaN  \n",
       "34                                                NaN  \n",
       "35                                                NaN  \n",
       "36                Two-level class hierarchy of traits  \n",
       "37                                                NaN  \n",
       "38                                                NaN  \n",
       "39                                                NaN  \n",
       "40                                                NaN  \n",
       "41                                                NaN  \n",
       "42                                         skip notes  \n",
       "43                                                NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlsx_sheet_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed5ff837b87cbfbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T01:35:33.597295Z",
     "iopub.status.busy": "2025-05-21T01:35:33.597046Z",
     "iopub.status.idle": "2025-05-21T01:37:01.019715Z",
     "shell.execute_reply": "2025-05-21T01:37:01.019201Z"
    },
    "papermill": {
     "duration": 87.4308,
     "end_time": "2025-05-21T01:37:01.020709",
     "exception": false,
     "start_time": "2025-05-21T01:35:33.589909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename                  article_download_status_20161222.xlsx\n",
      "sheet_name                                        all_protologs\n",
      "id_column                                                   UID\n",
      "skip                                                      False\n",
      "requires_transposition                                    False\n",
      "spo_already                                                 NaN\n",
      "note                               UID style: rid.10014_nm.6832\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DUPLICATES] article_download_status_20161222.xlsx:all_protologs - No duplicates in 'UID'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] article_download_status_20161222.xlsx:all_protologs → 58601 melted rows\n",
      "filename                  article_download_status_20161222.xlsx\n",
      "sheet_name                                     parsed_protologs\n",
      "id_column                                                   UID\n",
      "skip                                                      False\n",
      "requires_transposition                                    False\n",
      "spo_already                                                 NaN\n",
      "note                                                        NaN\n",
      "Name: 1, dtype: object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DUPLICATES] article_download_status_20161222.xlsx:parsed_protologs - No duplicates in 'UID'\n",
      "[INFO] article_download_status_20161222.xlsx:parsed_protologs → 39440 melted rows\n",
      "filename                  complete.term.book_07.18.2013_CTP.xlsx\n",
      "sheet_name                                                Sheet1\n",
      "id_column                                             Term|class\n",
      "skip                                                       False\n",
      "requires_transposition                                     False\n",
      "spo_already                                                  NaN\n",
      "note                                                         NaN\n",
      "Name: 2, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213811/3098165260.py:57: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[matched] = df[matched].astype(str).applymap(lambda v: v.strip() if isinstance(v, str) else v)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created synthetic ID column 'Term_class' from: ['Term', 'class']\n",
      "[DUPLICATES] complete.term.book_07.18.2013_CTP.xlsx:Sheet1 - No duplicates in 'Term_class'\n",
      "[INFO] complete.term.book_07.18.2013_CTP.xlsx:Sheet1 → 4309 melted rows\n",
      "filename                  complete.term.book_07.18.2013_CTP.xlsx\n",
      "sheet_name                                                Sheet2\n",
      "id_column                                                    NaN\n",
      "skip                                                        True\n",
      "requires_transposition                                     False\n",
      "spo_already                                                  NaN\n",
      "note                                                       blank\n",
      "Name: 3, dtype: object\n",
      "filename                  complete.term.book_07.18.2013_CTP.xlsx\n",
      "sheet_name                                                Sheet3\n",
      "id_column                                                    NaN\n",
      "skip                                                        True\n",
      "requires_transposition                                     False\n",
      "spo_already                                                  NaN\n",
      "note                                                       blank\n",
      "Name: 4, dtype: object\n",
      "filename                  media_normalized_20130916.xlsx\n",
      "sheet_name                             chemical_exemplar\n",
      "id_column                           chemical_exemplar.id\n",
      "skip                                               False\n",
      "requires_transposition                             False\n",
      "spo_already                                          NaN\n",
      "note                                                 NaN\n",
      "Name: 5, dtype: object\n",
      "[DUPLICATES] media_normalized_20130916.xlsx:chemical_exemplar - No duplicates in 'chemical_exemplar.id'\n",
      "[INFO] media_normalized_20130916.xlsx:chemical_exemplar → 240 melted rows\n",
      "filename                  media_normalized_20130916.xlsx\n",
      "sheet_name                                 chemical_name\n",
      "id_column                               chemical_name.id\n",
      "skip                                               False\n",
      "requires_transposition                             False\n",
      "spo_already                                          NaN\n",
      "note                                                 NaN\n",
      "Name: 6, dtype: object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DUPLICATES] media_normalized_20130916.xlsx:chemical_name - No duplicates in 'chemical_name.id'\n",
      "[INFO] media_normalized_20130916.xlsx:chemical_name → 258 melted rows\n",
      "filename                  media_normalized_20130916.xlsx\n",
      "sheet_name                                chemical_taxon\n",
      "id_column                              chemical_taxon.id\n",
      "skip                                               False\n",
      "requires_transposition                             False\n",
      "spo_already                                          NaN\n",
      "note                                                 NaN\n",
      "Name: 7, dtype: object\n",
      "[DUPLICATES] media_normalized_20130916.xlsx:chemical_taxon - No duplicates in 'chemical_taxon.id'\n",
      "[INFO] media_normalized_20130916.xlsx:chemical_taxon → 114 melted rows\n",
      "filename                  media_normalized_20130916.xlsx\n",
      "sheet_name                       chemical_taxon_exemplar\n",
      "id_column                              chemical_taxon.id\n",
      "skip                                               False\n",
      "requires_transposition                             False\n",
      "spo_already                                          NaN\n",
      "note                                                 NaN\n",
      "Name: 8, dtype: object\n",
      "[DUPLICATES] media_normalized_20130916.xlsx:chemical_taxon_exemplar - No duplicates in 'chemical_taxon.id'\n",
      "[INFO] media_normalized_20130916.xlsx:chemical_taxon_exemplar → 114 melted rows\n",
      "filename                                     media_normalized_20130916.xlsx\n",
      "sheet_name                                                       ingredient\n",
      "id_column                                                      substance_id\n",
      "skip                                                                  False\n",
      "requires_transposition                                                False\n",
      "spo_already                                                             NaN\n",
      "note                      (inconsistent) Excel formulae in substance_nam...\n",
      "Name: 9, dtype: object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DUPLICATES] media_normalized_20130916.xlsx:ingredient - 920 duplicate rows on 'substance_id' → ['CHEBI:17634', 'N4L.m_p:00001', 'CHEBI:26710', 'N4L.m_p:00004', 'N4L.m_p:00002', 'N4L.m_p:00003', 'N4L.m_p:00005', 'CHEBI:17716', 'CHEBI:17992', 'N4L.m_p:00008', 'CHEBI:31991', 'N4L.m_p:00006', 'N4L.m_p:00021', 'N4L.m_p:00009', 'CHEBI:50144', 'CHEBI:32599', 'N4L.m_p:00010', 'N4L.m_p:00011', 'N4L.m_p:00012', 'N4L.m_p:00013', 'CHEBI:63005', 'CHEBI:32588', 'CHEBI:31795', 'N4L.m_p:00014', 'N4L.m_p:00015', 'CHEBI:32954', 'CHEBI:53426', 'CHEBI:53258', 'N4L.m_p:00019', 'N4L.m_p:00020', 'N4L.m_p:00030', 'N4L.m_p:00022', 'CHEBI:3311', 'CHEBI:62946', 'CHEBI:63041', 'CHEBI:32312', 'CHEBI:34683', 'CHEBI:63036', 'N4L.m_p:00023', 'N4L.m_p:00040', 'CHEBI:16899', 'N4L.m_p:00031', 'CHEBI:31604', 'N4L.m_p:00045', 'CHEBI:22653', 'N4L.m_p:00024', 'CHEBI:72449', 'CHEBI:17754', 'N4L.m_p:00054', 'CHEBI:16015', 'CHEBI:31440', 'CHEBI:16709', 'CHEBI:15956', 'CHEBI:3312', '10.1601/mixture.exemplar.43', '10.1601/mixture.exemplar.44', 'N4L.m_p:00026', 'N4L.m_p:00027', 'N4L.m_p:00035', 'N4L.m_p:00064', 'N4L.m_p:00065', 'N4L.m_p:00060', '10.1601/mixture.exemplar.4', 'CHEBI:17561', 'CHEBI:29377', 'CHEBI:9754', 'CHEBI:31206', 'CHEBI:52053', 'CHEBI:6872', 'CHEBI:17196', 'N4L.m_p:00051', 'N4L.m_p:00061', 'N4L.m_p:00036', 'CHEBI:30753', 'CHEBI:35143', 'N4L.m_p:00039', 'N4L.m_p:00044', 'CHEBI:33118', 'CHEBI:6636', 'CHEBI:32139', 'CHEBI:32030', 'CHEBI:36383', 'CHEBI:60720', 'CHEBI:28741', 'CHEBI:63038', 'CHEBI:28017', 'CHEBI:63043', 'CHEBI:4853', 'N4L.m_p:00047', 'N4L.m_p:00037', 'CHEBI:26709', 'N4L.m_p:00049', 'N4L.m_p:00032', 'N4L.m_p:00043', 'N4L.m_p:00046', 'CHEBI:17306', 'CHEBI:64220', 'CHEBI:9177', '10.1601/mixture.exemplar.12', 'CHEBI:58083', 'CHEBI:29073', 'CHEBI:30808', 'CHEBI:18385']\n",
      "[INFO] media_normalized_20130916.xlsx:ingredient → 438 melted rows\n",
      "filename                  media_normalized_20130916.xlsx\n",
      "sheet_name                                        medium\n",
      "id_column                          substance_exemplar.id\n",
      "skip                                               False\n",
      "requires_transposition                             False\n",
      "spo_already                                          NaN\n",
      "note                                                 NaN\n",
      "Name: 10, dtype: object\n",
      "[DUPLICATES] media_normalized_20130916.xlsx:medium - 4 duplicate rows on 'substance_exemplar.id' → ['10.1601/medium.exemplar.58', '10.1601/medium.exemplar.279']\n",
      "[INFO] media_normalized_20130916.xlsx:medium → 143 melted rows\n",
      "filename                  media_normalized_20130916.xlsx\n",
      "sheet_name                               medium_features\n",
      "id_column                                            NaN\n",
      "skip                                               False\n",
      "requires_transposition                             False\n",
      "spo_already                                         True\n",
      "note                                                 NaN\n",
      "Name: 11, dtype: object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] media_normalized_20130916.xlsx:medium_features (SPO) → 627 rows\n",
      "filename                  media_normalized_20130916.xlsx\n",
      "sheet_name                                   medium_name\n",
      "id_column                              substance_name.id\n",
      "skip                                               False\n",
      "requires_transposition                             False\n",
      "spo_already                                          NaN\n",
      "note                                                 NaN\n",
      "Name: 12, dtype: object\n",
      "[DUPLICATES] media_normalized_20130916.xlsx:medium_name - No duplicates in 'substance_name.id'\n",
      "[INFO] media_normalized_20130916.xlsx:medium_name → 989 melted rows\n",
      "filename                  media_normalized_20130916.xlsx\n",
      "sheet_name                                  medium_taxon\n",
      "id_column                             substance_taxon.id\n",
      "skip                                               False\n",
      "requires_transposition                             False\n",
      "spo_already                                          NaN\n",
      "note                                                 NaN\n",
      "Name: 13, dtype: object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DUPLICATES] media_normalized_20130916.xlsx:medium_taxon - No duplicates in 'substance_taxon.id'\n",
      "[INFO] media_normalized_20130916.xlsx:medium_taxon → 362 melted rows\n",
      "filename                  media_normalized_20130916.xlsx\n",
      "sheet_name                         medium_taxon_exemplar\n",
      "id_column                                       taxon_id\n",
      "skip                                               False\n",
      "requires_transposition                             False\n",
      "spo_already                                          NaN\n",
      "note                                                 NaN\n",
      "Name: 14, dtype: object\n",
      "[ERROR] media_normalized_20130916.xlsx:medium_taxon_exemplar - ID column 'taxon_id' not found. Available columns: ['medium_taxon_exemplar.taxon_id', 'medium_taxon_exemplar.exemplar_id']\n",
      "filename                                     media_normalized_20130916.xlsx\n",
      "sheet_name                                                  medium_taxonomy\n",
      "id_column                 substance_taxonomy.parent_taxon_id|substance_t...\n",
      "skip                                                                  False\n",
      "requires_transposition                                                False\n",
      "spo_already                                                             NaN\n",
      "note                                                                    NaN\n",
      "Name: 15, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213811/3098165260.py:57: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[matched] = df[matched].astype(str).applymap(lambda v: v.strip() if isinstance(v, str) else v)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created synthetic ID column 'substance_taxonomy.parent_taxon_id_substance_taxonomy.child_taxon_id' from: ['substance_taxonomy.parent_taxon_id', 'substance_taxonomy.child_taxon_id']\n",
      "[DUPLICATES] media_normalized_20130916.xlsx:medium_taxonomy - No duplicates in 'substance_taxonomy.parent_taxon_id_substance_taxonomy.child_taxon_id'\n",
      "[INFO] media_normalized_20130916.xlsx:medium_taxonomy → 722 melted rows\n",
      "filename                  media_normalized_20130916.xlsx\n",
      "sheet_name                          medium_taxonomy_full\n",
      "id_column                              substance_name.id\n",
      "skip                                               False\n",
      "requires_transposition                             False\n",
      "spo_already                                          NaN\n",
      "note                                                 NaN\n",
      "Name: 16, dtype: object\n",
      "[DUPLICATES] media_normalized_20130916.xlsx:medium_taxonomy_full - No duplicates in 'substance_name.id'\n",
      "[INFO] media_normalized_20130916.xlsx:medium_taxonomy_full → 2248 melted rows\n",
      "filename                  media_normalized_20130916.xlsx\n",
      "sheet_name                              mixture_exemplar\n",
      "id_column                                    exemplar_id\n",
      "skip                                               False\n",
      "requires_transposition                             False\n",
      "spo_already                                          NaN\n",
      "note                                                 NaN\n",
      "Name: 17, dtype: object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DUPLICATES] media_normalized_20130916.xlsx:mixture_exemplar - No duplicates in 'exemplar_id'\n",
      "[INFO] media_normalized_20130916.xlsx:mixture_exemplar → 99 melted rows\n",
      "filename                  media_normalized_20130916.xlsx\n",
      "sheet_name                            mixture_ingredient\n",
      "id_column                  ingredient.list_id|sort_order\n",
      "skip                                               False\n",
      "requires_transposition                             False\n",
      "spo_already                                          NaN\n",
      "note                                                 NaN\n",
      "Name: 18, dtype: object\n",
      "[INFO] Created synthetic ID column 'ingredient.list_id_sort_order' from: ['ingredient.list_id', 'sort_order']\n",
      "[DUPLICATES] media_normalized_20130916.xlsx:mixture_ingredient - No duplicates in 'ingredient.list_id_sort_order'\n",
      "[INFO] media_normalized_20130916.xlsx:mixture_ingredient → 527 melted rows\n",
      "filename                  media_normalized_20130916.xlsx\n",
      "sheet_name                                  mixture_name\n",
      "id_column                              substance_name.id\n",
      "skip                                               False\n",
      "requires_transposition                             False\n",
      "spo_already                                          NaN\n",
      "note                                                 NaN\n",
      "Name: 19, dtype: object\n",
      "[DUPLICATES] media_normalized_20130916.xlsx:mixture_name - No duplicates in 'substance_name.id'\n",
      "[INFO] media_normalized_20130916.xlsx:mixture_name → 110 melted rows\n",
      "filename                  media_normalized_20130916.xlsx\n",
      "sheet_name                                 mixture_taxon\n",
      "id_column                             substance_taxon.id\n",
      "skip                                               False\n",
      "requires_transposition                             False\n",
      "spo_already                                          NaN\n",
      "note                                                 NaN\n",
      "Name: 20, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213811/3098165260.py:57: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[matched] = df[matched].astype(str).applymap(lambda v: v.strip() if isinstance(v, str) else v)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DUPLICATES] media_normalized_20130916.xlsx:mixture_taxon - No duplicates in 'substance_taxon.id'\n",
      "[INFO] media_normalized_20130916.xlsx:mixture_taxon → 53 melted rows\n",
      "filename                  media_normalized_20130916.xlsx\n",
      "sheet_name                        mixture_taxon_exemplar\n",
      "id_column                                       taxon_id\n",
      "skip                                               False\n",
      "requires_transposition                             False\n",
      "spo_already                                          NaN\n",
      "note                                                 NaN\n",
      "Name: 21, dtype: object\n",
      "[DUPLICATES] media_normalized_20130916.xlsx:mixture_taxon_exemplar - No duplicates in 'taxon_id'\n",
      "[INFO] media_normalized_20130916.xlsx:mixture_taxon_exemplar → 36 melted rows\n",
      "filename                                     media_normalized_20130916.xlsx\n",
      "sheet_name                                                 mixture_taxonomy\n",
      "id_column                 substance_taxonomy.parent|substance_taxonomy.c...\n",
      "skip                                                                  False\n",
      "requires_transposition                                                False\n",
      "spo_already                                                             NaN\n",
      "note                                                                    NaN\n",
      "Name: 22, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213811/3098165260.py:57: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[matched] = df[matched].astype(str).applymap(lambda v: v.strip() if isinstance(v, str) else v)\n",
      "/tmp/ipykernel_213811/3098165260.py:57: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[matched] = df[matched].astype(str).applymap(lambda v: v.strip() if isinstance(v, str) else v)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created synthetic ID column 'substance_taxonomy.parent_substance_taxonomy.child' from: ['substance_taxonomy.parent', 'substance_taxonomy.child']\n",
      "[DUPLICATES] media_normalized_20130916.xlsx:mixture_taxonomy - No duplicates in 'substance_taxonomy.parent_substance_taxonomy.child'\n",
      "[INFO] media_normalized_20130916.xlsx:mixture_taxonomy → 106 melted rows\n",
      "filename                      media_normalized_20130916.xlsx\n",
      "sheet_name                                           product\n",
      "id_column                 substance_name.id|vendor|productId\n",
      "skip                                                   False\n",
      "requires_transposition                                 False\n",
      "spo_already                                              NaN\n",
      "note                                                     NaN\n",
      "Name: 23, dtype: object\n",
      "[INFO] Created synthetic ID column 'substance_name.id_vendor_productId' from: ['substance_name.id', 'vendor', 'productId']\n",
      "[DUPLICATES] media_normalized_20130916.xlsx:product - No duplicates in 'substance_name.id_vendor_productId'\n",
      "[INFO] media_normalized_20130916.xlsx:product → 630 melted rows\n",
      "filename                  media_normalized_20130916.xlsx\n",
      "sheet_name                            substance_exemplar\n",
      "id_column                          substance_exemplar.id\n",
      "skip                                               False\n",
      "requires_transposition                             False\n",
      "spo_already                                          NaN\n",
      "note                                                 NaN\n",
      "Name: 24, dtype: object\n",
      "[DUPLICATES] media_normalized_20130916.xlsx:substance_exemplar - No duplicates in 'substance_exemplar.id'\n",
      "[INFO] media_normalized_20130916.xlsx:substance_exemplar → 184 melted rows\n",
      "filename                  media_normalized_20130916.xlsx\n",
      "sheet_name                    substance_exemplar_feature\n",
      "id_column                                            NaN\n",
      "skip                                                True\n",
      "requires_transposition                             False\n",
      "spo_already                                          NaN\n",
      "note                            blank except for headers\n",
      "Name: 25, dtype: object\n",
      "filename                        media_normalized_20130916.xlsx\n",
      "sheet_name                             substance_exemplar_type\n",
      "id_column                 substance_exemplar_feature_type.type\n",
      "skip                                                     False\n",
      "requires_transposition                                   False\n",
      "spo_already                                                NaN\n",
      "note                                                       NaN\n",
      "Name: 26, dtype: object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DUPLICATES] media_normalized_20130916.xlsx:substance_exemplar_type - No duplicates in 'substance_exemplar_feature_type.type'\n",
      "[INFO] media_normalized_20130916.xlsx:substance_exemplar_type → 4 melted rows\n",
      "filename                  media_normalized_20130916.xlsx\n",
      "sheet_name                                          unit\n",
      "id_column                                             id\n",
      "skip                                               False\n",
      "requires_transposition                             False\n",
      "spo_already                                          NaN\n",
      "note                                                 NaN\n",
      "Name: 27, dtype: object\n",
      "[DUPLICATES] media_normalized_20130916.xlsx:unit - No duplicates in 'id'\n",
      "[INFO] media_normalized_20130916.xlsx:unit → 36 melted rows\n",
      "filename                  media_normalized_20130916.xlsx\n",
      "sheet_name                                        vendor\n",
      "id_column                                         abbrev\n",
      "skip                                               False\n",
      "requires_transposition                             False\n",
      "spo_already                                          NaN\n",
      "note                                                 NaN\n",
      "Name: 28, dtype: object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DUPLICATES] media_normalized_20130916.xlsx:vendor - No duplicates in 'abbrev'\n",
      "[INFO] media_normalized_20130916.xlsx:vendor → 69 melted rows\n",
      "filename                  N4L_ID_to_NCBI_mappings.xlsx\n",
      "sheet_name                          N4L_NM.ID_to_EX.ID\n",
      "id_column                                   Name N4LID\n",
      "skip                                             False\n",
      "requires_transposition                           False\n",
      "spo_already                                        NaN\n",
      "note                                               NaN\n",
      "Name: 29, dtype: object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DUPLICATES] N4L_ID_to_NCBI_mappings.xlsx:N4L_NM.ID_to_EX.ID - No duplicates in 'Name N4LID'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] N4L_ID_to_NCBI_mappings.xlsx:N4L_NM.ID_to_EX.ID → 279917 melted rows\n",
      "filename                  N4L_ID_to_NCBI_mappings.xlsx\n",
      "sheet_name                     N4L_NM.ID_to_NCBI_TaxID\n",
      "id_column                                   Name N4LID\n",
      "skip                                             False\n",
      "requires_transposition                           False\n",
      "spo_already                                        NaN\n",
      "note                                               NaN\n",
      "Name: 30, dtype: object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DUPLICATES] N4L_ID_to_NCBI_mappings.xlsx:N4L_NM.ID_to_NCBI_TaxID - No duplicates in 'Name N4LID'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] N4L_ID_to_NCBI_mappings.xlsx:N4L_NM.ID_to_NCBI_TaxID → 91363 melted rows\n",
      "filename                  N4L_ID_to_NCBI_mappings.xlsx\n",
      "sheet_name                         N4L_REF.ID_to_DOCID\n",
      "id_column                                        refid\n",
      "skip                                             False\n",
      "requires_transposition                           False\n",
      "spo_already                                        NaN\n",
      "note                                               NaN\n",
      "Name: 31, dtype: object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DUPLICATES] N4L_ID_to_NCBI_mappings.xlsx:N4L_REF.ID_to_DOCID - No duplicates in 'refid'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] N4L_ID_to_NCBI_mappings.xlsx:N4L_REF.ID_to_DOCID → 64272 melted rows\n",
      "filename                  N4L_Taxonomy_20220802_pruned.xlsx\n",
      "sheet_name                     N4L_Taxonomy_20220802_pruned\n",
      "id_column                                             N4LID\n",
      "skip                                                  False\n",
      "requires_transposition                                False\n",
      "spo_already                                             NaN\n",
      "note                                                    NaN\n",
      "Name: 32, dtype: object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DUPLICATES] N4L_Taxonomy_20220802_pruned.xlsx:N4L_Taxonomy_20220802_pruned - No duplicates in 'N4LID'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] N4L_Taxonomy_20220802_pruned.xlsx:N4L_Taxonomy_20220802_pruned → 957331 melted rows\n",
      "filename                      N4L_Taxonomy_20220802.xlsx\n",
      "sheet_name                N4L_Taxonomy_20220802_complete\n",
      "id_column                                          N4LID\n",
      "skip                                               False\n",
      "requires_transposition                             False\n",
      "spo_already                                          NaN\n",
      "note                                                 NaN\n",
      "Name: 33, dtype: object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DUPLICATES] N4L_Taxonomy_20220802.xlsx:N4L_Taxonomy_20220802_complete - No duplicates in 'N4LID'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] N4L_Taxonomy_20220802.xlsx:N4L_Taxonomy_20220802_complete → 1273296 melted rows\n",
      "filename                    N4L_Taxonomy_20220802.xlsx\n",
      "sheet_name                N4L_Taxonomy_20220802_pruned\n",
      "id_column                                        N4LID\n",
      "skip                                             False\n",
      "requires_transposition                           False\n",
      "spo_already                                        NaN\n",
      "note                                               NaN\n",
      "Name: 34, dtype: object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DUPLICATES] N4L_Taxonomy_20220802.xlsx:N4L_Taxonomy_20220802_pruned - No duplicates in 'N4LID'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] N4L_Taxonomy_20220802.xlsx:N4L_Taxonomy_20220802_pruned → 957331 melted rows\n",
      "filename                  protolog_normalization_categories_with_1000_DB...\n",
      "sheet_name                                                  1000_proto_proj\n",
      "id_column                                           rid (effective)|name.id\n",
      "skip                                                                  False\n",
      "requires_transposition                                                 True\n",
      "spo_already                                                             NaN\n",
      "note                                                                    NaN\n",
      "Name: 35, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213811/3098165260.py:57: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[matched] = df[matched].astype(str).applymap(lambda v: v.strip() if isinstance(v, str) else v)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created synthetic ID column 'rid (effective)_name.id' from: ['rid (effective)', 'name.id']\n",
      "[DUPLICATES] protolog_normalization_categories_with_1000_DB.xlsx:1000_proto_proj - 324 duplicate rows on 'rid (effective)_name.id' → ['']\n",
      "[INFO] protolog_normalization_categories_with_1000_DB.xlsx:1000_proto_proj → 8856 melted rows\n",
      "filename                  protolog_normalization_categories_with_1000_DB...\n",
      "sheet_name                                                           Sheet1\n",
      "id_column                                                               NaN\n",
      "skip                                                                   True\n",
      "requires_transposition                                                False\n",
      "spo_already                                                             NaN\n",
      "note                                    Two-level class hierarchy of traits\n",
      "Name: 36, dtype: object\n",
      "filename                  protolog_normalization_categories_with_1000_DB...\n",
      "sheet_name                                                           Sheet2\n",
      "id_column                                                       rid|name.id\n",
      "skip                                                                  False\n",
      "requires_transposition                                                 True\n",
      "spo_already                                                             NaN\n",
      "note                                                                    NaN\n",
      "Name: 37, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/gitrepos/metpo/.venv/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/tmp/ipykernel_213811/3098165260.py:57: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[matched] = df[matched].astype(str).applymap(lambda v: v.strip() if isinstance(v, str) else v)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created synthetic ID column 'rid_name.id' from: ['rid', 'name.id']\n",
      "[DUPLICATES] protolog_normalization_categories_with_1000_DB.xlsx:Sheet2 - 2 duplicate rows on 'rid_name.id' → ['rid.2332_RID.2332 many OCR errors']\n",
      "[INFO] protolog_normalization_categories_with_1000_DB.xlsx:Sheet2 → 20948 melted rows\n",
      "filename                  protolog_normalization_categories_with_1000_DB...\n",
      "sheet_name                                                           Sheet3\n",
      "id_column                                                       rid|name.id\n",
      "skip                                                                  False\n",
      "requires_transposition                                                 True\n",
      "spo_already                                                             NaN\n",
      "note                                                                    NaN\n",
      "Name: 38, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/gitrepos/metpo/.venv/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/tmp/ipykernel_213811/3098165260.py:57: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[matched] = df[matched].astype(str).applymap(lambda v: v.strip() if isinstance(v, str) else v)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created synthetic ID column 'rid_name.id' from: ['rid', 'name.id']\n",
      "[DUPLICATES] protolog_normalization_categories_with_1000_DB.xlsx:Sheet3 - No duplicates in 'rid_name.id'\n",
      "[INFO] protolog_normalization_categories_with_1000_DB.xlsx:Sheet3 → 5425 melted rows\n",
      "filename                  protolog_normalization_categories_with_1000_KM...\n",
      "sheet_name                                                  1000_proto_proj\n",
      "id_column                                rid (effective/emendation)|name.id\n",
      "skip                                                                  False\n",
      "requires_transposition                                                 True\n",
      "spo_already                                                             NaN\n",
      "note                                                                    NaN\n",
      "Name: 39, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213811/3098165260.py:57: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[matched] = df[matched].astype(str).applymap(lambda v: v.strip() if isinstance(v, str) else v)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created synthetic ID column 'rid (effective/emendation)_name.id' from: ['rid (effective/emendation)', 'name.id']\n",
      "[DUPLICATES] protolog_normalization_categories_with_1000_KMP.xlsx:1000_proto_proj - 15 duplicate rows on 'rid (effective/emendation)_name.id' → ['', 'rid.3042_nm.4682', 'rid.15377_nm.207', 'rid.7454_nm.209']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] protolog_normalization_categories_with_1000_KMP.xlsx:1000_proto_proj → 33064 melted rows\n",
      "filename                  protolog_normalization_categories_with_1000_KM...\n",
      "sheet_name                                                  All(Sheet1,2,3)\n",
      "id_column                                                       rid|name.id\n",
      "skip                                                                  False\n",
      "requires_transposition                                                 True\n",
      "spo_already                                                             NaN\n",
      "note                                                                    NaN\n",
      "Name: 40, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213811/3098165260.py:57: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[matched] = df[matched].astype(str).applymap(lambda v: v.strip() if isinstance(v, str) else v)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created synthetic ID column 'rid_name.id' from: ['rid', 'name.id']\n",
      "[DUPLICATES] protolog_normalization_categories_with_1000_KMP.xlsx:All(Sheet1,2,3) - 31 duplicate rows on 'rid_name.id' → ['rid.2332_RID.2332 many OCR errors', 'rid.2351_nm.2812', 'rid.2584_nm.10201', 'rid.2692_nm.4564', 'rid.2809_nm.9168', 'rid.2868_nm.9103', 'rid.2981_nm.1983', 'rid.3042_nm.4682', '', 'rid.3107_nm.7957', 'rid.15377_nm.207', 'rid.7454_nm.209']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] protolog_normalization_categories_with_1000_KMP.xlsx:All(Sheet1,2,3) → 57109 melted rows\n",
      "filename                  protolog_normalization_categories_with_1000_KM...\n",
      "sheet_name                                     EffectRIDProtos(rid.2300 up)\n",
      "id_column                                                       rid|name.id\n",
      "skip                                                                  False\n",
      "requires_transposition                                                 True\n",
      "spo_already                                                             NaN\n",
      "note                                                                    NaN\n",
      "Name: 41, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/gitrepos/metpo/.venv/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/tmp/ipykernel_213811/3098165260.py:57: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[matched] = df[matched].astype(str).applymap(lambda v: v.strip() if isinstance(v, str) else v)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created synthetic ID column 'rid_name.id' from: ['rid', 'name.id']\n",
      "[DUPLICATES] protolog_normalization_categories_with_1000_KMP.xlsx:EffectRIDProtos(rid.2300 up) - 2 duplicate rows on 'rid_name.id' → ['rid.2332_RID.2332 many OCR errors']\n",
      "[INFO] protolog_normalization_categories_with_1000_KMP.xlsx:EffectRIDProtos(rid.2300 up) → 20945 melted rows\n",
      "filename                  protolog_normalization_categories_with_1000_KM...\n",
      "sheet_name                                                            Notes\n",
      "id_column                                                               NaN\n",
      "skip                                                                   True\n",
      "requires_transposition                                                False\n",
      "spo_already                                                             NaN\n",
      "note                                                             skip notes\n",
      "Name: 42, dtype: object\n",
      "filename                  protolog_normalization_categories_with_1000_KM...\n",
      "sheet_name                                                           Sheet2\n",
      "id_column                                                       rid|name.id\n",
      "skip                                                                  False\n",
      "requires_transposition                                                 True\n",
      "spo_already                                                             NaN\n",
      "note                                                                    NaN\n",
      "Name: 43, dtype: object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created synthetic ID column 'rid_name.id' from: ['rid', 'name.id']\n",
      "[DUPLICATES] protolog_normalization_categories_with_1000_KMP.xlsx:Sheet2 - No duplicates in 'rid_name.id'\n",
      "[INFO] protolog_normalization_categories_with_1000_KMP.xlsx:Sheet2 → 5406 melted rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/gitrepos/metpo/.venv/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/tmp/ipykernel_213811/3098165260.py:57: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[matched] = df[matched].astype(str).applymap(lambda v: v.strip() if isinstance(v, str) else v)\n"
     ]
    }
   ],
   "source": [
    "for _, row in xlsx_sheet_configs.iterrows():\n",
    "    print(row)\n",
    "\n",
    "    skip = str_to_bool(row.get(\"skip\", False))\n",
    "    spo_already = str_to_bool(row.get(\"spo_already\", False))\n",
    "    requires_transposition = str_to_bool(row.get(\"requires_transposition\", False))\n",
    "    id_column = row.get(\"id_column\")\n",
    "    composite_columns = None\n",
    "\n",
    "    if skip:\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(n4l_data_directory, row[\"filename\"])\n",
    "    sheet_name = row[\"sheet_name\"]\n",
    "    graph_iri = f\"{n4l_prefix}{safe_iri_component(row['filename'].strip())}/{safe_iri_component(sheet_name.strip())}\"\n",
    "\n",
    "    try:\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet_name, header=None if requires_transposition else 0)\n",
    "\n",
    "        if requires_transposition:\n",
    "            df = df.transpose()\n",
    "            df.columns = df.iloc[0]\n",
    "            df = df[1:].reset_index(drop=True)\n",
    "\n",
    "        df.columns = df.columns.map(lambda x: str(x).strip())  # Normalize column names\n",
    "\n",
    "        if spo_already:\n",
    "            if df.shape[1] != 3:\n",
    "                print(\n",
    "                    f\"[ERROR] {row['filename']}:{sheet_name} - Expected 3 columns for SPO format, found {df.shape[1]}\")\n",
    "                continue\n",
    "            df.columns = [\"subject\", \"predicate\", \"object_value\"]\n",
    "            df = df.dropna(subset=[\"subject\", \"predicate\", \"object_value\"])\n",
    "            df[\"subject\"] = df[\"subject\"].astype(str).apply(lambda x: f\"{n4l_prefix}{safe_iri_component(x.strip())}\")\n",
    "            df[\"predicate\"] = df[\"predicate\"].astype(str).apply(\n",
    "                lambda x: f\"{n4l_prefix}{safe_iri_component(x.strip())}\")\n",
    "            df[\"source_file\"] = row[\"filename\"]\n",
    "            df[\"source_sheet\"] = sheet_name\n",
    "            df[\"graph\"] = graph_iri\n",
    "            melted_frames.append(df)\n",
    "            print(f\"[INFO] {row['filename']}:{sheet_name} (SPO) → {df.shape[0]} rows\")\n",
    "            continue\n",
    "\n",
    "        # --- Composite ID handling (improved) ---\n",
    "        if isinstance(id_column, str) and \"|\" in id_column:\n",
    "            composite_columns = [col.strip() for col in id_column.split(\"|\")]\n",
    "\n",
    "            normalized_cols = {str(col).strip(): col for col in df.columns}\n",
    "            missing = [col for col in composite_columns if col not in normalized_cols]\n",
    "            if missing:\n",
    "                print(f\"[ERROR] {row['filename']}:{sheet_name} - Missing composite ID columns: {missing}\")\n",
    "                continue\n",
    "\n",
    "            matched = [normalized_cols[col] for col in composite_columns]\n",
    "            id_column = \"_\".join(composite_columns)\n",
    "\n",
    "            df[matched] = df[matched].astype(str).applymap(lambda v: v.strip() if isinstance(v, str) else v)\n",
    "\n",
    "            # Log partial composite IDs\n",
    "            partial_ids = df[matched].isna().any(axis=1) & ~df[matched].isna().all(axis=1)\n",
    "            if partial_ids.any():\n",
    "                print(f\"[QC] {row['filename']}:{sheet_name} - {partial_ids.sum()} rows with partial composite IDs\")\n",
    "\n",
    "            # Join only valid components\n",
    "            def safe_join(vals):\n",
    "                return \"_\".join([str(v).strip() for v in vals if v and str(v).strip().lower() != \"nan\"])\n",
    "\n",
    "            df[id_column] = df[matched].agg(safe_join, axis=1)\n",
    "\n",
    "            # Drop rows where all components were missing\n",
    "            blank_ids = df[matched].isna().all(axis=1)\n",
    "            if blank_ids.any():\n",
    "                print(f\"[QC] {row['filename']}:{sheet_name} - Dropped {blank_ids.sum()} rows with blank synthetic ID\")\n",
    "                df = df[~blank_ids]\n",
    "\n",
    "            print(f\"[INFO] Created synthetic ID column '{id_column}' from: {composite_columns}\")\n",
    "\n",
    "        else:\n",
    "            if pd.isna(id_column):\n",
    "                print(f\"[ERROR] {row['filename']}:{sheet_name} - ID column is NaN\")\n",
    "                continue\n",
    "\n",
    "            normalized_cols = {str(col).strip(): col for col in df.columns}\n",
    "            if id_column.strip() not in normalized_cols:\n",
    "                print(\n",
    "                    f\"[ERROR] {row['filename']}:{sheet_name} - ID column '{id_column}' not found. Available columns: {df.columns.tolist()}\")\n",
    "                continue\n",
    "            id_column = normalized_cols[id_column.strip()]\n",
    "\n",
    "        df = df.drop_duplicates()\n",
    "        df = df.dropna(subset=[id_column])\n",
    "\n",
    "        full_dupes = df.duplicated()\n",
    "        if full_dupes.any():\n",
    "            print(f\"[QC] {row['filename']}:{sheet_name} - Removed {full_dupes.sum()} fully duplicated rows\")\n",
    "            df = df[~full_dupes]\n",
    "\n",
    "        duplicated_mask = df[id_column].duplicated(keep=False)\n",
    "        duplicated_rows = df[duplicated_mask]\n",
    "\n",
    "        if not duplicated_rows.empty:\n",
    "            duplicated_ids = df[duplicated_mask][id_column].unique()\n",
    "            print(\n",
    "                f\"[DUPLICATES] {row['filename']}:{sheet_name} - {len(duplicated_rows)} duplicate rows on '{id_column}' → {list(duplicated_ids)}\")\n",
    "            df = df[~duplicated_mask]\n",
    "        else:\n",
    "            print(f\"[DUPLICATES] {row['filename']}:{sheet_name} - No duplicates in '{id_column}'\")\n",
    "\n",
    "        melted = df.melt(id_vars=[id_column], var_name=\"predicate\", value_name=\"object_value\")\n",
    "        melted = melted.rename(columns={id_column: \"subject\"})\n",
    "        melted = melted.dropna(subset=[\"subject\", \"predicate\", \"object_value\"])\n",
    "        melted[\"subject\"] = melted[\"subject\"].astype(str).apply(\n",
    "            lambda x: f\"{n4l_prefix}{safe_iri_component(x.strip())}\")\n",
    "        melted[\"predicate\"] = melted[\"predicate\"].astype(str).apply(\n",
    "            lambda x: f\"{n4l_prefix}{safe_iri_component(x.strip())}\")\n",
    "        melted[\"source_file\"] = row[\"filename\"]\n",
    "        melted[\"source_sheet\"] = sheet_name\n",
    "        melted[\"graph\"] = graph_iri\n",
    "        melted_frames.append(melted)\n",
    "        print(f\"[INFO] {row['filename']}:{sheet_name} → {melted.shape[0]} melted rows\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed processing {row['filename']}:{sheet_name} - {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efcaa4e40f87f30e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T01:37:01.041169Z",
     "iopub.status.busy": "2025-05-21T01:37:01.040876Z",
     "iopub.status.idle": "2025-05-21T01:37:01.341422Z",
     "shell.execute_reply": "2025-05-21T01:37:01.340764Z"
    },
    "papermill": {
     "duration": 0.311802,
     "end_time": "2025-05-21T01:37:01.342511",
     "exception": false,
     "start_time": "2025-05-21T01:37:01.030709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine all into one frame\n",
    "combined_df = pd.concat(melted_frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b00521709df88e34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T01:37:01.362962Z",
     "iopub.status.busy": "2025-05-21T01:37:01.362674Z",
     "iopub.status.idle": "2025-05-21T01:37:01.367461Z",
     "shell.execute_reply": "2025-05-21T01:37:01.366741Z"
    },
    "papermill": {
     "duration": 0.015802,
     "end_time": "2025-05-21T01:37:01.368317",
     "exception": false,
     "start_time": "2025-05-21T01:37:01.352515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6180621, 6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b03bcd1f929b94f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T01:37:01.388268Z",
     "iopub.status.busy": "2025-05-21T01:37:01.388055Z",
     "iopub.status.idle": "2025-05-21T01:37:05.391602Z",
     "shell.execute_reply": "2025-05-21T01:37:05.391020Z"
    },
    "papermill": {
     "duration": 4.014784,
     "end_time": "2025-05-21T01:37:05.392699",
     "exception": false,
     "start_time": "2025-05-21T01:37:01.377915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_df = combined_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7015cf0a15db9292",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T01:37:05.412137Z",
     "iopub.status.busy": "2025-05-21T01:37:05.411890Z",
     "iopub.status.idle": "2025-05-21T01:37:05.415692Z",
     "shell.execute_reply": "2025-05-21T01:37:05.415244Z"
    },
    "papermill": {
     "duration": 0.014562,
     "end_time": "2025-05-21T01:37:05.416589",
     "exception": false,
     "start_time": "2025-05-21T01:37:05.402027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6180612, 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2745e6a9bc2011f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T01:37:05.436288Z",
     "iopub.status.busy": "2025-05-21T01:37:05.435911Z",
     "iopub.status.idle": "2025-05-21T01:37:05.444729Z",
     "shell.execute_reply": "2025-05-21T01:37:05.444187Z"
    },
    "papermill": {
     "duration": 0.019568,
     "end_time": "2025-05-21T01:37:05.445632",
     "exception": false,
     "start_time": "2025-05-21T01:37:05.426064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>predicate</th>\n",
       "      <th>object_value</th>\n",
       "      <th>source_file</th>\n",
       "      <th>graph</th>\n",
       "      <th>source_sheet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://example.com/n4l/nm.0</td>\n",
       "      <td>http://example.com/n4l/index</td>\n",
       "      <td>1</td>\n",
       "      <td>N4L_Taxonomy_20220802.tsv</td>\n",
       "      <td>http://example.com/n4l/N4L_Taxonomy_20220802.tsv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://example.com/n4l/nm.1</td>\n",
       "      <td>http://example.com/n4l/index</td>\n",
       "      <td>2</td>\n",
       "      <td>N4L_Taxonomy_20220802.tsv</td>\n",
       "      <td>http://example.com/n4l/N4L_Taxonomy_20220802.tsv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://example.com/n4l/nm.2</td>\n",
       "      <td>http://example.com/n4l/index</td>\n",
       "      <td>3</td>\n",
       "      <td>N4L_Taxonomy_20220802.tsv</td>\n",
       "      <td>http://example.com/n4l/N4L_Taxonomy_20220802.tsv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://example.com/n4l/nm.31636</td>\n",
       "      <td>http://example.com/n4l/index</td>\n",
       "      <td>24009</td>\n",
       "      <td>N4L_Taxonomy_20220802.tsv</td>\n",
       "      <td>http://example.com/n4l/N4L_Taxonomy_20220802.tsv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://example.com/n4l/nm.3</td>\n",
       "      <td>http://example.com/n4l/index</td>\n",
       "      <td>4</td>\n",
       "      <td>N4L_Taxonomy_20220802.tsv</td>\n",
       "      <td>http://example.com/n4l/N4L_Taxonomy_20220802.tsv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180616</th>\n",
       "      <td>http://example.com/n4l/nm.8017</td>\n",
       "      <td>http://example.com/n4l/note</td>\n",
       "      <td>The descriptions of Murinilabilia sulmonicolor...</td>\n",
       "      <td>protolog_normalization_categories_with_1000_KM...</td>\n",
       "      <td>http://example.com/n4l/protolog_normalization_...</td>\n",
       "      <td>Sheet2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180617</th>\n",
       "      <td>http://example.com/n4l/nm.2199</td>\n",
       "      <td>http://example.com/n4l/note</td>\n",
       "      <td>The description of Acidithiobacillus thiooxida...</td>\n",
       "      <td>protolog_normalization_categories_with_1000_KM...</td>\n",
       "      <td>http://example.com/n4l/protolog_normalization_...</td>\n",
       "      <td>Sheet2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180618</th>\n",
       "      <td>http://example.com/n4l/nm.5724</td>\n",
       "      <td>http://example.com/n4l/note</td>\n",
       "      <td>In addition to the description of the genus</td>\n",
       "      <td>protolog_normalization_categories_with_1000_KM...</td>\n",
       "      <td>http://example.com/n4l/protolog_normalization_...</td>\n",
       "      <td>Sheet2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180619</th>\n",
       "      <td>http://example.com/n4l/rid.4142_nm.1005</td>\n",
       "      <td>http://example.com/n4l/note</td>\n",
       "      <td>no true protolog in this reference</td>\n",
       "      <td>protolog_normalization_categories_with_1000_KM...</td>\n",
       "      <td>http://example.com/n4l/protolog_normalization_...</td>\n",
       "      <td>Sheet2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180620</th>\n",
       "      <td>http://example.com/n4l/rid.4142_nm.1006</td>\n",
       "      <td>http://example.com/n4l/note</td>\n",
       "      <td>no true protolog in this reference</td>\n",
       "      <td>protolog_normalization_categories_with_1000_KM...</td>\n",
       "      <td>http://example.com/n4l/protolog_normalization_...</td>\n",
       "      <td>Sheet2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6180612 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         subject  \\\n",
       "0                    http://example.com/n4l/nm.0   \n",
       "1                    http://example.com/n4l/nm.1   \n",
       "2                    http://example.com/n4l/nm.2   \n",
       "3                http://example.com/n4l/nm.31636   \n",
       "4                    http://example.com/n4l/nm.3   \n",
       "...                                          ...   \n",
       "6180616           http://example.com/n4l/nm.8017   \n",
       "6180617           http://example.com/n4l/nm.2199   \n",
       "6180618           http://example.com/n4l/nm.5724   \n",
       "6180619  http://example.com/n4l/rid.4142_nm.1005   \n",
       "6180620  http://example.com/n4l/rid.4142_nm.1006   \n",
       "\n",
       "                            predicate  \\\n",
       "0        http://example.com/n4l/index   \n",
       "1        http://example.com/n4l/index   \n",
       "2        http://example.com/n4l/index   \n",
       "3        http://example.com/n4l/index   \n",
       "4        http://example.com/n4l/index   \n",
       "...                               ...   \n",
       "6180616   http://example.com/n4l/note   \n",
       "6180617   http://example.com/n4l/note   \n",
       "6180618   http://example.com/n4l/note   \n",
       "6180619   http://example.com/n4l/note   \n",
       "6180620   http://example.com/n4l/note   \n",
       "\n",
       "                                              object_value  \\\n",
       "0                                                        1   \n",
       "1                                                        2   \n",
       "2                                                        3   \n",
       "3                                                    24009   \n",
       "4                                                        4   \n",
       "...                                                    ...   \n",
       "6180616  The descriptions of Murinilabilia sulmonicolor...   \n",
       "6180617  The description of Acidithiobacillus thiooxida...   \n",
       "6180618        In addition to the description of the genus   \n",
       "6180619                 no true protolog in this reference   \n",
       "6180620                 no true protolog in this reference   \n",
       "\n",
       "                                               source_file  \\\n",
       "0                                N4L_Taxonomy_20220802.tsv   \n",
       "1                                N4L_Taxonomy_20220802.tsv   \n",
       "2                                N4L_Taxonomy_20220802.tsv   \n",
       "3                                N4L_Taxonomy_20220802.tsv   \n",
       "4                                N4L_Taxonomy_20220802.tsv   \n",
       "...                                                    ...   \n",
       "6180616  protolog_normalization_categories_with_1000_KM...   \n",
       "6180617  protolog_normalization_categories_with_1000_KM...   \n",
       "6180618  protolog_normalization_categories_with_1000_KM...   \n",
       "6180619  protolog_normalization_categories_with_1000_KM...   \n",
       "6180620  protolog_normalization_categories_with_1000_KM...   \n",
       "\n",
       "                                                     graph source_sheet  \n",
       "0         http://example.com/n4l/N4L_Taxonomy_20220802.tsv          NaN  \n",
       "1         http://example.com/n4l/N4L_Taxonomy_20220802.tsv          NaN  \n",
       "2         http://example.com/n4l/N4L_Taxonomy_20220802.tsv          NaN  \n",
       "3         http://example.com/n4l/N4L_Taxonomy_20220802.tsv          NaN  \n",
       "4         http://example.com/n4l/N4L_Taxonomy_20220802.tsv          NaN  \n",
       "...                                                    ...          ...  \n",
       "6180616  http://example.com/n4l/protolog_normalization_...       Sheet2  \n",
       "6180617  http://example.com/n4l/protolog_normalization_...       Sheet2  \n",
       "6180618  http://example.com/n4l/protolog_normalization_...       Sheet2  \n",
       "6180619  http://example.com/n4l/protolog_normalization_...       Sheet2  \n",
       "6180620  http://example.com/n4l/protolog_normalization_...       Sheet2  \n",
       "\n",
       "[6180612 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd55e4c17990c077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T01:37:05.465834Z",
     "iopub.status.busy": "2025-05-21T01:37:05.465545Z",
     "iopub.status.idle": "2025-05-21T01:37:07.730778Z",
     "shell.execute_reply": "2025-05-21T01:37:07.729653Z"
    },
    "papermill": {
     "duration": 2.277206,
     "end_time": "2025-05-21T01:37:07.732564",
     "exception": false,
     "start_time": "2025-05-21T01:37:05.455358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_df = combined_df.dropna(subset=[\"subject\", \"predicate\", \"object_value\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a31b34d42367c37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T01:37:07.759338Z",
     "iopub.status.busy": "2025-05-21T01:37:07.759122Z",
     "iopub.status.idle": "2025-05-21T01:37:07.763045Z",
     "shell.execute_reply": "2025-05-21T01:37:07.762491Z"
    },
    "papermill": {
     "duration": 0.016637,
     "end_time": "2025-05-21T01:37:07.764002",
     "exception": false,
     "start_time": "2025-05-21T01:37:07.747365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6180612, 6)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d099e6af0646839f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T01:37:07.785077Z",
     "iopub.status.busy": "2025-05-21T01:37:07.784804Z",
     "iopub.status.idle": "2025-05-21T01:37:07.788972Z",
     "shell.execute_reply": "2025-05-21T01:37:07.788511Z"
    },
    "papermill": {
     "duration": 0.015393,
     "end_time": "2025-05-21T01:37:07.789768",
     "exception": false,
     "start_time": "2025-05-21T01:37:07.774375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject', 'predicate', 'object_value', 'source_file', 'graph',\n",
       "       'source_sheet'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7a0d873dbbdf42d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T01:37:07.810199Z",
     "iopub.status.busy": "2025-05-21T01:37:07.809758Z",
     "iopub.status.idle": "2025-05-21T01:37:07.818228Z",
     "shell.execute_reply": "2025-05-21T01:37:07.817749Z"
    },
    "papermill": {
     "duration": 0.01958,
     "end_time": "2025-05-21T01:37:07.819072",
     "exception": false,
     "start_time": "2025-05-21T01:37:07.799492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>predicate</th>\n",
       "      <th>object_value</th>\n",
       "      <th>source_file</th>\n",
       "      <th>graph</th>\n",
       "      <th>source_sheet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://example.com/n4l/nm.0</td>\n",
       "      <td>http://example.com/n4l/index</td>\n",
       "      <td>1</td>\n",
       "      <td>N4L_Taxonomy_20220802.tsv</td>\n",
       "      <td>http://example.com/n4l/N4L_Taxonomy_20220802.tsv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://example.com/n4l/nm.1</td>\n",
       "      <td>http://example.com/n4l/index</td>\n",
       "      <td>2</td>\n",
       "      <td>N4L_Taxonomy_20220802.tsv</td>\n",
       "      <td>http://example.com/n4l/N4L_Taxonomy_20220802.tsv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://example.com/n4l/nm.2</td>\n",
       "      <td>http://example.com/n4l/index</td>\n",
       "      <td>3</td>\n",
       "      <td>N4L_Taxonomy_20220802.tsv</td>\n",
       "      <td>http://example.com/n4l/N4L_Taxonomy_20220802.tsv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://example.com/n4l/nm.31636</td>\n",
       "      <td>http://example.com/n4l/index</td>\n",
       "      <td>24009</td>\n",
       "      <td>N4L_Taxonomy_20220802.tsv</td>\n",
       "      <td>http://example.com/n4l/N4L_Taxonomy_20220802.tsv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://example.com/n4l/nm.3</td>\n",
       "      <td>http://example.com/n4l/index</td>\n",
       "      <td>4</td>\n",
       "      <td>N4L_Taxonomy_20220802.tsv</td>\n",
       "      <td>http://example.com/n4l/N4L_Taxonomy_20220802.tsv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180616</th>\n",
       "      <td>http://example.com/n4l/nm.8017</td>\n",
       "      <td>http://example.com/n4l/note</td>\n",
       "      <td>The descriptions of Murinilabilia sulmonicolor...</td>\n",
       "      <td>protolog_normalization_categories_with_1000_KM...</td>\n",
       "      <td>http://example.com/n4l/protolog_normalization_...</td>\n",
       "      <td>Sheet2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180617</th>\n",
       "      <td>http://example.com/n4l/nm.2199</td>\n",
       "      <td>http://example.com/n4l/note</td>\n",
       "      <td>The description of Acidithiobacillus thiooxida...</td>\n",
       "      <td>protolog_normalization_categories_with_1000_KM...</td>\n",
       "      <td>http://example.com/n4l/protolog_normalization_...</td>\n",
       "      <td>Sheet2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180618</th>\n",
       "      <td>http://example.com/n4l/nm.5724</td>\n",
       "      <td>http://example.com/n4l/note</td>\n",
       "      <td>In addition to the description of the genus</td>\n",
       "      <td>protolog_normalization_categories_with_1000_KM...</td>\n",
       "      <td>http://example.com/n4l/protolog_normalization_...</td>\n",
       "      <td>Sheet2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180619</th>\n",
       "      <td>http://example.com/n4l/rid.4142_nm.1005</td>\n",
       "      <td>http://example.com/n4l/note</td>\n",
       "      <td>no true protolog in this reference</td>\n",
       "      <td>protolog_normalization_categories_with_1000_KM...</td>\n",
       "      <td>http://example.com/n4l/protolog_normalization_...</td>\n",
       "      <td>Sheet2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180620</th>\n",
       "      <td>http://example.com/n4l/rid.4142_nm.1006</td>\n",
       "      <td>http://example.com/n4l/note</td>\n",
       "      <td>no true protolog in this reference</td>\n",
       "      <td>protolog_normalization_categories_with_1000_KM...</td>\n",
       "      <td>http://example.com/n4l/protolog_normalization_...</td>\n",
       "      <td>Sheet2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6180612 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         subject  \\\n",
       "0                    http://example.com/n4l/nm.0   \n",
       "1                    http://example.com/n4l/nm.1   \n",
       "2                    http://example.com/n4l/nm.2   \n",
       "3                http://example.com/n4l/nm.31636   \n",
       "4                    http://example.com/n4l/nm.3   \n",
       "...                                          ...   \n",
       "6180616           http://example.com/n4l/nm.8017   \n",
       "6180617           http://example.com/n4l/nm.2199   \n",
       "6180618           http://example.com/n4l/nm.5724   \n",
       "6180619  http://example.com/n4l/rid.4142_nm.1005   \n",
       "6180620  http://example.com/n4l/rid.4142_nm.1006   \n",
       "\n",
       "                            predicate  \\\n",
       "0        http://example.com/n4l/index   \n",
       "1        http://example.com/n4l/index   \n",
       "2        http://example.com/n4l/index   \n",
       "3        http://example.com/n4l/index   \n",
       "4        http://example.com/n4l/index   \n",
       "...                               ...   \n",
       "6180616   http://example.com/n4l/note   \n",
       "6180617   http://example.com/n4l/note   \n",
       "6180618   http://example.com/n4l/note   \n",
       "6180619   http://example.com/n4l/note   \n",
       "6180620   http://example.com/n4l/note   \n",
       "\n",
       "                                              object_value  \\\n",
       "0                                                        1   \n",
       "1                                                        2   \n",
       "2                                                        3   \n",
       "3                                                    24009   \n",
       "4                                                        4   \n",
       "...                                                    ...   \n",
       "6180616  The descriptions of Murinilabilia sulmonicolor...   \n",
       "6180617  The description of Acidithiobacillus thiooxida...   \n",
       "6180618        In addition to the description of the genus   \n",
       "6180619                 no true protolog in this reference   \n",
       "6180620                 no true protolog in this reference   \n",
       "\n",
       "                                               source_file  \\\n",
       "0                                N4L_Taxonomy_20220802.tsv   \n",
       "1                                N4L_Taxonomy_20220802.tsv   \n",
       "2                                N4L_Taxonomy_20220802.tsv   \n",
       "3                                N4L_Taxonomy_20220802.tsv   \n",
       "4                                N4L_Taxonomy_20220802.tsv   \n",
       "...                                                    ...   \n",
       "6180616  protolog_normalization_categories_with_1000_KM...   \n",
       "6180617  protolog_normalization_categories_with_1000_KM...   \n",
       "6180618  protolog_normalization_categories_with_1000_KM...   \n",
       "6180619  protolog_normalization_categories_with_1000_KM...   \n",
       "6180620  protolog_normalization_categories_with_1000_KM...   \n",
       "\n",
       "                                                     graph source_sheet  \n",
       "0         http://example.com/n4l/N4L_Taxonomy_20220802.tsv          NaN  \n",
       "1         http://example.com/n4l/N4L_Taxonomy_20220802.tsv          NaN  \n",
       "2         http://example.com/n4l/N4L_Taxonomy_20220802.tsv          NaN  \n",
       "3         http://example.com/n4l/N4L_Taxonomy_20220802.tsv          NaN  \n",
       "4         http://example.com/n4l/N4L_Taxonomy_20220802.tsv          NaN  \n",
       "...                                                    ...          ...  \n",
       "6180616  http://example.com/n4l/protolog_normalization_...       Sheet2  \n",
       "6180617  http://example.com/n4l/protolog_normalization_...       Sheet2  \n",
       "6180618  http://example.com/n4l/protolog_normalization_...       Sheet2  \n",
       "6180619  http://example.com/n4l/protolog_normalization_...       Sheet2  \n",
       "6180620  http://example.com/n4l/protolog_normalization_...       Sheet2  \n",
       "\n",
       "[6180612 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99652621c9fd1714",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T01:37:07.840215Z",
     "iopub.status.busy": "2025-05-21T01:37:07.839686Z",
     "iopub.status.idle": "2025-05-21T01:37:07.843035Z",
     "shell.execute_reply": "2025-05-21T01:37:07.842575Z"
    },
    "papermill": {
     "duration": 0.014779,
     "end_time": "2025-05-21T01:37:07.843926",
     "exception": false,
     "start_time": "2025-05-21T01:37:07.829147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2795446771023b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T01:37:07.864417Z",
     "iopub.status.busy": "2025-05-21T01:37:07.864220Z",
     "iopub.status.idle": "2025-05-21T01:37:07.870926Z",
     "shell.execute_reply": "2025-05-21T01:37:07.870471Z"
    },
    "papermill": {
     "duration": 0.017777,
     "end_time": "2025-05-21T01:37:07.871790",
     "exception": false,
     "start_time": "2025-05-21T01:37:07.854013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_predicate</th>\n",
       "      <th>normalized_predicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://example.com/n4l/per_volume_units</td>\n",
       "      <td>http://example.com/n4l/per_volume_units</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://example.com/n4l/preparation</td>\n",
       "      <td>http://example.com/n4l/preparation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://example.com/n4l/per_volume_amount</td>\n",
       "      <td>http://example.com/n4l/per_volume_amount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://example.com/n4l/chemical_taxon.rank</td>\n",
       "      <td>http://example.com/n4l/chemical_taxon_rank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://example.com/n4l/reference</td>\n",
       "      <td>http://example.com/n4l/reference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>http://example.com/n4l/eponym</td>\n",
       "      <td>http://example.com/n4l/eponym</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>http://example.com/n4l/see_also</td>\n",
       "      <td>http://example.com/n4l/see_also</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>http://example.com/n4l/Prescott</td>\n",
       "      <td>http://example.com/n4l/prescott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>http://example.com/n4l/eponym_meaning</td>\n",
       "      <td>http://example.com/n4l/eponym_meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>http://example.com/n4l/DOI</td>\n",
       "      <td>http://example.com/n4l/doi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             original_predicate  \\\n",
       "0       http://example.com/n4l/per_volume_units   \n",
       "1            http://example.com/n4l/preparation   \n",
       "2      http://example.com/n4l/per_volume_amount   \n",
       "3    http://example.com/n4l/chemical_taxon.rank   \n",
       "4              http://example.com/n4l/reference   \n",
       "..                                          ...   \n",
       "282               http://example.com/n4l/eponym   \n",
       "283             http://example.com/n4l/see_also   \n",
       "284             http://example.com/n4l/Prescott   \n",
       "285       http://example.com/n4l/eponym_meaning   \n",
       "286                  http://example.com/n4l/DOI   \n",
       "\n",
       "                           normalized_predicate  \n",
       "0       http://example.com/n4l/per_volume_units  \n",
       "1            http://example.com/n4l/preparation  \n",
       "2      http://example.com/n4l/per_volume_amount  \n",
       "3    http://example.com/n4l/chemical_taxon_rank  \n",
       "4              http://example.com/n4l/reference  \n",
       "..                                          ...  \n",
       "282               http://example.com/n4l/eponym  \n",
       "283             http://example.com/n4l/see_also  \n",
       "284             http://example.com/n4l/prescott  \n",
       "285       http://example.com/n4l/eponym_meaning  \n",
       "286                  http://example.com/n4l/doi  \n",
       "\n",
       "[287 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f0be9c86f165355",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T01:37:07.893215Z",
     "iopub.status.busy": "2025-05-21T01:37:07.893004Z",
     "iopub.status.idle": "2025-05-21T01:37:07.896331Z",
     "shell.execute_reply": "2025-05-21T01:37:07.895854Z"
    },
    "papermill": {
     "duration": 0.014971,
     "end_time": "2025-05-21T01:37:07.897184",
     "exception": false,
     "start_time": "2025-05-21T01:37:07.882213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicate_mapping = dict(zip(mapping_df[\"original_predicate\"], mapping_df[\"normalized_predicate\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9726367c8a41859",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T01:37:07.918007Z",
     "iopub.status.busy": "2025-05-21T01:37:07.917801Z",
     "iopub.status.idle": "2025-05-21T01:47:16.039611Z",
     "shell.execute_reply": "2025-05-21T01:47:16.039054Z"
    },
    "papermill": {
     "duration": 608.133382,
     "end_time": "2025-05-21T01:47:16.040701",
     "exception": false,
     "start_time": "2025-05-21T01:37:07.907319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for _, row in combined_df.iterrows():\n",
    "    subj = URIRef(row[\"subject\"])\n",
    "\n",
    "    if row[\"predicate\"] not in predicate_mapping:\n",
    "        raise ValueError(f\"Predicate not found in mapping: {row['predicate']}\")\n",
    "\n",
    "    pred_iri = predicate_mapping[row[\"predicate\"]]\n",
    "    pred = URIRef(pred_iri)\n",
    "\n",
    "    obj = safe_object_term(row[\"object_value\"])\n",
    "    graph_iri = URIRef(row[\"graph\"])\n",
    "\n",
    "    ds.add((subj, pred, obj, graph_iri))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d78224c4c47a8cc",
   "metadata": {
    "papermill": {
     "duration": 0.009659,
     "end_time": "2025-05-21T01:47:16.060204",
     "exception": false,
     "start_time": "2025-05-21T01:47:16.050545",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "11 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1cbdc65a2fff4475",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T01:47:16.080879Z",
     "iopub.status.busy": "2025-05-21T01:47:16.080620Z",
     "iopub.status.idle": "2025-05-21T01:48:11.895648Z",
     "shell.execute_reply": "2025-05-21T01:48:11.895060Z"
    },
    "papermill": {
     "duration": 55.838638,
     "end_time": "2025-05-21T01:48:11.908647",
     "exception": false,
     "start_time": "2025-05-21T01:47:16.070009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N1c576016d4e241038309dfa99c2ad744 (<class 'rdflib.graph.Dataset'>)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ✅ Serialize to N-Quads file\n",
    "ds.serialize(destination=nq_out, format=\"nquads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb6424521998905",
   "metadata": {
    "papermill": {
     "duration": 0.010948,
     "end_time": "2025-05-21T01:48:11.931002",
     "exception": false,
     "start_time": "2025-05-21T01:48:11.920054",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "now zip and load into graphdb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 772.744653,
   "end_time": "2025-05-21T01:48:14.959704",
   "environment_variables": {},
   "exception": null,
   "input_path": "metpo/n4l_tables_to_quads.ipynb",
   "output_path": "metpo/n4l_tables_to_quads.ran.ipynb",
   "parameters": {},
   "start_time": "2025-05-21T01:35:22.215051",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}